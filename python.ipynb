{"cells":[{"cell_type": "markdown", "metadata": {}, "source": ["<h1>Numerical Methods in Python</h1>\n\nThis Jupyter notebook serves as supplementary material to the Python code from the book [Numerical Methods for Scientific Computing](https://nbviewer.jupyter.org/github/nmfsc/book/blob/main/NMFSC.pdf).  These code snippets are minimal working toy algorithms meant to better understand the mathematics that goes into them. They are tools for tinkering and learning. Play with them and have fun. And, perhaps you can repurpose a few of them. In practice, use real packages. By-and-large, the snippets are verbatim from the book with the an occasional explicit plot statement or variable declaration.  The notebook is designed to be nonlinear⁠—you can jump around.  We'll load the following packages which are used throughout this notebook:"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import matplotlib.pyplot as plt\n","import numpy as np\n","import scipy.linalg as la\n","import scipy.sparse as sp\n","bucket = \"https://raw.githubusercontent.com/nmfsc/data/master/\""]},{"cell_type": "markdown", "metadata": {}, "source": ["We can set the output of matplotlib in Jupyter to produce SVG, which will result in higher quality plots than the default PNG. Rendering a SVG is a little slower than a PNG and it can produce noticeable jerkiness in ipywidgets animations.  To switch back to the default PNG, use the command `set_matplotlib_formats('png')`."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from IPython.display import set_matplotlib_formats\n","%matplotlib inline\n","set_matplotlib_formats('svg')"]},{"cell_type": "markdown", "metadata": {}, "source": [""]},{"cell_type": "markdown", "metadata": {}, "source": ["<h1>Notebook Contents</h1>\n\n [Part 1: Numerical Linear Algebra](#label0)<br>\n&emsp; [Chapter 1: A Review of Linear Algebra](#label1)<br>\n&emsp; [Chapter 2: Direct Methods for Linear Systems](#label2)<br>\n&emsp; [Chapter 3: Inconsistent Systems](#label3)<br>\n&emsp; [Chapter 4: Computing Eigenvalues](#label4)<br>\n&emsp; [Chapter 6: Fast Fourier Transform](#label5)<br>\n [Part 2: Numerical Methods for Analysis](#label6)<br>\n&emsp; [Chapter 7: Preliminaries](#label7)<br>\n&emsp; [Chapter 8: Solutions to Nonlinear Equations](#label8)<br>\n&emsp; [Chapter 9: Interpolation](#label9)<br>\n&emsp; [Chapter 10: Approximating Functions](#label10)<br>\n&emsp; [Chapter 11: Differentiation and Integration](#label11)<br>\n [Part 3: Numerical Differential Equations](#label12)<br>\n&emsp; [Chapter 12: Ordinary Differential Equations](#label13)<br>\n&emsp; [Chapter 13: Parabolic Equations](#label14)<br>\n&emsp; [Chapter 16: Fourier Spectral Methods](#label15)<br>\n [Part 4: Solutions](#label16)<br>\n&emsp; [Numerical Linear Algebra](#label17)<br>\n&emsp; [Numerical Analysis](#label18)<br>\n&emsp; [Numerical Differential Equations](#label19)<br>\n"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label0\"></a>\n# Part 1: Numerical Linear Algebra\n<a name=\"label1\"></a>\n## Chapter 1: A Review of Linear Algebra\n**The Hilbert matrix.** The Hilbert matrix $\\mathbf{H}$ is ill-conditioned even for relatively small dimensions. Taking $\\mathbf{H}^{-1}\\mathbf{H}$ should give us the identity matrix.Notice that Python gives explicit warnings that the matrices are ill conditioned."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["M = [la.solve(la.hilbert(n),la.hilbert(n)) for n in [10,15,20,25,50]]\n","fig, ax = plt.subplots(1, 5)\n","for i in range(len(M)): \n","  ax[i].imshow(1-np.abs(M[i]),vmin=0,cmap=\"gray\")\n","plt.tight_layout(); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label2\"></a>\n## Chapter 2: Direct Methods for Linear Systems\n**Gaussian elimination.** The following function implements a naïve Gaussian elimination algorithm for a matrix `A` and vector `b`. We'll verify the code using a random matrix-vector pair. Note that the function `gaussian_elimination(A,b)` overwites both `A` and `b`. Pass array copies of these objects `gaussian_elimination(A.copy(),b.copy())` if you wish to avoid overwriting them."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def gaussian_elimination(A,b):\n","  n = len(A)\n","  for j in range(n):\n","    A[j+1:,j] /= A[j,j]\n","    A[j+1:,j+1:] -= np.outer(A[j+1:,j],A[j,j+1:])\n","  for i in range(1,n):\n","    b[i] = b[i] - A[i,:i]@b[:i]\n","  for i in reversed(range(n)):\n","    b[i] = ( b[i] - A[i,i+1:]@b[i+1:] )/A[i,i]\n","  return(b)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = np.random.rand(8,8); b = np.random.rand(8,1)\n","np.c_[la.solve(A,b),gaussian_elimination(A,b)]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Simplex method.** <a name=\"simplex\"></a>The following three functions (`get_pivot`, `row_reduce`, and `simplex`) implement a naïve simplex method. Let's use them to solve the LP problem \"Find the maximum of the objective function $2x + y + z$ subject to the constraints $2x+ z  \\leq 3$, $4x+y + 2z  \\leq 2$, and $x+y \\leq 1$\" along with the dual LP problem. "]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def get_pivot(tableau):\n","  j = np.argmax(tableau[-1,:-1]>0)\n","  a, b = tableau[:-1,j], tableau[:-1,-1]\n","  k = np.argwhere(a > 0)\n","  i = k[np.argmin(b[k]/a[k])]\n","  return(i,j)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def row_reduce(tableau):\n","  i,j = get_pivot(tableau)\n","  G = tableau[i,:]/tableau[i,j]\n","  tableau -= tableau[:,j].reshape(-1,1)*G\n","  tableau[i,:] = G"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from collections import namedtuple\n","def simplex(c,A,b):\n","  m,n = A.shape\n","  tableau = np.r_[np.c_[A,np.eye(m),b], \\\n","    np.c_[c.T,np.zeros((1,m)),0]]\n","  while (any(tableau[-1,:n]>0)): row_reduce(tableau)\n","  p = np.argwhere(tableau[-1,:n] != 0) \n","  x = np.zeros(n)\n","  for i in p.flatten(): \n","    x[i] = np.dot(tableau[:,i],tableau[:,-1])\n","  z = -tableau[-1,-1]\n","  y = -tableau[-1,range(n,n+m)]\n","  solution = namedtuple(\"solution\",[\"z\",\"x\",\"y\"])       \n","  return(solution(z,x,y))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = np.array([[2,0,1],[4,1,2],[1,1,0]])\n","c = np.array([[2],[1],[1]]);  b = np.array([[3],[2],[1]])\n","solution = simplex(c,A,b)\n","print(\"outcome:\", solution.z)\n","print(\"primal solution:\", solution.x)\n","print(\"dual solution:\", solution.y)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Graph drawing.** The following code draws the dolphin networks of the Doubtful Sound. We'll use dolphin gray (\\#828e84) to color the nodes.<a name=\"dolphins_graph\"></a>"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd, networkx as nx\n","df = pd.read_csv(bucket+'dolphins.csv', header=None)\n","G = nx.from_pandas_edgelist(df,0,1)\n","nx.draw(G,nx.spectral_layout(G),alpha=0.5,node_color='#828e84')\n","plt.axis('equal'); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["nx.draw(G,nx.spring_layout(G),alpha=0.5,node_color='#828e84')\n","plt.axis('equal'); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["nx.draw(G,nx.circular_layout(G),alpha=0.5,node_color='#828e84')\n","plt.axis('equal'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Revised simplex method.** "]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from collections import namedtuple\n","def revised_simplex(c,A,b):\n","  c, A, b = c.astype(float), A.astype(float), b.astype(float)\n","  m, n = A.shape\n","  def xi(i): z=sp.lil_matrix((m,1)); z[i] = 1; return z.tocsr()\n","  N =  np.arange(n); B = np.arange(n,n+m)\n","  A = sp.hstack([sp.csr_matrix(A),sp.identity(m)],format=\"csr\")\n","  ABinv = sp.identity(m).tocsr()\n","  b = sp.csr_matrix(b)\n","  c = sp.vstack([sp.csr_matrix(c),sp.csr_matrix((m,1))])\n","  while True:\n","    J = np.argwhere( (c[N].T-(c[B].T @ ABinv) @ A[:,N]) > 0)\n","    if len(J)==0: break\n","    j = J[0,1]   \n","    q = ABinv @ A[:,N[j]]\n","    k = np.argwhere(q>0)[:,0]\n","    i = k[ np.argmin( ABinv[k,:] @ b/q[k] ) ]\n","    B[i], N[j] = N[j], B[i]\n","    ABinv -=  ((q - xi(i))/q[i][0,0]) @ ABinv[i,:]\n","  i = np.argwhere(B<n)\n","  x = np.zeros(n)\n","  for k in i.flatten(): x[B[k]] = (ABinv[k,:] @ b)[0,0]\n","  y=(c[B].T@ABinv).toarray().flatten()\n","  solution = namedtuple(\"solution\",[\"z\",\"x\",\"y\"])  \n","  return solution(z=x@c[:n],x=x,y=y)"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label3\"></a>\n## Chapter 3: Inconsistent Systems\n**Zipf's law.**  Let's use ordinary least squares to find Zipf's law coefficients for canon of Sherlock Holmes."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd\n","data = pd.read_csv(bucket+'sherlock.csv', sep='\\t', header=None)\n","T = np.array(data[1])\n","n = len(T)\n","A = np.c_[np.ones((n,1)),np.log(np.arange(1,n+1)[:, np.newaxis])]\n","B = np.log(T)[:, np.newaxis]\n","c = la.lstsq(A,B)[0]\n","print('ordinary least squares:\\n'+str(c))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Constrained least squares.** The constrained least squares problem of solving $\\mathbf{Ax} = \\mathbf{b}$ with the constraint condition $\\mathbf{Cx}=\\mathbf{d}$:"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def constrained_lstsq(A,b,C,d):\n","  x = la.solve(np.r_[np.c_[A.T@A,C.T], \n","      np.c_[C,np.zeros((C.shape[0],C.shape[0]))]], np.r_[A.T@b,d] )\n","  return(x[:A.shape[1]])"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Total least squares.**  The function `tls` solves the total least squares problem."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def tls(A,B):\n","  n = A.shape[1]\n","  _,_,V = la.svd(np.c_[A,B])\n","  return(-la.solve(V[n:,n:],V[n:,:n]).T)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = np.array([[2,4],[1,-1],[3,1],[4,-8]]); b = np.array([[1,1,4,1]]).T\n","x_ols = la.lstsq(A,b)[0]\n","x_tls = tls(A,b)\n","print(\"ordinary least squares:\", x_ols.T)\n","print(\"total least squares:\", x_tls.T)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Image compression** Let's use singular value decomposition to compress an image. We'll choose a nominal rank `k = 20` for demonstration. We'll use the Frobenius norm to compute the total pixelwise error in the compressed image. Then, we'll plot out all the singular values for comparison."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import urllib\n","f = urllib.request.urlopen(bucket+'red-fox.jpg')\n","image = plt.imread(f,format='jpg')\n","A = np.dot(image[...,:3], [0.2989, 0.5870, 0.1140])\n","U,sigma,V = la.svd(A)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["k = 20\n","Ak = U[:,:k] @ np.diag(sigma[:k]) @ V[:k,:]\n","la.norm(A-Ak,'fro') - la.norm(sigma[k:])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["plt.imshow(Ak, cmap=plt.get_cmap('gray')); plt.show()\n","r = np.sum(A.shape)/np.prod(A.shape)*range(1,min(A.shape)+1)\n","error = 1 - np.sqrt(np.cumsum(sigma**2))/la.norm(sigma)\n","plt.semilogx(r,error,'.-'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Non-negative matrix factorization (NMF).** A naive implementation of non-negative matrix factorization using multiplicative updates (without a stopping criterion):"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def nmf(X,p=6):\n","  W = np.random.rand(X.shape[0],p)\n","  H = np.random.rand(p,X.shape[1])\n","  for i in range(50):\n","    W = W*(X@H.T)/(W@(H@H.T) + (W==0))\n","    H = H*(W.T@X)/((W.T@W)@H + (H==0))\n","  return (W,H)"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label4\"></a>\n## Chapter 4: Computing Eigenvalues\n**Eigenvalue condition number.** The function `condeig` computes the eigenvalue condition number. Let's use it on a small random matrix."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def condeig(A):\n","  w, vl, vr = la.eig(A, left=True, right=True)\n","  c = 1/np.sum(vl*vr,axis=0)\n","  return(c, vr, w)\n","A = np.random.rand(4,4)\n","condeig(A)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**PageRank.** The following minimal code computes the PageRank of the very  small graph by using the power method over 9 iterations <img src=\"https://raw.githubusercontent.com/nmfsc/data/master/internet_graph.svg\" alt=\"internet graph\" title=\"internet graph\" />"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["H = np.array([[0,0,0,0,1],[1,0,0,0,0], \\\n","      [1,0,0,0,1],[1,0,1,0,0],[0,0,1,1,0]])\n","v = ~np.any(H,0) \n","H = H/(np.sum(H,0)+v)\n","n = len(H) \n","d = 0.85;\n","x = np.ones((n,1))/n\n","for i in range(9):\n","  x = d*(H@x) + d/n*(v@x)  + (1-d)/n\n","x"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label5\"></a>\n## Chapter 6: Fast Fourier Transform\n**Radix-2 FFT.** This chapter introduces several naive functions. The radix-2 FFT algorithm is written as a recursive function `fftx2` and the inverse FFT is written as `ifftx2`.<a name=\"radix2fft\"></a>"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def fftx2(c):\n","  n = len(c)\n","  omega = np.exp(-2j*np.pi/n); \n","  if np.mod(n,2) == 0:\n","    k = np.arange(n/2)\n","    u = fftx2(c[:-1:2])\n","    v = (omega**k)*fftx2(c[1::2])\n","    return( np.concatenate((u+v, u-v)) )\n","  else:\n","    k = np.arange(n)[:,None]\n","    F = omega**(k*k.T);\n","    return( (F @ c))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def ifftx2(y): return(np.conj(fftx2(np.conj(y)))/len(y))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Fast Toeplitz multiplication.** The function `fasttoeplitz` computes the Toeplitz multiplication by padding out a Toeplitz matrix with zeros to make it circulant."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def fasttoeplitz(c,r,x):\n","  n = len(x)\n","  m = (1<<(n-1).bit_length())-n\n","  x1 = np.concatenate((np.pad(c,(0,m)),r[:1:-1]))\n","  x2 = np.pad(x,(0,m+n-1))\n","  return(ifftx2(fftx2(x1)*fftx2(x2))[:n])"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Bluestein algorithm.** The following function implements  the Bluestein algorithm using fast Toeplitz multiplication."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def bluestein(x):\n","  n = len(x)\n","  w = np.exp((1j*np.pi/n)*(np.arange(n)**2))\n","  return(w*fasttoeplitz(conj(w),conj(w),w*x))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Fast Poisson solver.** The following set of functions solves the Poisson equation using a naive fast Poisson solver."]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label6\"></a>\n# Part 2: Numerical Methods for Analysis\n<a name=\"label7\"></a>\n## Chapter 7: Preliminaries\nLet's start with a function that returns a double-precision floating-point representation as a string of bits."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def float_to_bin(x):\n","  if x == 0: return \"0\" * 64\n","  w, sign = (float.hex(x),0) if x > 0 else (float.hex(x)[1:],1)\n","  mantissa, exp = int(w[4:17], 16), int(w[18:])\n","  return \"{}{:011b}{:052b}\".format(sign, exp + 1023, mantissa)\n","float_to_bin(np.pi)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Fast inverse square root.**  The following function implements the circa 1999 Q_rsqrt algorithm to approximate the reciprocal square root of a number."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def Q_rsqrt(x):\n","  x = np.float32(x)\n","  i = x.view(int)\n","  i = 0x5f3759df - i//2 \n","  y = i.view(np.float32)  \n","  return y * (1.5 - (0.5 * x * y * y))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["Q_rsqrt(0.01)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Rump's catastrophic cancellation.**  The answer should be `-0.827396...` What does Python come up with?"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["a = 77617; b = 33096\n","333.75*b**6+a**2*(11*a**2*b**2-b**6-121*b**4-2)+5.5*b**8+a/(2*b)"]},{"cell_type": "markdown", "metadata": {}, "source": ["`NaN` can be used to lift \"pen off paper\" when plotting a series of connected points."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["plt.plot(np.array([1,2,2,2,3]),np.array([1,2,np.nan,1,2]));plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label8\"></a>\n## Chapter 8: Solutions to Nonlinear Equations\nWe start with simple implementation of the bisection method."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def bisection(f,a,b,tolerance):\n","  while abs(b-a)>tolerance:\n","    c = (a+b)/2\n","    if np.sign(f(c))==np.sign(f(a)): a = c \n","    else: b = c\n","  return((a+b)/2)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["bisection(lambda x: np.sin(x),2,4,1e-14)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**The Mandelbrot set**. The following function takes the array `bb` for the lower-left and upper-right corners of the bounding box; `xpix` for the number of horizontal pixels; `n` for the maximum number of iterations; and `s` for the starting value $z^{(0)}$, which for the Mandelbrot set is 0. The function returns a two-dimensional array `M` that counts the number of iterations `k` to escape $\\{z\\in\\C \\mid |z^{(k)}|>2\\}$. We'll then use this function to generate an image."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def mandelbrot(bb,xpix,n,s):\n","  ypix = int(np.round(xpix*(bb[3]-bb[1])/(bb[2]-bb[0])))\n","  M = np.zeros((ypix,xpix))\n","  z = s*np.ones((ypix,xpix),dtype=complex)\n","  c = np.linspace(bb[0],bb[2],xpix).reshape(1,-1) + \\\n","      1j*np.linspace(bb[3],bb[1],ypix).reshape(-1,1)\n","  for k in range(n):\n","    mask = np.abs(z)<2\n","    M[mask] += 1\n","    z[mask] = z[mask]**2 + c[mask]\n","  return(M)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import matplotlib.image as mpimg\n","M = mandelbrot([-0.1710,1.0228,-0.1494,1.0443],800,200,0)\n","mpimg.imsave('mandelbrot.png', -M, cmap='magma')\n","from PIL import Image\n","Image.open('mandelbrot.png')"]},{"cell_type": "markdown", "metadata": {}, "source": ["Imaging the Julia set uses almost identical code. The Mandelbrot set lives in the $c$-domain with a given value $z^{(0)}=0$, and the Julia set lives in the $z$-domain with a given value $c$. So the code for the Julia set requires only swapping the initializations for variables `z` and `c` in the code."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def julia(bb,xpix,n,s):\n","  ypix = int(np.round(xpix*(bb[3]-bb[1])/(bb[2]-bb[0])))\n","  M = np.zeros((ypix,xpix))\n","  z = s*np.ones((ypix,xpix),dtype=complex)\n","  c = np.linspace(bb[0],bb[2],xpix).reshape(1,-1) + \\\n","      1j*np.linspace(bb[3],bb[1],ypix).reshape(-1,1)\n","  c,z = z,c\n","  for k in range(n):\n","    mask = np.abs(z)<2\n","    M[mask] += 1\n","    z[mask] = z[mask]**2 + c[mask]\n","  return(M)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["J = julia([-2,-1,2,1],800,100,-1+0.3j)\n","mpimg.imsave('julia.png', -J, cmap='magma')\n","Image.open('julia.png')"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Homotopy continuation**. The following snippet of code finds a root of $$x^3-3xy^2-1 =0$$\n$$y^3-3x^2y = 0$$ with an initial guess $(x,y) = (1,1)$ using homotopy continuation: "]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","def f(x): return(np.array([x[0]**3-3*x[0]*x[1]**2-1, \n","  x[1]**3-3*x[0]**2*x[1]]))\n","def df(t,x,p): \n","  A = np.array([[3*x[0]**2-3*x[1]**2,-6*x[0]*x[1]],\n","      [-6*x[0]*x[1],3*x[1]**2-3*x[0]**2]])\n","  return(la.solve(-A,p))\n","x0 = np.array([1,1])\n","sol = solve_ivp(df,[0,1],x0,args=(f(x0),))\n","sol.y[:,-1]"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label9\"></a>\n## Chapter 9: Interpolation\n **Splines.** The function `spline_natural` computes the coefficients `m` of a cubic spline with natural boundary conditions through the nodes given by the arrays `x` and `y`. The function `evaluate_spline` returns a set of `n` points along the spline. The final code snippet tests these functions with several randomly selected points.<a name=\"spline_natural\"></a>"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def spline_natural(x,y):\n","  h = np.diff(x)\n","  gamma = 6*np.diff(np.diff(y)/h)\n","  C = [h[:-1],2*(h[:-1]+h[1:])]\n","  m = np.pad(la.solveh_banded(C,gamma),(1, 1))\n","  return(m)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def evaluate_spline(x,y,m,n):\n","  h = np.diff(x)\n","  B = y[:-1] - m[:-1]*h**2/6\n","  A = np.diff(y)/h-h/6*np.diff(m)\n","  X = np.linspace(np.min(x),np.max(x),n+1)    \n","  i = np.array([np.argmin(i>=x)-1 for i in X])\n","  i[-1] = len(x)-2\n","  Y = (m[i]*(x[i+1]-X)**3 + m[i+1]*(X-x[i])**3)/(6*h[i]) \\\n","      + A[i]*(X-x[i]) + B[i]\n","  return(X,Y)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["x = np.linspace(0,1,8); y = np.random.rand(8)\n","m = spline_natural(x,y)\n","X,Y = evaluate_spline(x,y,m,100)\n","plt.plot(x,y,'.',X,Y); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Bézier cirves.** The following function builds a Bernstein matrix. We'll then test the function on a set of points to create a cubic Bézier curve with a set of four randomly selected control points. "]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def bernstein(n,t): \n","  from scipy.special import comb\n","  k = np.arange(n+1)[None,:]\n","  return(comb(n,k)*t**k*(1-t)**(n-k))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 3\n","t = np.linspace(0,1,20)[:,None]\n","p = np.random.rand(n+1,2)\n","z = bernstein(n,t)@p\n","plt.plot(p[:,0],p[:,1],'.-',alpha=0.3);\n","plt.plot(z[:,0],z[:,1]); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label10\"></a>\n## Chapter 10: Approximating Functions\n **Legendre polynomials** We can evaluate a Legendre polynomial of order $n$ using Bonnet's recursion formula."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def legendre(x,n):\n","  if n==0: \n","    return(np.ones_like(x))\n","  elif n==1:\n","    return(x)\n","  else:\n","    return(x*legendre(x,n-1)-1/(4-1/(n-1)**2)*legendre(x,n-2))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["x = np.linspace(-1,1,100)\n","for n in range(5): plt.plot(x,legendre(x,n))\n","plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Chebyshev polynomials** We'll construct a Chebyshev differentiation matrix and use the matrix to solve a few simple problems."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def chebdiff(n):\n","  x = -np.cos(np.linspace(0,np.pi,n))[:,None]\n","  c = np.outer(np.r_[2,np.ones(n-2),2],(-1)**np.arange(n))\n","  D = c/c.T/(x - x.T + np.eye(n))\n","  return D - np.diag(np.sum(D,axis=1)), x"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 15\n","D,x = chebdiff(n)\n","u = np.exp(-4*x**2);\n","plt.plot(x,D@u,'.-')\n","t = np.linspace(-1,1,200);\n","plt.plot(t,-8*t*np.exp(-4*t**2)); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["D[0,:] = np.zeros((1,n)); D[0,0] = 1; u[0] = 2\n","plt.plot(x,la.solve(D,u),'.-'); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 15; k2 = 256\n","D,x = chebdiff(n)\n","L = D@D - k2*np.diag(x.flatten())\n","L[[0,-1],:] = 0; L[0,0] = 1; L[-1,-1] = 1 \n","y = la.solve(L,np.r_[2,[0]*(n-2),1].T)\n","plt.plot(x,y,'o');"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy import special\n","k32 = np.cbrt(k2) \n","ai,_,bi,_ = special.airy([-k32,k32])\n","a = la.solve(np.c_[ai,bi],np.c_[2,1].T)\n","def sol(x): \n","  ai,_,bi,_ = special.airy(k32*x)\n","  return a[0]*ai + a[1]*bi\n","plt.plot(t,sol(t)); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["N = range(6,62,2); e = []\n","for n in N: \n","  D,x = chebdiff(n);\n","  L = D@D - k2*np.diag(x.flatten())\n","  L[[0,-1],:] = 0; L[0,0] = 1; L[-1,-1] = 1 \n","  y = la.solve(L,np.r_[2,[0]*(n-2),1][:,None])\n","  e.append(la.norm(y - sol(x),np.inf))\n","plt.semilogy(N,e,'.-');plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Wavelets**. The function `scaling` returns the scaling function (father wavelet). We can use it to generate the wavelet function (mother wavelet). As an example, we will plot the Daubechies $D_4$ with $c_k = (1+\\sqrt{3},3+\\sqrt{3},3-\\sqrt{3},1-\\sqrt{3}])/4$ and $\\phi(k) = (0,1+\\sqrt{3},1-\\sqrt{3},0)/2$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def scaling(c,z,n):\n","  m = len(c); L = 2**n\n","  phi = np.zeros(2*m*L) \n","  phi[0:m*L:L] = z\n","  for j in range(n):\n","    for i in range(m*2**j):\n","      x = (2*i+1)*2**(n-1-j)            \n","      phi[x] = sum([c[k]*phi[(2*x-k*L)%(2*m*L)] for k in range(m)])\n","  return(np.arange((m-1)*L)/L,phi[:(m-1)*L])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["sqrt3 = np.sqrt(3)\n","c = np.array([1+sqrt3,3+sqrt3,3-sqrt3,1-sqrt3])/4\n","z = np.array([0,1+sqrt3,1-sqrt3,0])/2\n","x,phi = scaling(c,z,8)\n","plt.plot(x,phi); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["psi = np.zeros_like(phi); n = len(c)-1; L = len(phi)//(2*n)\n","for k in range(n):\n","  psi[k*L:(k+n)*L] += (-1)**k*c[n-k]*phi[::2]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**DWT image compression** The following code explores using a discrete wavelet transform along with filtering as means of image compression."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pywt, urllib    \n","def rgb2gray(rgb): return np.dot(rgb[...,:3], [0.2989,0.5870,0.1140])\n","def adjustlevels(x): return 1-np.clip(np.sqrt(np.abs(x)),0,1)\n","f = urllib.request.urlopen(bucket+'laura_square.png')\n","img = rgb2gray(plt.imread(f,format='png'))\n","A = pywt.wavedec2(img,'haar')\n","c, slices = pywt.coeffs_to_array(A)\n","plt.imshow(adjustlevels(c), cmap='gray'); plt.axis('off'); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["level = 0.5\n","c = pywt.threshold(c,level)\n","c = pywt.array_to_coeffs(c,slices,output_format='wavedec2')\n","B = pywt.waverec2(c,'haar')\n","plt.imshow(B, cmap='gray'); plt.axis('off'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Nonlinear least squares approximation**. The function `gauss_newton` solves a nonlinear least squares problem where the Jacobian is approximated numerically using function `jacobian`. The solver is then used to find the parameters for a model logistic regression problem.<a name=\"jacobian\"></a>"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def gauss_newton(x,y,c,f):\n","  r = y - f(c,x)\n","  for j in range(50):\n","    c += la.lstsq(jacobian(f,c,x),r)[0]\n","    r, r0 = y-f(c,x), r\n","    if la.norm(r-r0) < 1e-8: return(c)\n","  print('Gauss-Newton did not converge.')"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def jacobian(f,c,x):\n","  J = np.empty([len(x), len(c)])\n","  n = np.arange(len(c))\n","  for i in n:\n","    J[:,i] = np.imag(f(c+1e-8j*(i==n),x))/1e-8\n","  return(J)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["x = np.r_[np.random.normal(0,1,10),np.random.normal(0,1,10)+2]\n","y = np.r_[np.zeros(10),np.ones(10)]\n","def f(c,x): return(1/(np.exp(-c[0]*x+c[1])+1))\n","c = gauss_newton(x,y,[1,2],f)\n","X = np.linspace(-4,6,100)\n","plt.plot(x,y,'.',X,f(c,X)); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Neural Networks**. Let's use a neural network to find the a function that approximates semi-circular data."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["N = 100; θ = np.linspace(0,np.pi,N)\n","x = np.cos(θ); x = np.c_[np.ones(N),x].T\n","y = np.sin(θ) + 0.05*np.random.randn(1,N)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 20; W1 = np.random.rand(n,2); W2 = np.random.randn(1,n)\n","def ϕ(x): return np.maximum(x,0)\n","def dϕ(x): return (x>0)\n","α = 1e-3"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["for epoch in range(10000):\n","  ŷ = W2 @ ϕ(W1@x)\n","  dLdy = 2*(ŷ-y)\n","  dLdW1 = dϕ(W1@x)* (W2.T@ dLdy) @ x.T   \n","  dLdW2 = dLdy @ ϕ(W1@x).T\n","  W1 -= 0.1 * α * dLdW1 \n","  W2 -= α * dLdW2"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["plt.scatter(x[1,:],y,color='#ff000050')\n","x̂ = np.linspace(-1.2,1.2,200); x̂ = np.c_[np.ones_like(x̂),x̂].T\n","ŷ = W2 @ ϕ(W1@x̂)\n","plt.plot(x̂[1,:],ŷ[0],color='#000000')\n","plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["N = 100; θ = np.linspace(0,np.pi,N)\n","x = np.cos(θ); x = np.c_[np.ones(N),x].T\n","y = np.sin(θ) + 0.05*np.random.randn(1,N)\n","n = 20; W1 = np.random.rand(n,2); W2 = np.random.randn(1,n)\n","def ϕ(x): return 1/(1+np.exp(-x))\n","def dϕ(x): return ϕ(x)*(1-ϕ(x))\n","α = 1e-1\n","for epoch in range(10000):\n","  ŷ = W2 @ ϕ(W1@x)\n","  L = la.norm(ŷ-y)\n","  dLdy = 2*(ŷ-y)/L\n","  dLdW1 = dϕ(W1@x)* (W2.T@ dLdy) @ x.T   \n","  dLdW2 = dLdy @ ϕ(W1@x).T\n","  W1 -= 0.1*α * dLdW1 \n","  W2 -= α * dLdW2 \n","plt.scatter(x[1,:],y,color='#ff000050')\n","x̂ = np.linspace(-1.2,1.2,200); x̂ = np.c_[np.ones_like(x̂),x̂].T\n","ŷ = W2 @ ϕ(W1@x̂)\n","plt.plot(x̂[1,:],ŷ[0],color='#000000');plt.ylim(-0.25,1.25)\n","plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","n = 20; N = 100; \n","θ = tf.linspace(0.0,np.pi,N)\n","x = tf.math.cos(θ); y = tf.math.sin(θ) + 0.05*tf.random.normal([N])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["model = keras.Sequential(\n","  [\n","    layers.Dense(n, input_dim=1, activation='relu'),\n","    layers.Dense(1)\n","  ]\n",")\n","model.compile(loss='mean_squared_error', optimizer='SGD')\n","model.fit(x,y,epochs=2000,verbose=0)\n","ŷ = model.predict(x)\n","plt.plot(x,ŷ,color='#000000'); plt.scatter(x,y,color='#ff000050')"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label11\"></a>\n## Chapter 11: Differentiation and Integration\n Let's compute the coefficients to the third-order approximation to $f'(x)$ using nodes at $x-h$, $x$, $x+h$ and $x+2h$. We can use the function `rats` <a name=\"rats\"></a> to rewrite the floating-point approximation for the coefficients given by `C[1,:]` as fractions"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["d = np.array([-1,0,1,2])[:,None]\n","n = len(d)\n","V = d**np.arange(n) / [np.math.factorial(i) for i in range(n)]\n","C = la.inv(V)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from fractions import Fraction\n","def rats(x): return str(Fraction(x).limit_denominator())\n","[rats(x) for x in C[1,:]]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Richardson extrapolation**. $D(\\phi(x))$ of a finite difference operator $\\phi(x)$.<a name=\"richardson_extrapolation\"></a>"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def richardson(f,x,m,n):\n","  if n==0: return(phi(f,x,2**m)) \n","  return (4**n*richardson(f,x,m,n-1)-richardson(f,x,m-1,n-1))/(4**n-1)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def phi(f,x,n): return((f(x+1/n) - f(x-1/n))/(2/n))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["richardson(lambda x: np.sin(x),0,4,4)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Automatic differentiation**. <a name=\"dualclass\"></a> We can build a minimal working example of forward accumulation automatic differentiation by defining a class and overloading the base operators.  We'll verify the code using the funtion $x + \\sin x$. "]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["class Dual:\n","  def __init__(self, value, deriv=1):\n","    self.value = value\n","    self.deriv = deriv\n","  def __add__(u, v):\n","    return Dual(value(u) + value(v), deriv(u) + deriv(v))\n","  __radd__ = __add__\n","  def __sub__(u, v):\n","    return Dual(value(u) - value(v), deriv(u) - deriv(v))\n","  __rsub__ = __sub__\n","  def __mul__(u, v):\n","    return Dual(value(u)*value(v), \n","        value(v)*deriv(u) + value(u)*deriv(v))\n","  __rmul__ = __mul__\n","  def sin(u):\n","    return Dual(sin(value(u)),cos(value(u))*deriv(u))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def value(x): \n","  return(x.value if isinstance(x, Dual) else x)\n","def deriv(x): \n","  return(x.deriv if isinstance(x, Dual) else 0)\n","def sin(x): return np.sin(x) \n","def cos(x): return np.cos(x) \n","def auto_diff(f,x): \n","    return f(Dual(x)).deriv"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["auto_diff(lambda x: x + sin(x),0)"]},{"cell_type": "markdown", "metadata": {}, "source": ["Now, let's apply the code above to compute the Jacobian of the system $$y_1 = x_1x_2 + \\sin x_2$$$$y_2 = x_1x_2 - \\sin x_2$$ evaluated at $(x_1,x_2) = (2,\\pi)$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["x1 = Dual(2,np.array([1,0]))\n","x2 = Dual(np.pi,np.array([0,1]))\n","y1 = x1*x2 + sin(x2)\n","y2 = x1*x2 - sin(x2)\n","[y1.value,y2.value,y1.deriv,y2.deriv]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Romberg method**. We can use the following trapezoidal quadrature  to make a Romberg method using Richardson extrapolation. We first define the function `trapezoidal` for composite trapezoidal quadrature. By redefine `phi` to equal `trapezoidal` we can simply apply the function `D` that we used to define Richardson extrapolation. We'll verify the code by integrating $\\sin x$ from $0$ to $\\pi/2$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def trapezoidal(f,x,n): \n","  F = f(np.linspace(x[0],x[1],n+1))\n","  return((F[0]/2 + sum(F[1:-1]) + F[-1]/2)*(x[1]-x[0])/n)\n","def phi(f,x,n): return trapezoidal(f,x,n)\n","richardson(lambda x: np.sin(x),[0,np.pi/2],4,4)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Composite trapezoidal method**. Let's examine the convergence rate for the composite trapezoidal rule applied to the function $f(x) = x + (x - x^2)^p$ over the interval $[0,2]$ with $p = 1,2,\\dots,7$. We can do this by finding the loglog slope of the error as a function of subintervals $n$. We find that the error of the trapezoidal rule is $O(n^2)$ when $p=1$, $O(n^4)$ when $p$ is 2 or 3, $O(n^6)$ when $p$ is 4 or 5, and so on."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = np.logspace(1,2,num=10).astype(int)\n","error = np.zeros((10,7))\n","def f(x,p): return(x + x**p*(2-x)**p)\n","for p in range(1,8):\n","  S = trapezoidal(lambda x: f(x,p),(0,2),10**6)\n","  for i in range(len(n)):\n","    Sn = trapezoidal(lambda x: f(x,p),(0,2),n[i])\n","    error[i,p-1] =  abs(Sn - S)/S\n","np.log(error)  \n","A = np.c_[np.log(n),np.ones_like(n)]\n","x = np.log(error)\n","s = np.linalg.lstsq(A,x,rcond=None)[0][0]\n","info = ['{0}: slope={1:0.1f}'.format(k+1,s[k]) for k in range(7)]\n","lines = plt.loglog(n,error)\n","plt.legend(lines, info); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Clenshaw–Curtis quadrature**. applies the trapezoidal rule to a discrete cosine transform (type-1) as a means of numerically evaluating the integral $\\int_{-1}^{1} f(x) \\,\\mathrm{d}x.$  We'll test the integral on the function $f(x) = 8 \\cos x^2$, with an integral of approximately 0.566566"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def clenshaw_curtis(f,n):\n","  x = np.cos(np.pi*np.arange(n+1)/n)\n","  w = np.zeros(n+1); w[0:n+1:2] = 2/(1-np.arange(0,n+1,2)**2)\n","  return(1/n * np.dot(dctI(f(x)), w))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import dct\n","def dctI(f):\n","  g = dct(f,type=1)\n","  return(np.r_[g[0]/2, g[1:-1], g[-1]/2])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["clenshaw_curtis(lambda x: np.cos(8*x**2),20)"]},{"cell_type": "markdown", "metadata": {}, "source": ["A mathematical comment: we could have also  defined a type-1 DCT explicitly in terms of its underlying FFTs if we wanted to crack the black box open just a wee bit more."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import fft\n","def dctI(f):\n","  n = len(f)\n","  g = np.real(fft(np.r_[f, f[n-2:0:-1]]))\n","  return(np.r_[g[0]/2, g[1:n-1], g[n-1]]/2)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Gauss–Legendre quadrature.** We first compute the Legendre weights and nodes and then apply Gauss–Legendre quadrature to compute $$\\int_{-1}^{1} \\cos x \\cdot \\mathrm{e}^{-x^2} \\,\\mathrm{d}x$$ using a nominal number of nodes $n=8$.  Alternatively, we can use the NumPy  function `leggauss` to compute the nodes and weights for Gauss–Legendre quadrature."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def gauss_legendre(n):\n","  a = np.zeros(n)  \n","  b = np.arange(1,n)**2 / (4*np.arange(1,n)**2 - 1)\n","  scaling = 2\n","  nodes, v = la.eigh_tridiagonal(a, np.sqrt(b))\n","  return(nodes, scaling*v[0,:]**2)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 8\n","def f(x): return(np.cos(x)*np.exp(-x**2))\n","nodes, weights = gauss_legendre(n)\n","np.dot(f(nodes), weights)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["nodes, weights = np.polynomial.legendre.leggauss(n)\n","np.dot(f(nodes), weights)"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label12\"></a>\n# Part 3: Numerical Differential Equations\n<a name=\"label13\"></a>\n## Chapter 12: Ordinary Differential Equations\n Let's plot the boundary of the region of absolute stability for BDF2: $$z = \\frac{\\frac{3}{2} r^2 - 2 r + \\frac{1}{2}}{r^2}$$"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["r = np.exp(2j*np.pi*np.linspace(0,1,100))\n","z = (3/2*r**2 - 2*r + 0.5)/r**2\n","plt.plot(z.real,z.imag); plt.axis('equal'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Multistep coefficients**. The function `multistepcoeffs` determines the multistep coefficients for stencil given by `m` and `n`. The function `plotstability` uses these coefficients to plot boundary of the region of absolute stability. We'll test it on the Adams–Moulton method with input `m = [1]` and `n = [0 1 2]`.<a name=\"multistepcoeffs\"></a>"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def multistepcoeffs(m,n):\n","  s = len(m) + len(n)\n","  A = (np.r_[m]+1.0)**np.c_[range(s)]\n","  B = np.c_[range(s)]*(np.r_[n]+1.0)**(np.c_[range(s)]-1)\n","  c = la.solve(-np.c_[A,B],np.ones((s,1))).flatten()\n","  return(np.r_[1,c[:len(m)]], c[len(m):] )"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def plotstability(a,b):\n","  r = np.exp(1j*np.linspace(0,2*np.pi,200))\n","  z = [np.dot(a,r**np.arange(len(a))) / \\\n","       np.dot(b, r**np.arange(len(b))) for r in r]\n","  plt.plot(np.real(z),np.imag(z));\n","  plt.axis('equal'); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = [1]; n = [0,1,2]\n","a,b = multistepcoeffs(m,n)\n","plotstability(a,b)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Recipe for solving an ODE**. The general recipe for solving an ODE is to\n1. Load the module\n1. Set up the parameters\n1. Choose the method\n1. Solve the problem\n1. Present the solution\n\nLet's apply this recipe to solve the pendulum problem $u'' = \\sin u$ with initial conditions $u(0) = \\pi/9$ and $u'(0) = 0$ over $t\\in[0,8\\pi]$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import numpy as np; import matplotlib.pyplot as plt\n","from scipy.integrate import solve_ivp\n","def pndlm(t,u): return u[1],-np.sin(u[0])\n","u0 = [8*np.pi/9,0]; tspan = [0,8*np.pi]\n","mthd = 'RK23'\n","sltn = solve_ivp(pndlm,tspan,u0,method=mthd)\n","plt.plot(sltn.t,sltn.y[0,:],'.-')\n","plt.plot(sltn.t,sltn.y[1,:],'.-')\n","plt.legend(labels=['θ','ω']); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["The values of `sltn.t` are those determined and used for adaptive time stepping. Higher-order methods such as `DOP853` that use smoother interpolating polynomials produce rougher (though still accurate) plots than lower-order methods such as `RK23`:"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["mthd = 'DOP853'\n","sltn = solve_ivp(pndlm,tspan,u0,method=mthd)\n","plt.plot(sltn.t,sltn.y[0,:],'.-')\n","plt.plot(sltn.t,sltn.y[1,:],'.-')\n","plt.legend(labels=['θ','ω']); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["We can request a continuous solution by setting `dense_output=True`.  In this case, `solve_ivp` returns an additional field `sol` that we can think of as a function of the independent variable:"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["sltn = solve_ivp(pndlm,tspan,u0,method=mthd,dense_output=True)\n","t = np.linspace(tspan[0],tspan[1],200)\n","y = sltn.sol(t)\n","plt.plot(t,y[0],t,y[1])\n","plt.legend(labels=['θ','ω']); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label14\"></a>\n## Chapter 13: Parabolic Equations\n**Heat equation using the backward Euler method**. Let's solve the heat equation using the backward Euler method with initial conditions given by a rectangular function and absorbing boundary conditions."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import timeit\n","start_time = timeit.default_timer()\n","dx = .01; dt = .01; L = 2; c = dt/dx**2; uL = 0; uR = 0;\n","x = np.arange(-L,L,dx); n = len(x) \n","u = (abs(x)<1)\n","u[0] += 2*c*uL; u[n-1] += 2*c*uR; \n","D = np.tile(np.array([[-c,1+2*c,-c]]).T,(1,n))\n","D[0,1] = 0; D[2,n-2] = 0\n","for i in range(20):\n","  u = la.solve_banded((1, 1), D, u)\n","elapsed_time = timeit.default_timer() - start_time\n","plt.plot(x,u);plt.show()\n","print(\"elapsed time = \"+str(elapsed_time))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Heat equation using the Crank–Nicolson method**. Let's solve the heat equation again using the Crank–Nicolson method with initial conditions given by a rectangular function. This time we'll use reflecting boundary conditions. Notice how the high-frequency information does not decay as it did when using the backward Euler method."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["dx = .01; dt = .01; L = 2; λ = dt/dx**2\n","x = np.arange(-L,L,dx); n = len(x) \n","u = (abs(x)<1)\n","diagonals = [np.ones(n-1), -2*np.ones(n), np.ones(n-1)]\n","D = sp.diags(diagonals, [-1,0,1], format='csr')\n","D[0,1] *= 2; D[-1,-2] *= 2\n","A = 2*sp.identity(n) + λ*D \n","B = 2*sp.identity(n) - λ*D \n","for i in range(20):\n","  u = sp.linalg.spsolve(B,A@u)\n","plt.plot(x,u); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Porous medium equation**. We'll now solve the porous medium equation $u_t = (u^2u_x)_x$ using an adaptive-step BDF routine."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","n = 400; L = 2; x,dx = np.linspace(-L,L,n,retstep=True)\n","def m(u): return u**2\n","def Du(t,u): \n","  return(np.r_[0,np.diff(m((u[:-1]+u[1:])/2)*np.diff(u))/dx**2,0])\n","u0 = (abs(x)<1)\n","sol = solve_ivp(Du, [0,2], u0, method='LSODA',\\\n","  lband=1,uband=1,dense_output=True)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from ipywidgets import interactive\n","def anim(t=0):\n","  plt.fill_between(x,sol.sol(t),color='#ff9999');\n","  plt.ylim(0,1);plt.show()\n","interactive(anim, t = (0,2,0.01))"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label15\"></a>\n## Chapter 16: Fourier Spectral Methods\n**Heat equation**. The formal solution to the heat equation is $$u(t,x) = \\mathrm{F}^{-1}\\left[  \\mathrm{e}^{-\\xi^2 t}  \\mathrm{F} u(0,x) \\right].$$"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from numpy.fft import fft,ifft, fftfreq\n","n = 256; ℓ = 4\n","k2 = (fftfreq(n,1/n)*(2*np.pi/L))**2\n","def u(t,u0): return np.real(ifft(np.exp(-k2*t)*fft(u0)))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["x = np.linspace(-L/2,L/2,n,endpoint=False)\n","u0 = (np.abs(x)<1)\n","plt.plot(x,u(0.1,u0)); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Incompressible Navier–Stokes equation**. Let's solve the heat equation using the backward Euler method with initial conditions given by a rectangular function and absorbing boundary conditions."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from numpy.fft import fft2,ifft2,fftfreq\n","def cdiff(Q,step=1): return Q-np.roll(Q,step,0)\n","def flux(Q,c): return c*cdiff(Q,1) - \\\n","  0.5*c*(1-c)*(cdiff(Q,1)+cdiff(Q,-1))\n","def H(u,v,ikx,iky): return -ikx*fft2(ifft2(u)**2) + \\\n","  -iky*fft2(ifft2(u)*ifft2(v))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["L, n, dt, e = 2, 128, 0.001, 0.001; dx = L/n \n","x = np.linspace(dx,L,n)[None,:]; y = x.T\n","q = 0.5*(1+np.tanh(10*(1-np.abs(L/2 - y)/(L/4))))\n","Q = np.tile(q, (1,n))\n","u = Q*(1+0.5*np.sin(L*np.pi*x))  \n","v = np.zeros_like(u) \n","u,v = fft2(u),fft2(v)\n","us,vs = u,v\n","ikx = (1j*fftfreq(n)*n*(2*np.pi/L))[None,:]\n","iky = ikx.T\n","k2 = ikx**2+iky**2\n","Hx, Hy = H(u,v,ikx,iky), H(v,u,iky,ikx)  \n","M1 = 1/dt + (e/2)*k2\n","M2 = 1/dt - (e/2)*k2"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["for i in range(1200):\n","  Q -= flux(Q,(dt/dx)*np.real(ifft2(v))) + \\\n","    flux(Q.T,(dt/dx)*np.real(ifft2(u)).T).T\n","  Hxo, Hyo = Hx, Hy\n","  Hx, Hy = H(u,v,ikx,iky), H(v,u,iky,ikx)           \n","  us = u - us + (1.5*Hx - 0.5*Hxo + M1*u)/M2\n","  vs = v - vs + (1.5*Hy - 0.5*Hyo + M1*v)/M2\n","  phi = (ikx*us + iky*vs)/(k2+(k2==0)) \n","  u, v =  us - ikx*phi, vs - iky*phi\n","plt.imshow(Q,'seismic'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label16\"></a>\n# Part 4: Solutions\n<a name=\"label17\"></a>\n## Numerical Linear Algebra\n**1.4. Invertibility of random (0,1) matrices.** The number of invertible $n\\times n$ (0,1) matrices is known for $n$ up to 8. (See the [On-Line Encyclopedia of Integer Sequences](http://oeis.org/A055165).) We'll approximate the ratio of invertible matrices by checking the determinants of randomly drawn ones. "]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["N = 10000; n = np.zeros(20)\n","def mat_01(d): return(np.random.choice((0,1),size=(d,d)))\n","for d in range(20):\n","  n[d] = sum([np.linalg.det(mat_01(d))!=0 for i in range(N)])\n","plt.plot(range(1,21),n/N,'.-'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**2.3. Naive algorithm for the determinant.** The determinant of  matrix $\\mathbf{A}$ is given by the product of the elements along the diagonal of $\\mathbf{U}$ multiplied by the parity of the permutation matrix $\\mathbf{P}$ from the LU decomposition $\\mathbf{PLU} = \\mathbf{A}$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def det(A):\n","  P,L,U = la.lu(A)\n","  s = 1\n","  for i in range(len(P)):\n","    try:\n","      m = np.argwhere(P[i+1:,i]).item(0)+1\n","      P[[i,i+m],:] = P[[i+m,i],:] \n","      s *= -1\n","    except:\n","      pass\n","  return(s * np.prod(np.diagonal(U)))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = np.random.rand(20,20)\n","det(A) - la.det(A)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**2.4. Reverse Cuthill–McKee algorithm.** The following function implements a naive reverse Cuthill–McKee algorithm  for symmetric matrices. We'll verify the algorithm by applying it to a sparse, random (0,1) matrix."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def rcuthillmckee(A):\n","  r = np.argsort(np.bincount(A.nonzero()[0]))\n","  while r.size:\n","    q = np.atleast_1d(r[0])\n","    r = np.delete(r,0)\n","    while q.size:\n","      try: p = np.append(p,q[0])\n","      except: p = np.atleast_1d(q[0])\n","      k = sp.find(A[q[0],r])[1]\n","      q = np.append(q[1:],r[k])\n","      r = np.delete(r,k)\n","  return(np.flip(p))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = sp.random(1000,1000,0.001); A += A.T\n","p = rcuthillmckee(A)\n","fig, (ax1, ax2) = plt.subplots(1, 2)\n","ax1.spy(A,ms=1); ax2.spy(A[p[:,None],p],ms=1)\n","plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**2.5. Dolphins of Doubtful Sound.**  We'll reuse the code [above](#dolphins_graph) used to draw the original graph of the dolphins."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd, networkx as nx\n","df = pd.read_csv(bucket+'dolphins.csv', header=None)\n","G = nx.from_pandas_edgelist(df,0,1)\n","nx.draw(G,nx.circular_layout(G),alpha=0.5,node_color='#828e84')\n","plt.axis('equal'); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = nx.adjacency_matrix(G)\n","p = rcuthillmckee(A)\n","A = A[p[:,None],p]\n","G = nx.from_scipy_sparse_matrix(A)\n","nx.draw(G,nx.circular_layout(G),alpha=0.5,node_color='#828e84')\n","plt.axis('equal'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**2.6. Stigler diet problem.** Let's solve the Stigler diet problem. We'll use the function naïve [`simplex`](#simplex) defined above."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def get_pivot(tableau):\n","  j = np.argmax(tableau[-1,:-1]>0)\n","  a, b = tableau[:-1,j], tableau[:-1,-1]\n","  k = np.argwhere(a > 0)\n","  i = k[np.argmin(b[k]/a[k])]\n","  return(i,j)\n","\n","def row_reduce(tableau):\n","  i,j = get_pivot(tableau)\n","  G = tableau[i,:]/tableau[i,j]\n","  tableau -= tableau[:,j].reshape(-1,1)*G\n","  tableau[i,:] = G\n","\n","from collections import namedtuple\n","def simplex(c,A,b):\n","  m,n = A.shape\n","  tableau = np.r_[np.c_[A,np.eye(m),b], \\\n","    np.c_[c.T,np.zeros((1,m)),0]]\n","  while (any(tableau[-1,:n]>0)): row_reduce(tableau)\n","  p = np.argwhere(tableau[-1,:n] != 0) \n","  x = np.zeros(n)\n","  for i in p.flatten(): \n","    x[i] = np.dot(tableau[:,i],tableau[:,-1])\n","  z = -tableau[-1,-1]\n","  y = -tableau[-1,range(n,n+m)]\n","  solution = namedtuple(\"solution\",[\"z\",\"x\",\"y\"])       \n","  return(solution(z,x,y))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd\n","diet = pd.read_csv(bucket+'diet.csv')\n","A = diet.values[1:,3:].T\n","b = diet.values[0,3:][:,None]\n","c = np.ones(((A.shape)[1],1))\n","food = diet.values[1:,0]\n","solution = simplex(b,A.T,c)\n","print(\"value: \", solution.z)\n","i = np.argwhere(solution.y!=0).flatten()\n","print(\"foods: \", food[i])"]},{"cell_type": "markdown", "metadata": {}, "source": ["In practice, we can use `scipy.optimize.linprog`."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy import optimize \n","solution = optimize.linprog(c,-A,-b,method='revised simplex')\n","solution.fun, food[np.where(solution.x>1e-12)]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**2.7. Six degrees of Kevin Bacon** Let's determine the shortest path between two actors along with their connecting movies. We'll first define helper functions `get_names`<a href=\"get_names\"></a> and `get_adjacency_matrix`<a href=\"get_adjacency_matrix\"></a>. Then we'll build an biadjacency matrix $\\mathbf{B"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def get_names(filename):\n","  return np.genfromtxt(bucket+filename+'.txt',delimiter='\\n',\\\n","    dtype=\"str\",encoding=\"utf8\").tolist()\n","def get_adjacency_matrix(filename):\n","  i = np.genfromtxt(bucket+filename+'.csv',delimiter=',',dtype=int)\n","  return sp.csr_matrix((np.ones_like(i[:,0]), (i[:,0]-1,i[:,1]-1)))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["actors = get_names(\"actors\")\n","movies = get_names(\"movies\")\n","B = get_adjacency_matrix(\"actor-movie\")\n","A = sp.bmat([[None,B.T],[B,None]],format='csr')\n","actormovie = np.r_[actors,movies]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def findpath(A,a,b):\n","  p = -np.ones(A.shape[1],dtype=np.int64)\n","  q = [a]; p[a] = -9999; i = 0\n","  while i<len(q):\n","    k = sp.find(A[q[i],:])[1]\n","    k = k[p[k]==-1]\n","    q.extend(k)\n","    p[k] = q[i]; i += 1\n","    if any(k==b): return(backtrack(p,b))\n","  display(\"No path.\")"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def backtrack(p,b):\n","  s = [b]; i = p[b]\n","  while i != -9999: s.append(i); i = p[i]\n","  return s[::-1]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["a = actors.index(\"Bruce Lee\"); b = actors.index(\"Tommy Wiseau\")\n","actormovie[findpath(A,a,b)].tolist()"]},{"cell_type": "markdown", "metadata": {}, "source": ["In practice, we can use the `shortest_path` function from the scipy.sparse.csgraph library or networkx library"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["a = actors.index(\"Bruce Lee\"); b = actors.index(\"Tommy Wiseau\")\n","_,p = sp.csgraph.shortest_path(A,indices=a,return_predecessors=True)\n","actormovie[backtrack(p,b)].tolist()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import networkx as nx\n","G = nx.from_scipy_sparse_matrix(A)\n","a = actors.index(\"Emma Watson\"); b = actors.index(\"Kevin Bacon\")\n","i = nx.shortest_path(G,a,b)\n","actormovie[i].tolist()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**3.4. NIST Filippelli problem.** The Filippelli dataset was contrived by NIST to benchmark linear regression software. The Filippelli problem consists of fitting an 10th degree polynomial to the data set⁠—a rather ill-conditioned problem. We first need to download the data. Then we'll define three methods for solving the Vandermonde problem: the normal equation, QR decomposition, and the pseudoinverse."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd\n","df = pd.read_csv(bucket+'filip.csv',header=None)\n","y,x = np.array(df[0]),np.array(df[1])\n","coef = pd.read_csv(bucket+'filip-coeffs.csv',header=None)\n","beta = np.array(coef[0])[None,:]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def solve_filip(x,y):\n","  V = vandermonde(x,11)\n","  Q,R = la.qr(V,mode='economic') \n","  c = np.zeros((3,11),float)\n","  c[0,:] = la.solve(V.T@V,V.T@y)\n","  c[1,:] = la.solve(R,Q.T@y)\n","  c[2,:] = la.pinv(V,1e-14)@y\n","  r = [la.norm(V@c[i,:].T-y) for i in range(3)]\n","  return(c,r)\n","def build_poly(c,x): \n","  return vandermonde(x,len(c))@c\n","def vandermonde(x,n): \n","  return np.vander(x,n,increasing=True)"]},{"cell_type": "markdown", "metadata": {}, "source": ["Now, let's solve the problem and plot the results. Let's also list the coefficients from each method alongside the official NIST coefficients. What do you notice about the coefficients? What method performs the best?"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["b,r = solve_filip(x,y)\n","X = np.linspace(min(x),max(x),200)\n","b = np.r_[b,beta]\n","plt.scatter(x,y,color='#0000ff40')\n","for i in range(4): \n","  plt.plot(X,build_poly(b[i],X))\n","plt.ylim(0.7,0.95);plt.show()\n","coef.assign(β1=b[0], β2=b[1], β3=b[2])"]},{"cell_type": "markdown", "metadata": {}, "source": ["What makes the Filippelli problem a difficult problem is that the condition number of the system is huge. We can reduce the condition number by first standardizing the data before using it⁠—i.e., subtracting the mean and dividing by the standard deviation. Look at the difference in condition numbers of the Vandermonde matrix before and after standardizing the data."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def zscore(X,x): return((X - x.mean())/x.std())\n","k1 = np.linalg.cond(vandermonde(x,11))\n","k2 = np.linalg.cond(vandermonde(zscore(x,x),11))\n","print(\"Condition numbers of the Vandermonde matrix:\")\n","print(\"{:e}\".format(k1))\n","print(\"{:e}\".format(k2))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["c,r = solve_filip(zscore(x,x),zscore(y,y))\n","plt.scatter(x,y,color='#0000ff40')\n","for i in range(3):\n","  Y = build_poly(c[i],zscore(X,x))*y.std() + y.mean()\n","  plt.plot(X, Y)\n","plt.show()\n","la.norm(c[0]-c[1]),la.norm(c[0]-c[2])"]},{"cell_type": "markdown", "metadata": {}, "source": ["**3.5. Modeling daily temperatures** We'll use $u(t) = c_1 \\sin(2\\pi t) + c_2 \\cos(2\\pi t) + c_3$ to model the daily temperatures using data recorded in Washington, DC. between 1967 and 1971."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd\n","df = pd.read_csv(bucket+'dailytemps.csv')\n","t = pd.to_datetime(df[\"date\"]).values\n","day = (t - t[0])/np.timedelta64(365, 'D')\n","u = df[\"temperature\"].values[:,None]\n","def tempsmodel(t): return np.c_[np.sin(2*np.pi*t),\\\n","  np.cos(2*np.pi*t), np.ones_like(t)]\n","c = la.lstsq(tempsmodel(day),u)[0]\n","plt.plot(day,u,'o',color='#0000ff15');\n","plt.plot(day,tempsmodel(day)@c,'k'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**3.6. Image recognition** We'll practice  identifying handwritten digits using the EMNIST database.  The [NIST website](https://www.nist.gov/itl/products-and-services/emnist-dataset) provides a version formatted as a Matlab MAT-file. The full container from the NIST website is quite large (around 700MB) and we only need a smaller 20MB set, so I've put a copy of the just the emnist-nist file on GitHub at this [link](https://github.com/nmfsc/data/raw/master/emnist-mnist.mat)."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from keras.datasets import mnist\n","import scipy.sparse.linalg\n","(image_train,label_train),(image_test,label_test) = mnist.load_data()\n","image_train = np.reshape(image_train, (60000,-1));\n","V = np.zeros((12,784,10))\n","for i in range(10):\n","  D = sp.csr_matrix(image_train[label_train==i], dtype=float)\n","  U,S,V[:,:,i] = sp.linalg.svds(D,12)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import matplotlib.pyplot as plt\n","pix = [V[i,:,3].reshape(28,28) for i in range(11,-1,-1)]\n","plt.imshow(np.hstack(pix), cmap=\"gray\")\n","plt.axis('off'); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["image_test = np.reshape(image_test, (10000,-1));\n","r = np.zeros((10,10000))\n","for i in range(10):\n","  q = V[:,:,i].T@(V[:,:,i] @ image_test.T) -  image_test.T\n","  r[i,:]  = np.sum(q**2,axis=0)\n","prediction = np.argmin(r,axis=0)\n","confusion = np.zeros((10,10)).astype(int)\n","for i in range(10): \n","  confusion[i,:] = np.bincount(prediction[label_test==i],minlength=10)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd\n","pd.DataFrame(confusion)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import requests\n","from scipy import io\n","r = requests.get(bucket+\"emnist-mnist.mat\")\n","with open('emnist-mnist.mat', 'wb') as local_file:\n","    local_file.write(r.content)\n","data = io.loadmat('emnist-mnist.mat')\n","image_train = data['dataset'][0,0]['train'][0,0]['images']\n","label_train = data['dataset'][0,0]['train'][0,0]['labels'].flatten()\n","image_test = data['dataset'][0,0]['test'][0,0]['images']\n","label_test = data['dataset'][0,0]['test'][0,0]['labels'].flatten()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**3.8. Actor similarity model** We use SVD to find a lower-dimensional subspace relating actors and genres. Then we find the closest actors in that subspace using cosine similarity. We use the functions [`get_names`](#get_names) and  [`get_adjacency_matrix`](#get_adjacency_matrix) developed earlier."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["actors = get_names(\"actors\")\n","genres = get_names(\"genres\")\n","A = get_adjacency_matrix(\"movie-genre\"); A /= A.sum(axis=0)\n","B = get_adjacency_matrix(\"actor-movie\")"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["U,S,Vt = sp.linalg.svds(A@B, 12)\n","Q = Vt/np.sqrt((Vt**2).sum(axis=0))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["q = Q[:,actors.index(\"Steve Martin\")]                         \n","z = Q.T@q\n","r = np.argsort(-z)\n","[actors[i] for i in r[:10]]"]},{"cell_type": "markdown", "metadata": {}, "source": ["Let's also see Steve Martin's genre signature."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["p = (U*S)@q\n","r = np.argsort(-p)\n","[(genres[i],p[i]/p.sum()) for i in r[:10]]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**3.9. Multilateration** We use ordinary least squares and total least squares to solve a multulateration problem."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["xyt = np.array([[3,3,12],[1,15,14],[10,2,13],[12,15,13],[0,11,12]])\n","reference = xyt[0,:];  xyt = xyt - reference\n","A = np.array([2,2,-2])*xyt\n","b = (xyt**2)@np.array([[1],[1],[-1]])\n","x_ols = la.lstsq(A,b)[0] + reference[:,None]\n","x_tls = tls(A,b) + reference[:,None]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**4.2. Girko's circular law** Let's plot out the eigenvalues of a few thousand normal random matrices of size $n$ to get a probability distribution in the complex plane.  What do you notice?"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 8\n","E = [la.eigvals(np.random.randn(n,n)) for i in range(2500)]\n","E = np.concatenate(E)\n","plt.plot(E.real, E.imag,'.',c='#0000ff10',mec='none') \n","plt.axis('equal'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**4.4. Rayleigh quotient iteration** Let's define a function that finds an eigenvalue $\\lambda$ and eigenvector $\\mathbf{x}$ of a matrix. We'll pick a random initial guess for $\\mathbf{x}$ unless one is given. We'll then verify the algorithm on a symmetric matrix. Rayleigh quotient iteration works on general classes of matrices, but often has difficulty converging when matrices get large or far from symmetric⁠—i.e., when eigenvectors get closer together."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def rayleigh(A,x=[]):\n","  n = len(A)\n","  if x==[]: x = np.random.randn(n,1)\n","  while True:\n","    x = x/la.norm(x)\n","    rho = x.T @ A @ x\n","    M = A - rho*np.eye(n)\n","    if abs(la.det(M))<1e-10:\n","      return(rho,x)\n","    x = la.solve(M,x)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**4.5. Implicit QR method** We'll define a function that computes all the eigenvalues of a matrix using the implicit QR method. We'll then verify the algorithm on a matrix with known eigenvalues."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def implicitqr(A):\n","  tolerance = 1e-12\n","  n = len(A)\n","  H = la.hessenberg(A)\n","  while True:\n","    if abs(H[n-1,n-2]) < tolerance:\n","      n -= 1\n","      if n<2: return(np.diag(H))\n","    Q,_ = la.qr([[H[0,0]-H[n-1,n-1]], [H[1,0]]])\n","    H[:2,:n] = Q @ H[:2,:n]\n","    H[:n,:2] = H[:n,:2] @ Q.T\n","    for i in range(1,n-1):\n","      Q,_ = la.qr([[H[i,i-1]], [H[i+1,i-1]]])\n","      H[i:i+2,:n] = Q @ H[i:i+2,:n]\n","      H[:n,i:i+2] = H[:n,i:i+2] @ Q.T"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 20; S = np.random.randn(n,n); \n","D = np.diag(np.arange(1,n+1)); A = S@D@la.inv(S)\n","implicitqr(A)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**4.6. Randomized SVD** We define a method that implements randomized SVD. The idea is to start with a set of $k$ random vectors and perform a few steps of the simple QR method to generate a $k$-dimensional subspace that is closer to the space of dominant singular values. Then, we perform SVD on that subspace. We may not get the exact singular values, but it we just need a good guess and the matrix is huge, this method can be significantly faster than SVD or sparse SVD."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def randomizedsvd(A,k):\n","  Z = np.random.rand(A.shape[1],k)\n","  Q,R = la.qr(A@Z, mode='economic')\n","  for i in range(4):\n","    Q,R = la.qr(A.T @ Q, mode='economic')\n","    Q,R = la.qr(A @ Q, mode='economic')\n","  W,S,V = la.svd(Q.T @ A,full_matrices=False)\n","  U = Q @ W\n","  return(U,S,V)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import timeit\n","n = 1000; k = 10\n","A = np.random.randn(n,n)\n","print('Random SVD singular values and elapsed time:')\n","start_time = timeit.default_timer()\n","display(randomizedsvd(A,k)[1])\n","display(timeit.default_timer() - start_time)\n","print('Regular SVD singular values and elapsed time:')\n","start_time = timeit.default_timer()\n","display(la.svd(A)[1][:k])\n","display(timeit.default_timer() - start_time)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**4.8. Hollywood eigenvector centrality** We'll use eigenvector centrality to determine who's at the center of Hollywood. We use the functions [`get_names`](#get_names) and  [`get_adjacency_matrix`](#get_adjacency_matrix) developed earlier."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["actors = get_names(\"actors\")\n","B = get_adjacency_matrix(\"actor-movie\")\n","r,c = (B.T@B).nonzero()\n","M = sp.csr_matrix((np.ones(len(r)),(r,c)))\n","v = np.ones(M.shape[0])\n","for k in range(10):\n","  v = M@v; v /= np.linalg.norm(v)\n","r = np.argsort(-v)\n","[actors[i] for i in r[:10]]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**5.3. 3D Poisson equation** Let's compare the Jacobi, Gauss-Seidel, SOR, and conjugate gradient methods in solving the Poisson equation in the unit cube."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 50; xi = np.arange(1,n+1)/(n+1); dx = 1/(n+1)\n","I = sp.identity(n)\n","D = sp.diags([1, -2, 1], [-1, 0, 1], shape=(n, n))\n","A = ( sp.kron(sp.kron(D,I),I) + sp.kron(I,sp.kron(D,I)) +\n","  sp.kron(I,sp.kron(I,D)) )/dx**2\n","f = np.array([(x-x**2)*(y-y**2) + (x-x**2)*(z-z**2)+(y-y**2)*(z-z**2) \n","    for x in xi for y in xi for z in xi])\n","ue = np.array([(x-x**2)*(y-y**2)*(z-z**2)/2 \n","    for x in xi for y in xi for z in xi])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def stationary(A,b,w=0,n=400):\n","  e = []; u = np.zeros_like(b)\n","  P = sp.diags(A.diagonal(),0) + w*sp.tril(A,-1)\n","  for i in range(n):\n","    u += sp.linalg.spsolve(P,b-A@u,'NATURAL')\n","    e = np.append(e,la.norm(u - ue,1))\n","  return(e)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def conjugategradient(A,b,n=400):\n","  e = []; u = np.zeros_like(b)\n","  r = b - A@u; p = np.copy(r)\n","  for i in range(n):\n","    Ap = A@p\n","    α = np.dot(r,p)/np.dot(Ap,p)\n","    u += α*p; r -= α*Ap\n","    β = np.dot(r,Ap)/np.dot(Ap,p)\n","    p = r - β*p\n","    e = np.append(e,la.norm(u - ue,1))\n","  return(e)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["e = np.zeros((400,4))\n","e[:,0] = stationary(A,-f,0)\n","e[:,1] = stationary(A,-f,1)\n","e[:,2] = stationary(A,-f,1.9)\n","e[:,3] = conjugategradient(A,-f)\n","plt.semilogy(e); \n","plt.legend([\"Jacobi\",\"Gauss-Seidel\",\"SOR\",\"Conj. Grad.\"]); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**6.1. Radix-3 FFT** The radix-3 FFT is similar to the [radix-2 FFT](#radix2fft). We'll verify that the code is correct by comparing it with a built-in FFT"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def fftx3(c):\n","  n = len(c)\n","  omega = np.exp(-2j*np.pi/n); \n","  if np.mod(n,3) == 0:\n","    k = np.arange(n/3)\n","    u = np.stack((fftx3(c[:-2:3]),\\\n","        omega**k * fftx3(c[1:-1:3]),\\\n","        omega**(2*k) * fftx3(c[2::3])))\n","    F = np.exp(-2j*np.pi/3)** \\\n","        np.array([[0,0,0],[0,1,2],[0,2,4]])    \n","    return((F @ u).flatten() )\n","  else:\n","    k = np.arange(n)[:,None]\n","    F = omega**(k*k.T);\n","    return( (F @ c))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import fft\n","v = np.random.rand(24)\n","np.c_[fft(v),fftx3(v)]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**6.2. Fast multiplication** The following function uses FFTs to multiply two large integers (inputted as strings). We'll verify that the algorithm works by multplying the [RSA-129 factors](https://en.wikipedia.org/wiki/RSA_numbers#RSA-129).  Python uses arbitrary-precision integers, so we can simply multiply the numbers directly."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def multiply(p_,q_):\n","  from scipy.signal import fftconvolve\n","  p = np.flip(np.array([int(i) for i in list(p_)]))\n","  q = np.flip(np.array([int(i) for i in list(q_)]))\n","  pq = np.rint(fftconvolve(p,q)).astype(int)\n","  pq = np.r_[pq,0]\n","  carry = pq//10\n","  while (np.any(carry)):\n","    pq -= carry*10\n","    pq[1:] += carry[:-1]\n","    carry = pq//10\n","  return(''.join([str(i) for i in np.flip(pq)]).lstrip('0'))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["display(32769132993266709549961988190834461413177642967992942539798288533 *\\\n","3490529510847650949147849619903898133417764638493387843990820577)\n","multiply('32769132993266709549961988190834461413177642967992942539798288533',\\\n","'3490529510847650949147849619903898133417764638493387843990820577')"]},{"cell_type": "markdown", "metadata": {}, "source": ["**6.3. Fast discrete cosine transform**"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import fft,ifft\n","def dct(f):\n","  n = f.shape[0]\n","  w = np.exp(-0.5j*np.pi*np.arange(n)/n).reshape(-1,1)\n","  i = [*range(0,n,2),*range(n-1-n%2,0,-2)]\n","  return(np.real(w*fft(f[i,:],axis=0)))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def idct(f):\n","  n = f.shape[0]\n","  w = np.exp(-0.5j*np.pi*np.arange(n)/n).reshape(-1,1)\n","  i = [n-(i+1)//2 if i%2 else i//2 for i in range(n)]\n","  f[0,:] = f[0,:]/2\n","  return(np.real(ifft(f/w,axis=0))[i,:]*2)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def dct2(f): return(dct(dct(f.T).T))\n","def idct2(f): return(idct(idct(f.T).T))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import urllib\n","f = urllib.request.urlopen(bucket+'red-fox.jpg')\n","image = plt.imread(f,format='jpg')\n","A = np.dot(image[...,:3], [0.2989, 0.5870, 0.1140])\n","B = dct2(A)[:50,:50]\n","C = idct2(np.pad(B,((0,A.shape[0]-50),(0,A.shape[1]-50))))\n","plt.figure(figsize=(8, 6), dpi=160)\n","plt.imshow(np.c_[A,C], cmap=plt.get_cmap('gray'))\n","plt.axis('off'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label18\"></a>\n## Numerical Analysis\n**8.9. Solving a nonlinear system.** We'll solve $$(x^2+y^2)^2 - 2 (x^2 - y^2) =0$$ $$(x^2+y^2 -1)^3-x^2y^3 = 0$$ using homotopy continuation and Newton's method."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def f(x,y): return(np.array([(x**2+y**2)**2-2*(x**2-y**2),\n","  (x**2+y**2-1)**3-x**2*y**3]))\n","def df(x,y): return(np.array([ \\\n","  [4*x*(x**2+y**2-1),  4*y*(x**2+y**2+1)],\n","  [6*x*(x**2+y**2-1)**2-2*x*y**3, \\\n","   6*y*(x**2+y**2-1)**2-3*x**2*y**2]]))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def homotopy(f,df,x):\n","  from scipy.integrate import solve_ivp\n","  def dxdt(t,x,p): return(la.solve(-df(x[0],x[1]),p))\n","  sol = solve_ivp(dxdt,[0,1],x,args=(f(x[0],x[1]),))\n","  return(sol.y[:,-1])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def newton(f,df,x):\n","  for i in range(100):\n","    dx = -la.solve(df(x[0],x[1]),f(x[0],x[1]))\n","    x += dx\n","    if (la.norm(dx) < 1e-8): return(x)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["x0 = [-1,-1]\n","print(homotopy(f,df,x0))\n","print(newton(f,df,x0))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**9.2. Periodic parametric splines.** We modify the code [`spline_natural`](#spline_natural) (above) to  make a generate a spine with periodic boundary conditions. The function `evaluate_spline` is duplicated from the code above."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def spline_periodic(x,y):\n","  h = np.diff(x)\n","  d = 6*np.diff(np.diff(np.r_[y[-2],y])/np.r_[h[-1],h])\n","  a = h[:-1]\n","  b = h + np.r_[h[-1],h[:-1]]\n","  C = np.diag(b)+np.diag(a,1)\n","  C[0,-1]=h[-1]; C += C.T \n","  m = la.solve(C,d)\n","  return(np.r_[m,m[0]])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def evaluate_spline(x,y,m,n):\n","  h = np.diff(x)\n","  B = y[:-1] - m[:-1]*h**2/6\n","  A = np.diff(y)/h-h/6*np.diff(m)\n","  X = np.linspace(np.min(x),np.max(x),n+1)    \n","  i = np.array([np.argmin(X>=x)-1 for X in X])\n","  i[-1] = len(x)-2\n","  Y = (m[i]*(x[i+1]-X)**3 + m[i+1]*(X-x[i])**3)/(6*h[i]) \\\n","      + A[i]*(X-x[i]) + B[i]\n","  return(X,Y)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n, nx = 10, 20\n","x, y = np.random.rand(n), np.random.rand(n)\n","x, y = np.r_[x,x[0]], np.r_[y,y[0]]\n","t = np.cumsum(np.sqrt(np.diff(x)**2+np.diff(y)**2))\n","t = np.r_[0,t]  \n","T,X = evaluate_spline(t,x,spline_periodic(t,x),nx*n)\n","T,Y = evaluate_spline(t,y,spline_periodic(t,y),nx*n)\n","plt.plot(X,Y,x,y,'o'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**9.3. Radial basis functions.** Let's examine how a polynomial $y(x) = \\sum_{i=0}^n c_i x^i$ compares with Gaussian and cubic radial basis functions $y(x) = \\sum_{i=0}^n c_i \\phi(x-x_i)$ taking $\\phi(x)= \\exp(-20x^2)$ and $\\phi(x) = |x|^3$ an interpolant of the Heaviside function."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 20; N = 200\n","x = np.linspace(-1,1,n)[:,None]\n","X = np.linspace(-1,1,N)[:,None]\n","y = (x>0)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def phi1(x,a): return(abs(x-a)**3)\n","def phi2(x,a): return(np.exp(-20*(x-a)**2))\n","def phi3(x,a): return(x**a)\n","def interp(phi,a): \n","  return(phi(X,a.T)@la.solve(phi(x,a.T),y))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["Y1 = interp(phi1,x)\n","Y2 = interp(phi2,x)\n","Y3 = interp(phi3,np.arange(n))\n","plt.plot(x,y,X,Y1,X,Y2,X,Y3)\n","plt.ylim((-.5,1.5)); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**9.4. Collocation.** We'll use collocation to solve Bessel's equation.  We first define a function to solve general linear boundary value problems. And, then we define a function to interpolate between collocation points."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def solve(L,f,bc,x):\n","  h = x[1]-x[0]\n","  S = np.array([[1,-1/2,1/6],[-2,0,2/3],[1,1/2,1/6]])  \\\n","          /np.array([h**2,h,1])\n","  S = np.r_[np.zeros((1,3)),L(x)@S.T,np.zeros((1,3))]\n","  d = np.r_[bc[0], f(x), bc[1]]\n","  A = np.diag(S[1:,0],-1) + np.diag(S[:,1]) + np.diag(S[:-1,2],1)\n","  A[0,:3] , A[-1,-3:] = np.array([1,4,1])/6 , np.array([1,4,1])/6\n","  return(la.solve(A,d))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def build(c,x,N):\n","  X = np.linspace(x[0],x[-1],N)\n","  h = x[1] - x[0]\n","  i = (X // h).astype(int)\n","  i[-1] = i[-2]\n","  C = np.c_[c[i],c[i+1],c[i+2],c[i+3]]\n","  B = lambda x: np.c_[(1-x)**3, 4-3*(2-x)*x**2, \\\n","           4-3*(1+x)*(1-x)**2, x**3]/6\n","  Y = np.sum(C*B((X-x[i])/h),axis=1)\n","  return(X,Y)"]},{"cell_type": "markdown", "metadata": {}, "source": ["Now, we can solve the Bessel equation $xu''+u'+xu =0$ with boundary conditions $u(0)=1$ and $u(b)=0$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.special import jn_zeros, j0\n","n = 15; N = 141\n","L = lambda x: np.c_[x,np.ones_like(x),x]\n","f = lambda x: np.zeros_like(x)\n","b = jn_zeros(0,4)[-1]\n","x = np.linspace(0,b,n)\n","c = solve(L,f,[1,0],x)\n","X,Y = build(c,x,N)\n","plt.plot(X,Y,X,j0(X)); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["Finally, we'll examine the error and convergence rate."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["N = 10*2**np.arange(6)\n","e = []\n","for n in N:\n","  x = np.linspace(0,b,n)\n","  c = solve(L,f,[1,0],x)\n","  [X,Y] = build(c,x,n)\n","  e = np.r_[e,la.norm(Y-j0(X))/n]\n","plt.loglog(N,e,'.-'); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from numpy.polynomial.polynomial import polyfit \n","s = polyfit(np.log(N),np.log(e),1)[1]\n","print(\"slope = \" + \"{:4.4f}\".format(s))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**10.3. Fractional derivatives.** We'll plot the fractional derivatives for a function."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from numpy.fft import fft,ifft,fftshift\n","def f(x): return np.exp(-16*x**2)\n","def f(x): return x*(1-np.abs(x))\n","n = 2000; L = 2 \n","x = np.arange(n)/n*L-L/2\n","k = fftshift(np.arange(n)-n/2)*2*np.pi/L"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from ipywidgets import interactive\n","def anim(derivative=0):\n","  u = np.real(ifft((1j*k)**derivative*fft(f(x))))\n","  plt.plot(x,u,color='k'); plt.show()\n","interactive(anim, derivative = (0,2,0.01))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**10.4. Levenberg–Marquardt method.** We find parameters for a nonlinear function that best fits our data. We'll first define a function `gauss_newton` and duplicate the function [`jacobian`](#jacobian) from above. If the Gauss–Newton method converges, then we can plot the results."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def gauss_newton(x,y,c,f):\n","  r = y - f(c,x)\n","  for j in range(100):\n","    G = jacobian(f,c,x)\n","    M = G.T @ G\n","    c += la.solve(M + np.diag(np.diag(M)),G.T@r)\n","    r, r0 = y-f(c,x), r\n","    if la.norm(r-r0) < 10E-8: return(c)\n","  print('Gauss-Newton did not converge.')"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def jacobian(f,c,x):\n","  J = np.empty([len(x), len(c)])\n","  n = np.arange(len(c))\n","  for i in n:\n","    J[:,i] = np.imag(f(c+1e-8j*(i==n),x))/1e-8\n","  return(J)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def f(c,x): return( c[0]*np.exp(-c[1]*(x-c[2])**2) +\n","  c[3]*np.exp(-c[4]*(x-c[5])**2))\n","x = 8*np.random.rand(100)\n","y = f(np.array([1,3,3,2,3,6]),x) + np.random.normal(0,0.1,100)\n","c0 = np.array([2,0.3,2,1,0.3,7])\n","c = gauss_newton(x,y,c0,f)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["X = np.linspace(0,8,100)\n","plt.plot(x,y,'.',X,f(c,X)); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**10.5. Handwriting classification.** We'll use Keras to train a convolutional neural net using MNIST data and then test the model."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import tensorflow as tf\n","from tensorflow import keras\n","from keras.layers import Conv2D, AvgPool2D, Dense, Flatten\n","model = keras.models.Sequential([\n","  Conv2D(6,5,activation='tanh',padding='same',input_shape=(28,28,1)),\n","  AvgPool2D(),\n","  Conv2D(16, 5, activation='tanh'),\n","  AvgPool2D(),\n","  Conv2D(120, 5, activation='tanh'),\n","  Flatten(),\n","  Dense(84, activation='tanh'),\n","  Dense(10, activation='sigmoid')\n","])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["model.build(); model.summary()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from keras.datasets import mnist\n","(image_train,label_train),(image_test,label_test) = mnist.load_data()\n","image_train = tf.expand_dims(image_train/255.0, 3)\n","image_test = tf.expand_dims(image_test/255.0, 3)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","model.compile(optimizer=\"adam\",  loss=loss, metrics=[\"accuracy\"])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["model.fit(image_train, label_train, epochs=5)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["model.evaluate(image_test,label_test)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**11.1. Finite difference approximation.**  Let's find coefficients to the third-order approximation of $f'(x)$ for nodes at $x$, $x+h$, $x+2h$ and $x+3h$.  We'll reuse the function [`rats`](#rats) from above."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["d = np.array([0,1,2,3])[:,None]; n = len(d)\n","factorial = [np.math.factorial(i) for i in range(n+1)]\n","V = d**np.arange(n) / factorial[:-1]\n","C = la.inv(V)\n","C = np.c_[C,C@d**n/factorial[-1]]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from fractions import Fraction\n","def rats(x): return str(Fraction(x).limit_denominator())"]},{"cell_type": "markdown", "metadata": {}, "source": ["The coefficients of the finite difference approximation of the derivative and coefficient of the truncation error are given by"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["print(\"Coefficients: \"+\", \".join([rats(x) for x in C[1,:-1]]))\n","print(\"Truncation: \"+rats(C[1,-1]) )"]},{"cell_type": "markdown", "metadata": {}, "source": ["**11.2. Richardson extrapolation.** The following code is an iterative version of the recursive [`richardson`](#richardson_extrapolation) function above:"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def richardson(f,x,m):\n","  D = np.zeros(m)\n","  for i in range(m):\n","    D[i] = phi(f,x,2**(i+1))\n","    for j in range(i-1,-1,-1):\n","      D[j] = (4**(i-j)*D[j+1] - D[j])/(4**(i-j) - 1)\n","  return(D[1])"]},{"cell_type": "markdown", "metadata": {}, "source": ["**11.3. Automatic differentiation.** Let's extend the [`Dual class`](#dualclass) above by adding methods for division, cosine, and square root to the class definition. We'll also add a few more help functions. "]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["class Dual:\n","  def __init__(self, value, deriv=1):\n","    self.value = value\n","    self.deriv = deriv\n","  def __add__(u, v):\n","    return Dual(value(u) + value(v), deriv(u) + deriv(v))\n","  __radd__ = __add__\n","  def __sub__(u, v):\n","    return Dual(value(u) - value(v), deriv(u) - deriv(v))\n","  __rsub__ = __sub__\n","  def __mul__(u, v):\n","    return Dual(value(u)*value(v), \n","        value(v)*deriv(u) + value(u)*deriv(v))\n","  __rmul__ = __mul__\n","  def sin(u):\n","    return Dual(sin(value(u)),cos(value(u))*deriv(u)) \n","  def __truediv__(u, v):\n","    return Dual(value(u) / value(v), \n","      (value(v)*deriv(u)-value(u)*deriv(v))/(value(v)*value(v)))\n","  __rtruediv__ = __truediv__\n","  def cos(u):\n","    return Dual(cos(value(u)),-1*sin(value(u))*deriv(u))\n","  def sqrt(u):\n","    return Dual(sqrt(value(u)),deriv(u)/(2*sqrt(value(u))))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def value(x): \n","  return(x.value if isinstance(x, Dual) else x)\n","def deriv(x): \n","  return(x.deriv if isinstance(x, Dual) else 0)\n","def sin(x): return np.sin(x) \n","def cos(x): return np.cos(x) \n","def auto_diff(f,x): \n","    return f(Dual(x)).deriv\n","def cos(u): return np.cos(u)\n","def sqrt(u): return np.sqrt(u)"]},{"cell_type": "markdown", "metadata": {}, "source": ["Now, we'll can define Newton's method using this new Dual class and use it to find the zero of $4\\sin x + \\sqrt{x}$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def get_zero(f,x):\n","  tolerance = 1e-14; delta = 1\n","  while abs(delta)>tolerance:\n","    fx = f(Dual(x))\n","    delta = value(fx)/deriv(fx)\n","    x -= delta\n","  return(x)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def f(x): return 4*sin(x) + sqrt(x)\n","get_zero(f, 4)"]},{"cell_type": "markdown", "metadata": {}, "source": ["We can find a minimum or maximum of $4\\sin x + \\sqrt{x}$ by modifying Newton's method."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def get_extremum(f,x):\n","  tolerance = 1e-14; delta = 1\n","  while abs(delta)>tolerance:\n","    fx = f(Dual(Dual(x)))\n","    delta = deriv(value(fx))/deriv(deriv(fx))\n","    x -= delta\n","  return(x)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["get_extremum(f, 4)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**11.4. Gauss–Legendre quadrature .** The following  function computes the nodes and weights for  Gauss–Legendre quadrature by using Newton's method to find the roots of $\\mathrm{P_n}(x)$. We'll verify the function on a toy problem."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def gauss_legendre(n):\n","  x = -np.cos((4*np.arange(n)+3)*np.pi/(4*n+2))\n","  dx = np.ones_like(x)\n","  dP = 0\n","  while(max(abs(dx))>1e-16):\n","    P0, P1 = x, np.ones_like(x)\n","    for k in range(2,n+1):\n","      P0, P1 = ((2*k - 1)*x*P0-(k-1)*P1)/k, P0 \n","    dP = n*(x*P0 - P1)/(x**2-1)\n","    dx =  P0 / dP \n","    x -= dx\n","  return( x, 2/((1-x**2)*dP**2) )"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def f(x): return 2*sqrt(1-x**2)\n","x,w = gauss_legendre(10)\n","np.dot(w,f(x))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**11.6. Fundamental solution to the heat equation.** We'll use Gauss–Hermite quadrature to compute the solution to the heat equation $$u(t,x) = \\frac{1}{\\sqrt{4\\pi t}}\\int_{-\\infty}^\\infty  u_0(s) \\mathrm{e}^{-(x-s)^2/4t} \\;\\mathrm{d}s.$$"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["ξ,w = np.polynomial.hermite.hermgauss(40)\n","def u0(x): return np.sin(x)\n","def u(t,x): \n","  return [np.dot(w,u0(x-2*np.sqrt(t)*ξ)/np.sqrt(np.pi)) for x in x]\n","x = np.linspace(-12,12,100)\n","plt.plot(x,u(1,x)); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**11.7. Monte Carlo integration.** The following  function the volume of an $d$-dimensional sphere using $n$ samples and $m$ trials. We'll use it to verify that error of Monte Carlo integretion is $O(1/\\sqrt{n})$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def mc_pi(n,d,m): \n","  return(sum(sum(np.random.rand(d,n,m)**2)<1)/n*2**d)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = 20; error = []; N = 2**np.arange(20)\n","error = [sum(abs(np.pi - mc_pi(n,2,m)))/m for n in N]\n","plt.loglog(N,error,marker=\".\",linestyle=\"None\")\n","s = np.polyfit(np.log(N),np.log(error),1)\n","plt.loglog(N,np.exp(s[1])*N**s[0])\n","plt.show()\n","print(\"slope = {:4.3f}\".format(s[0]))"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label19\"></a>\n## Numerical Differential Equations\n**12.4. Runge–Kutta  stability** The following code plots the region of absolute stability for a Runge–Kutta method with tableau `A` and `b`."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = np.array([\n","  [0,   0,   0,   0,   0],\n","  [1/3, 0,   0,   0,   0],\n","  [1/6, 1/6, 0,   0,   0],\n","  [1/8, 0,   3/8, 0,   0],\n","  [1/2, 0,  -3/2, 2,   0]])\n","b = np.array([[1/6, 0, 0, 2/3, 1/6]])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["N = 100; n = b.shape[1]\n","r = np.zeros((N,N))\n","E = np.ones((n,1))\n","x,y = np.linspace(-4,4,N),np.linspace(-4,4,N)\n","for i in range(N):\n","  for j in range(N):\n","    z = x[i] + 1j*y[j]\n","    r[j,i] = abs(1 + z*b@(la.solve(np.eye(n) - z*A,E)))\n","plt.contour(x,y,r,[1]); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**12.8. Third-order IMEX coefficients.** We can determine the coefficients of a third-order IMEX method by inverting a system of linear equations."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["i = np.arange(4)[:,None]\n","def factorial(k): return np.cumprod(np.r_[1,range(1,k)])\n","c1 = la.solve(((-i)**i.T/factorial(4)).T,np.array([0,1,0,0]))\n","c2 = la.solve(((-(i+1))**i.T/factorial(4)).T,np.array([1,0,0,0]))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from fractions import Fraction\n","def rats(x): return str(Fraction(x).limit_denominator())"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["print(\"right-hand side: \" + \", \".join([rats(c) for c in c1]))\n","print(\"implicit: \" + \", \".join([rats(c) for c in c2]))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**12.9. Predictor-corrector stability.** We'll use the  [`multistepcoeffs`](#multistepcoeffs) introduced earlier. The following function provides the orbit of points in the complex plane for an $n$th order  Adams–Bashforth–Moulton PE(CE)$^m$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def multistepcoeffs(m,n):\n","  s = len(m) + len(n)\n","  A = (np.r_[m]+1.0)**np.c_[range(s)]\n","  B = np.c_[range(s)]*(np.r_[n]+1.0)**(np.c_[range(s)]-1)\n","  c = la.solve(-np.c_[A,B],np.ones((s,1))).flatten()\n","  return(np.r_[1,c[:len(m)]], c[len(m):] )"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def PECE(n,m):\n","  _,a = multistepcoeffs([1],range(1,n+1))\n","  _,b = multistepcoeffs([1],range(0,n+1))\n","  def c(r): return np.r_[r-1,\\\n","    np.full(m, r + (b[1:] @ r**np.arange(1,n+1))/b[0]),\\\n","    (a @ r**np.arange(1,n+1))/b[0]]\n","  z = []\n","  for r in np.exp(1j*np.linspace(0,2*np.pi,200)):\n","    z = np.append(z,np.roots(np.flip(c(r)))/b[0])\n","  return z"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["for i in range(5): \n","  z = PECE(4,i)      \n","  plt.scatter(np.real(z),np.imag(z),s=0.5)\n","plt.axis('equal'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**12.10. Padé approximant.** We'll build a function to compute the coefficients of the Padé approximant to $log(r)$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def pade(a,m,n):\n","  A = np.eye(m+n+1);\n","  for i in range(n): A[i+1:,m+i+1] = -a[:m+n-i]\n","  pq = la.solve(A,a[:m+n+1])\n","  return pq[:m+1], np.r_[1,pq[m+1:]]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = 3; n = 2\n","a = np.r_[0, (-1)**np.arange(m+n)/(1+np.arange(m+n))]\n","p,q = pade(a,m,n)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def S(n): return la.invpascal(n+1, kind='upper')\n","S(m)@p, S(n)@q"]},{"cell_type": "markdown", "metadata": {}, "source": ["**12.14. SIR solution.** We solve the susceptible-infected-recovered (SIR) model for infectious diseases using a general ODE solver."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","def SIR(t,y,b,g): return (-b*y[0]*y[1],b*y[0]*y[1]-g*y[1],g*y[1])\n","sol = solve_ivp(SIR, [0, 15], [0.99, 0.01, 0],\\\n","  args=(2,0.4), dense_output=True)\n","t = np.linspace(0,15,200); y = sol.sol(t)\n","plt.plot(t,y[0,:],t,y[1,:],t,y[2,:]); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**12.15. Duffing equation.** We'll use a high-order, explicit ODE solver for the Duffing equation."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","def duff(t,x,g): return(x[1],-g*x[1]+x[0]-x[0]**3+0.3*np.cos(t))\n","sol = solve_ivp(duff,[0,200], [1, 0], args=(0.37,), \n","    method='DOP853',dense_output=True)\n","t = np.linspace(0,200,2000); y = sol.sol(t)\n","plt.plot(y[0,:],y[1,:]); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**12.16. Shooting method.** We'll solve the Airy equation $y'' - xy = 0$ using the shooting method that incorporates an initial value solver along into a nonlinear root finder."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","from scipy.optimize import fsolve\n","def airy(x,y): return(y[1],x*y[0])\n","domain = [-12,0]; bc = [1,1]; guess = 5\n","def shoot_airy(guess):\n","  sol = solve_ivp(airy,domain,[bc[0],guess[0]])\n","  return sol.y[0,-1] - bc[1] \n","v = fsolve(shoot_airy,guess)[0]"]},{"cell_type": "markdown", "metadata": {}, "source": ["Once we have our second initial value, we can plot the solution:"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["sol = solve_ivp(airy,domain,[bc[0],v],dense_output=True)\n","x = np.linspace(-12,0,200)\n","plt.plot(x,sol.sol(x)[0,:]); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**13.4. Dufort–Frankel method.** We'll use the Dufort–Frankel method to solve the heat equation. While this method is unconditionally stable, it generates the wrong solution. Notice that while the long-term behavior is dissipative, the solution is largely oscillatory and the dynamics are more characteristic of a viscous fluid than heat propagation."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["dx = 0.01; dt = 0.01; n = 400\n","L = 1; x = np.arange(-L,L,dx); m = len(x) \n","U = np.empty((n,m))\n","U[0,:] = np.exp(-8*x**2); U[1,:] = U[0,:]  \n","c = dt/dx**2; a = 0.5 + c; b = 0.5 - c\n","start_time = timeit.default_timer()\n","B = c*sp.diags([1, 1], [-1, 1], shape=(m, m)).tocsr()\n","B[0,1] *=2; B[-1,-2] *=2\n","for i in range(1,n-1):\n","  U[i+1,:] = (B@U[i,:]+b*U[i-1,:])/a"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from ipywidgets import interactive\n","def anim(i=0):\n","  plt.fill_between(x,U[i,:],color='#ff9999');\n","  plt.ylim(0,1);plt.show()\n","interactive(anim, i = (0,n-1))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**13.6. Schrödinger equation.** We solve the Schrödinger equation for harmonic potential using the Strang splitting Crank-Nicolson and confirm that the method is $O(h^2,k^2)$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def psi0(x,eps): return np.exp(-(x-1)**2/(2*eps))/(np.pi*eps)**(1/4)\n","def schroedinger(n,m,eps):\n","  x,dx = np.linspace(-4,4,n,retstep=True); dt = 2*np.pi/m; V = x**2/2\n","  psi = psi0(x,eps)\n","  D = 0.5j*eps*sp.diags([1, -2, 1], [-1, 0, 1], shape=(n, n))/dx**2 \\\n","    - 1j/eps*sp.diags(V,0)\n","  D[0,1] *= 2; D[-1,-2] *= 2\n","  A = sp.eye(n) + (dt/2)*D \n","  B = sp.eye(n) - (dt/2)*D  \n","  for i in range(m):\n","    psi = sp.linalg.spsolve(B,A*psi)\n","  return(psi)"]},{"cell_type": "markdown", "metadata": {}, "source": ["We'll loop over several values for time steps and mesh sizes and plot the error. This may take a while. Go get a snack."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["eps = 0.3; m = 20000; N = np.logspace(2,3.7,6).astype(int)\n","x = np.linspace(-4,4,m)\n","psi_m = -psi0(x,eps)\n","error_t = []; error_x = []\n","for n in N: \n","  x = np.linspace(-4,4,n) \n","  psi_n = -psi0(x,eps)\n","  error_t.append(la.norm(psi_m - schroedinger(m,n,eps))/m)\n","  error_x.append(la.norm(psi_n - schroedinger(n,m,eps))/n)\n","plt.loglog(2*np.pi/N,error_t,'.-r',8/N,error_x,'.-k'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**13.7. Polar heat equation.** We'll solve a radially symmetric heat equation. Although we divide by zero at $r=0$ when constructing the Laplacian operator, the resulting term `inf` is overwritten when we apply the boundary condition."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["T = 0.5; m = 100; n = 100\n","r = np.linspace(0,2,m); dr = r[1]-r[0]; dt = T/n\n","u = np.tanh(32*(1-r))[:,None]\n","D = sp.diags([1, -2, 1], [-1, 0, 1], shape=(m,m))/dr**2 \\\n","  + sp.diags([-1/r[1:], 1/r[:-1]], [-1, 1])/(2*dr)\n","D[0,0:2] = np.array([-4,4])/dr**2;\n","D[-1,-2:] = np.array([2,-2])/dr**2 \n","A = sp.eye(m) - 0.5*dt*D \n","B = sp.eye(m) + 0.5*dt*D  \n","for i in range(n):\n","  u = sp.linalg.spsolve(A,B@u)\n","plt.fill_between(r,u,-1,color='#ff9999'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**13.8. Open boundaries.** We can approximate open boundaries by spacing the grid points using a sigmoid function such as $\\mathrm{arctanh}\\, x$. We start by defining a function `logitspace` which is the logit analogue to `np.linspace`. Then we define a Laplacian operator using arbitrary grid spacing. Finally, we solve the heat equation using the Crank–Nicolson using both equally spaced gridpoints and logit spaced gridpoints."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def logitspace(x,n,p): \n","  return x*np.arctanh(np.linspace(-p,p,n))/np.arctanh(p)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def laplacian(x):\n","  h = np.diff(x); h1 = h[:-1]; h2 = h[1:]; n = len(x)\n","  d = np.c_[ \\\n","    np.r_[h1[0]**2, h2*(h1+h2),0], \\\n","    np.r_[-h1[0]**2, -h1*h2,-h2[-1]**2 ], \\\n","    np.r_[h1*(h1+h2), h2[-1]**2,0]].T\n","  d[0,-1],d[2,-1] = 999,999\n","  return sp.diags(2/d,[-1,0,1],shape=(n, n)).T"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def heat_equation(x,t,u):\n","  m = 40; dt = t/m\n","  u = phi(x,0,10)\n","  D = laplacian(x)\n","  A = sp.eye(len(x)) - 0.5*dt*D\n","  B = sp.eye(len(x)) + 0.5*dt*D\n","  for i in range(m):\n","    u = sp.linalg.spsolve(A,B@u)\n","  return(u)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def phi(x,t,s): \n","  return np.exp(-s*x**2/(1+4*s*t))/np.sqrt(1+4*s*t)\n","t = 15; n = 40\n","x = logitspace(20,n,.999)\n","laplacian(x).toarray()\n","u = heat_equation(x,t,phi(x,0,10))\n","plt.plot(x,u,'.-',x,phi(x,t,10),'k'); plt.show()\n","x = np.linspace(-20,20,n)\n","u = heat_equation(x,t,phi(x,0,10))\n","plt.plot(x,u,'.-',x,phi(x,t,10),'k'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**13.9. Allen–Cahn equation.** We'll solve the Allen–Cahn equation using  Strang splitting. We'll save the solution every tenth iteration and animate the solution using the `ipywidgets` library.  Rerun the code by uncommenting the random initial conditions."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["L = 16; m = 200; dx = L/m\n","T = 8; n = 1600; dt = T/n\n","x = np.linspace(-L/2,L/2,m)[None,:]\n","u = np.tanh(x**4 - 16*(2*x**2-x.T**2))\n","#u = np.random.standard_normal((m,m))\n","D = sp.diags([1, -2, 1], [-1, 0, 1], shape=(m,m)).tocsr()/dx**2\n","D[0,1] *= 2; D[-1,-2] *= 2;\n","A = sp.eye(m) + 0.5*dt*D\n","B = sp.eye(m) - 0.5*dt*D \n","def f(u,dt): \n","  return u/np.sqrt(u**2 - (u**2-1)*np.exp(-50*dt))\n","u = f(u,dt/2)\n","U = np.empty((m,m,n//10))\n","for i in range(n):\n","  if (i%8==0): U[:,:,i//10] = u\n","  u = sp.linalg.spsolve(B,(A@sp.linalg.spsolve(B,A@u).T)).T\n","  if (i<n): u = f(u,dt)\n","u = f(u,dt/2)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from ipywidgets import interactive\n","def anim(i=0):\n","  plt.imshow(U[:,:,i], cmap=\"gray\"); plt.axis('off'); plt.show()\n","interactive(anim, i = (0,U.shape[2]-1))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**14.7. Burgers' Equation.**"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = 100; x,dx = np.linspace(-1,3,m,retstep=True)\n","n = 100; Lt = 4; dt = Lt/n; c = dt/dx\n","def f(u): return u**2/2\n","def fp(u): return u\n","u = ((x>=0)&(x<=1)).astype(float)\n","for i in range(n):\n","  fu = f(np.r_[u[0],u]); fpu = fp(np.r_[u[0],u])\n","  a = np.maximum(abs(fu[1:-1]),abs(fu[:-2]))\n","  F = (fu[1:-1]+fu[:-2])/2 - a*(u[1:]-u[:-1])/2\n","  u -= c*(np.diff(np.r_[0,F,0]))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**14.8. Dam break problem.**"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def limiter(t): return (abs(t)+t)/(1+abs(t))  \n","def fixzero(u): return u + (u==0).astype(float)\n","def diff(u): return np.diff(u,axis=0)\n","def slope(u):\n","  du = diff(u)\n","  return np.r_[np.c_[0,0], \\\n","    np.c_[du[1:,:]*limiter(du[:-1,:]/fixzero(du[1:,:]))],\\\n","    np.c_[0,0]]\n","def F(u):\n","  return np.c_[u[:,0]*u[:,1], u[:,0]*u[:,1]**2+0.5*u[:,0]**2]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = 1000; x,dx = np.linspace(-.5,.5,m,retstep=True)\n","T = 0.25; n = (T/(dx/2)).astype(int); dt = (T/n)/2; c = dt/dx\n","u = np.c_[0.8*(x<0)+0.2,0*x] \n","for i in range(n):\n","  v = u-0.5*c*slope(F(u))\n","  u[1:,:]=(u[:-1,:]+u[1:,:])/2 - diff(slope(u))/8 - c*diff(F(v)) \n","  v = u-0.5*c*slope(F(u))\n","  u[:-1,:]=(u[:-1,:]+u[1:,:])/2 - diff(slope(u))/8 - c*diff(F(v))\n","plt.plot(x,u); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**15.1. Finite element method.**"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = 10; x,h = np.linspace(0,1,m,retstep=True)\n","A = np.tile(np.r_[-1/h-h/6,2/h-2/3*h,-1/h-h/6],(m,1)).T\n","A[1,0]/=2; A[1,-1] /= 2\n","b=np.r_[-2/3*h**3,-4/3*h**3-8*h*x[1:-1]**2,-4*h+8/3*h**2-2/3*h**3+1]\n","u=la.solve_banded((1,1),A,b)\n","s=(-16)+8*x**2+15*np.cos(x)/np.sin(1)\n","plt.plot(x,s,'o-',x,u,'.-'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**15.2. Finite element method.**"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = 8; x,h = np.linspace(0,1,m+2,retstep=True)\n","def tridiag(a,b,c): return np.diag(a,-1)+np.diag(b,0)+np.diag(c,1)\n","def D(a,b,c):   \n","  return tridiag(a*np.ones(m-1), b*np.ones(m), c*np.ones(m-1))/h**3\n","M = np.r_[np.c_[D(-12,24,-12),D(-6,0,6)],\n","  np.c_[D(6,0,-6),D(2,8,2)]]\n","b = np.r_[np.ones(m)*h*384,np.zeros(m)]\n","u = la.solve(M,b)\n","plt.plot(x,16*(x**4 - 2*x**3 + x**2),'o-',x,np.r_[0,u[:m],0],'.-') \n","plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**16.2. Burgers' equation.** Fourier spectral methods perform poorly on problems that develop discontinuities such as Burgers' equation.  Gibbs oscillations develop around the discontinuity, and these oscillations will spread and grow because Burgers' equation is dispersive. Ultimately, the oscillations overwhelm the solution."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","from scipy.fft import fftshift, fft, ifft\n","m = 128; x = np.linspace(-np.pi,np.pi,m,endpoint=False)\n","k = 1j*fftshift(np.arange(-m/2,m/2))\n","def f(t,u): return -np.real(ifft(k*fft(0.5*u**2)))\n","sol = solve_ivp(f, [0,1.5], np.exp(-x**2), method = 'RK45')  \n","plt.plot(x,sol.y[:,-1]); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**16.3. KdV equation.** We'll solve the KdV equation using integrating factors. We first set the initial conditions and parameters. Then, we define the integrating factor `G` and the right-hand side `f` of the differential equation. Finally, we animate the solution. Notice the two soliton solution."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import fftshift, fft, ifft\n","def phi(x,x0,c): return 0.5*c/np.cosh(np.sqrt(c)/2*(x-x0))**2\n","L = 30; T = 2.0; m = 256\n","x = np.linspace(-L/2,L/2,m,endpoint=False)\n","k = 1j*fftshift(np.arange(-m/2,m/2))*(2*np.pi/L)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def G(t): return np.exp(-k**3*t)\n","def f(t,w): return -(3*k*fft(ifft(G(t)*w)**2))/G(t)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","u = phi(x,-4,4) + phi(x,-9,9)\n","w = fft(u)\n","sol = solve_ivp(f,[0,T],w,t_eval=np.linspace(0,T,200))   \n","u = [np.real(ifft(G(sol.t[i])*sol.y[:,i])) for i in range(200)]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["plt.rcParams[\"animation.html\"] = \"jshtml\"\n","from matplotlib.animation import FuncAnimation\n","fig, ax = plt.subplots()\n","l, = ax.plot([-15,15],[0,5])\n","def animate(i): l.set_data(x, u[i])\n","FuncAnimation(fig, animate, frames=len(u),interval=50)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**16.4. Swift–Hohenberg equation.** We'll use Strang splitting to solve the  Swift–Hohenberg equation."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import fftshift, fft2, ifft2\n","eps = 1; m = 256; L = 100; n = 2000; dt=100/n\n","U = (np.random.rand(m,m)>0.5)-0.5\n","k = fftshift(np.arange(-m/2,m/2))*(2*np.pi/L)\n","D2 = -k[:,None]**2-k[None,:]**2\n","E = np.exp(-(D2+1)**2*dt)\n","def f(U):\n","  return U/np.sqrt(U**2/eps + np.exp(-dt*eps)*(1-U**2/eps))\n","for i in range(n):\n","  U = f(ifft2(E*fft2(f(U))))\n","plt.imshow(np.real(U), cmap=\"gray\"); plt.axis('off'); plt.show()"]}],
"metadata": { "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython","version": 3}, "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython3",   "version": "3.6.3"  } }, "nbformat": 4, "nbformat_minor": 2 }