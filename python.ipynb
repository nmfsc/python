{"cells":[{"cell_type": "markdown", "metadata": {}, "source": ["<h1>Numerical Methods in Python</h1>\n\nThis Jupyter notebook serves as supplementary material to the Python code from the book [Numerical Methods for Scientific Computing](https://www.equalsharepress.com/media/NMFSC.pdf). This notebook was written and tested using Python version 3.9.7. By and large, the snippets are verbatim from the book with an occasional explicit output, plot statement, or variable declaration. These code snippets are minimal working toy algorithms meant to better understand the mathematics that goes into them. They are tools for tinkering and learning. Play with them and have fun. And, perhaps you can repurpose a few of them.  The notebook is designed to be nonlinear⁠—you can jump around.  We'll use the following packages and definitions throughout this notebook:"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import matplotlib.pyplot as plt\n","import numpy as np\n","import scipy.linalg as la\n","import scipy.sparse as sps"]},{"cell_type": "markdown", "metadata": {}, "source": ["We'll also define the following commonly used variables:"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["bucket = \"https://raw.githubusercontent.com/nmfsc/data/master/\"\n","π = np.pi"]},{"cell_type": "markdown", "metadata": {}, "source": ["Finally, we'll define a few helper functions for downloading and displaying images."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import PIL, requests, io\n","def rgb2gray(rgb): return np.dot(rgb[...,:3], [0.2989,0.5870,0.1140])\n","def getimage(url):\n","  response = requests.get(url)\n","  return np.asarray(PIL.Image.open(io.BytesIO(response.content)))\n","def showimage(img):\n","  display(PIL.Image.fromarray(np.int8(img.clip(0,255)), mode='L'))"]},{"cell_type": "markdown", "metadata": {}, "source": ["We can set the output of matplotlib in Jupyter to produce SVG, which will result in higher quality plots than the default PNG. Rendering an SVG is a little slower than a PNG, and it can produce noticeable jerkiness in ipywidgets animations.  To switch back to the default PNG, use the command `set_matplotlib_formats('png')`. You may need to enable the ipywidgets package before launching Jupyter using `jupyter nbextension enable –py widgetsnbextension`."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["!pip install matplotlib-inline\n","import matplotlib_inline.backend_inline\n","matplotlib_inline.backend_inline.set_matplotlib_formats('svg')"]},{"cell_type": "markdown", "metadata": {}, "source": ["<h1>Notebook Contents</h1>\n\n [Part 1: Numerical Linear Algebra](#label0)<br>\n&emsp; [Chapter 1: A Review of Linear Algebra](#label1)<br>\n&emsp; [Chapter 2: Direct Methods for Linear Systems](#label2)<br>\n&emsp; [Chapter 3: Inconsistent Systems](#label3)<br>\n&emsp; [Chapter 4: Computing Eigenvalues](#label4)<br>\n&emsp; [Chapter 6: Fast Fourier Transform](#label5)<br>\n [Part 2: Numerical Methods for Analysis](#label6)<br>\n&emsp; [Chapter 7: Preliminaries](#label7)<br>\n&emsp; [Chapter 8: Solutions to Nonlinear Equations](#label8)<br>\n&emsp; [Chapter 9: Interpolation](#label9)<br>\n&emsp; [Chapter 10: Approximating Functions](#label10)<br>\n&emsp; [Chapter 11: Differentiation and Integration](#label11)<br>\n [Part 3: Numerical Differential Equations](#label12)<br>\n&emsp; [Chapter 12: Ordinary Differential Equations](#label13)<br>\n&emsp; [Chapter 13: Parabolic Equations](#label14)<br>\n&emsp; [Chapter 16: Fourier Spectral Methods](#label15)<br>\n [Part 4: Solutions](#label16)<br>\n&emsp; [Numerical Linear Algebra](#label17)<br>\n&emsp; [Numerical Analysis](#label18)<br>\n&emsp; [Numerical Differential Equations](#label19)<br>\n"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label0\"></a>\n# Part 1: Numerical Linear Algebra\n<a name=\"label1\"></a>\n## Chapter 1: A Review of Linear Algebra\n**The Hilbert matrix.** The Hilbert matrix $\\mathbf{H}$ is ill-conditioned even for relatively small dimensions. Taking $\\mathbf{H}^{-1}\\mathbf{H}$ should give us the identity matrix. Notice that `la.solve` explicitly warns that the matrices are ill conditioned."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["M = [la.solve(la.hilbert(n),la.hilbert(n)) for n in [10,15,20,25,50]]\n","fig, ax = plt.subplots(1, 5)\n","for i in range(len(M)): \n","  ax[i].imshow(1-np.abs(M[i]),vmin=0,cmap=\"gray\")\n","plt.tight_layout(); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label2\"></a>\n## Chapter 2: Direct Methods for Linear Systems\n**Gaussian elimination.** The following function implements a naïve Gaussian elimination algorithm for a matrix `A` and vector `b`. We'll verify the code using a random matrix-vector pair. Note that the function `gaussian_elimination(A,b)` overwrites both `A` and `b`. Pass array copies of these objects `gaussian_elimination(A.copy(),b.copy())` if you wish to avoid overwriting them."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def gaussian_elimination(A,b):\n","  n = len(A)\n","  for j in range(n):\n","    A[j+1:,j] /= A[j,j]\n","    A[j+1:,j+1:] -= np.outer(A[j+1:,j],A[j,j+1:])\n","  for i in range(1,n):\n","    b[i] = b[i] - A[i,:i]@b[:i]\n","  for i in reversed(range(n)):\n","    b[i] = ( b[i] - A[i,i+1:]@b[i+1:] )/A[i,i]\n","  return b"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = np.random.rand(8,8); b = np.random.rand(8,1)\n","np.c_[la.solve(A,b),gaussian_elimination(A,b)]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Simplex method.** <a name=\"simplex\"></a>The following three functions (`get_pivot`, `row_reduce`, and `simplex`) implement a naïve simplex method. Let's use them to solve the LP problem \"Find the maximum of the objective function $2x + y + z$ subject to the constraints $2x+ z  \\leq 3$, $4x+y + 2z  \\leq 2$, and $x+y \\leq 1$\" along with the dual LP problem. "]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def get_pivot(tableau):\n","  j = np.argmax(tableau[-1,:-1]>0)\n","  a, b = tableau[:-1,j], tableau[:-1,-1]\n","  k = np.argwhere(a > 0)\n","  i = k[np.argmin(b[k]/a[k])]\n","  return i,j"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def row_reduce(tableau):\n","  i,j = get_pivot(tableau)\n","  G = tableau[i,:]/tableau[i,j]\n","  tableau -= tableau[:,j].reshape(-1,1)*G\n","  tableau[i,:] = G"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from collections import namedtuple\n","def simplex(c,A,b):\n","  m,n = A.shape\n","  tableau = np.r_[np.c_[A,np.eye(m),b], \\\n","    np.c_[c.T,np.zeros((1,m)),0]]\n","  while (any(tableau[-1,:n]>0)): row_reduce(tableau)\n","  p = np.argwhere(tableau[-1,:n] != 0) \n","  x = np.zeros(n)\n","  for i in p.flatten(): \n","    x[i] = np.dot(tableau[:,i],tableau[:,-1])\n","  z = -tableau[-1,-1]\n","  y = -tableau[-1,range(n,n+m)]\n","  solution = namedtuple(\"solution\",[\"z\",\"x\",\"y\"])       \n","  return solution(z,x,y)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = np.array([[2,0,1],[4,1,2],[1,1,0]])\n","c = np.array([[2],[1],[1]]);  b = np.array([[3],[2],[1]])\n","solution = simplex(c,A,b)\n","print(\"outcome:\", solution.z)\n","print(\"primal solution:\", solution.x)\n","print(\"dual solution:\", solution.y)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = sps.rand(60,80,density=0.2)\n","print(A.nnz), plt.spy(A,markersize=1)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Graph drawing.** The following code draws the dolphin networks of the Doubtful Sound. We'll use dolphin gray (\\#828e84) to color the nodes.<a name=\"dolphins_graph\"></a>"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd, networkx as nx\n","df = pd.read_csv(bucket+'dolphins.csv', header=None)\n","G = nx.from_pandas_edgelist(df,0,1)\n","nx.draw(G,nx.spectral_layout(G),alpha=0.5,node_color='#828e84')\n","plt.axis('equal'); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["nx.draw(G,nx.spring_layout(G),alpha=0.5,node_color='#828e84')\n","plt.axis('equal'); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["nx.draw(G,nx.circular_layout(G),alpha=0.5,node_color='#828e84')\n","plt.axis('equal'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Revised simplex method.** "]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from collections import namedtuple\n","def revised_simplex(c,A,b):\n","  c, A, b = c.astype(float), A.astype(float), b.astype(float)\n","  m, n = A.shape\n","  def xi(i): z=sps.lil_matrix((m,1)); z[i] = 1; return z.tocsr()\n","  N = np.arange(n); B = np.arange(n,n+m)\n","  A = sps.hstack([sps.csr_matrix(A),sps.identity(m)],format=\"csr\")\n","  ABinv = sps.identity(m).tocsr()\n","  b = sps.csr_matrix(b)\n","  c = sps.vstack([sps.csr_matrix(c),sps.csr_matrix((m,1))])\n","  while True:\n","    J = np.argwhere( (c[N].T-(c[B].T @ ABinv) @ A[:,N]) > 0)\n","    if len(J)==0: break\n","    j = J[0,1]   \n","    q = ABinv @ A[:,N[j]]\n","    k = np.argwhere(q>0)[:,0]\n","    i = k[ np.argmin( ABinv[k,:] @ b/q[k] ) ]\n","    B[i], N[j] = N[j], B[i]\n","    ABinv -=  ((q - xi(i))/q[i][0,0]) @ ABinv[i,:]\n","  i = np.argwhere(B<n)\n","  x = np.zeros(n)\n","  for k in i.flatten(): x[B[k]] = (ABinv[k,:] @ b)[0,0]\n","  y=(c[B].T@ABinv).toarray().flatten()\n","  solution = namedtuple(\"solution\",[\"z\",\"x\",\"y\"])  \n","  return solution(z=x@c[:n],x=x,y=y)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = np.array([[2,0,1],[4,1,2],[1,1,0]])\n","c = np.array([[2],[1],[1]]);  b = np.array([[3],[2],[1]])\n","solution = revised_simplex(c,A,b)\n","print(\"outcome:\", solution.z)\n","print(\"primal solution:\", solution.x)\n","print(\"dual solution:\", solution.y)"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label3\"></a>\n## Chapter 3: Inconsistent Systems\n**Zipf's law.**  Let's use ordinary least squares to find Zipf's law coefficients for the canon of Sherlock Holmes."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd\n","data = pd.read_csv(bucket+'sherlock.csv', sep='\\t', header=None)\n","T = np.array(data[1])\n","n = len(T)\n","A = np.c_[np.ones((n,1)),np.log(np.arange(1,n+1)[:, np.newaxis])]\n","B = np.log(T)[:, np.newaxis]\n","c = la.lstsq(A,B)[0]\n","print('ordinary least squares:\\n'+str(c))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def zipf(x,c): return np.exp(c[0])*x**c[1]\n","plt.loglog(T,'r.')\n","x = np.array([1,n])\n","plt.loglog(x,zipf(x,c),'k');"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Constrained least squares.** The constrained least squares problem of solving $\\mathbf{Ax} = \\mathbf{b}$ with the constraint condition $\\mathbf{Cx}=\\mathbf{d}$:"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def constrained_lstsq(A,b,C,d):\n","  x = la.solve(np.r_[np.c_[A.T@A,C.T], \n","      np.c_[C,np.zeros((C.shape[0],C.shape[0]))]], np.r_[A.T@b,d] )\n","  return x[:A.shape[1]]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Total least squares.**  The function `tls`<a name=\"tls\"></a> solves the total least squares problem."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def tls(A,B):\n","  n = A.shape[1]\n","  _,_,Vᵀ = la.svd(np.c_[A,B])\n","  return -la.solve(Vᵀ[n:,n:],Vᵀ[n:,:n]).T"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = np.array([[2,4],[1,-1],[3,1],[4,-8]]); b = np.array([[1,1,4,1]]).T\n","x_ols = la.lstsq(A,b)[0]\n","x_tls = tls(A,b)\n","print(\"ordinary least squares:\", x_ols.T)\n","print(\"total least squares:\", x_tls.T)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Image compression.** Let's use singular value decomposition to compress an image. We'll choose a nominal rank `k = 20` for demonstration. We'll use the Frobenius norm to compute the total pixelwise error in the compressed image. Then, we'll plot out all the singular values for comparison."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = rgb2gray(getimage(bucket+'red-fox.jpg'))\n","U,σ,Vᵀ = la.svd(A)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["k = 20\n","Aₖ = U[:,:k] @ np.diag(σ[:k]) @ Vᵀ[:k,:]\n","la.norm(A-Aₖ,'fro') - la.norm(σ[k:])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["showimage(np.c_[A,Aₖ])\n","r = np.sum(A.shape)/np.prod(A.shape)*range(1,min(A.shape)+1)\n","error = 1 - np.sqrt(np.cumsum(σ**2))/la.norm(σ)\n","plt.semilogx(r,error,'.-'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Nonnegative matrix factorization.** The following code is a naive implementation of nonnegative matrix factorization using multiplicative updates (without a stopping criterion):"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def nmf(X,p=6):\n","  W = np.random.rand(X.shape[0],p)\n","  H = np.random.rand(p,X.shape[1])\n","  for i in range(50):\n","    W = W*(X@H.T)/(W@(H@H.T) + (W==0))\n","    H = H*(W.T@X)/((W.T@W)@H + (H==0))\n","  return (W,H)"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label4\"></a>\n## Chapter 4: Computing Eigenvalues\n**Eigenvalue condition number.** The function `condeig` computes the eigenvalue condition number. Let's use it on a small random matrix."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def condeig(A):\n","  w, vl, vr = la.eig(A, left=True, right=True)\n","  c = 1/np.sum(vl*vr,axis=0)\n","  return (c, vr, w)\n","A = np.random.rand(4,4)\n","condeig(A)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**PageRank.** The following minimal code computes the PageRank of the very  small graph by using the power method over 9 iterations</br><img src=\"https://raw.githubusercontent.com/nmfsc/data/master/internet_graph.svg\" alt=\"internet graph\" title=\"internet graph\" />"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["H = np.array([[0,0,0,0,1],[1,0,0,0,0], \\\n","      [1,0,0,0,1],[1,0,1,0,0],[0,0,1,1,0]])\n","v = ~np.any(H,0) \n","H = H/(np.sum(H,0)+v)\n","n = len(H) \n","d = 0.85;\n","x = np.ones((n,1))/n\n","for i in range(9):\n","  x = d*(H@x) + d/n*(v@x)  + (1-d)/n\n","x"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label5\"></a>\n## Chapter 6: Fast Fourier Transform\n**Radix-2 FFT.** This chapter introduces several naive functions. The radix-2 FFT algorithm is written as a recursive function `fftx2` and the inverse FFT is written as `ifftx2`.<a name=\"radix2fft\"></a>"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def fftx2(c):\n","  n = len(c)\n","  ω = np.exp(-2j*π/n); \n","  if np.mod(n,2) == 0:\n","    k = np.arange(n/2)\n","    u = fftx2(c[:-1:2])\n","    v = (ω**k)*fftx2(c[1::2])\n","    return np.concatenate((u+v, u-v))\n","  else:\n","    k = np.arange(n)[:,None]\n","    F = ω**(k*k.T);\n","    return  F @ c"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def ifftx2(y): return np.conj(fftx2(np.conj(y)))/len(y)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Fast Toeplitz multiplication.** The function `fasttoeplitz` computes the Toeplitz multiplication by padding out a Toeplitz matrix with zeros to make it circulant."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def fasttoeplitz(c,r,x):\n","  n = len(x)\n","  m = (1<<(n-1).bit_length())-n\n","  x1 = np.concatenate((np.pad(c,(0,m)),r[:1:-1]))\n","  x2 = np.pad(x,(0,m+n-1))\n","  return ifftx2(fftx2(x1)*fftx2(x2))[:n]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Bluestein algorithm.** The following function implements  the Bluestein algorithm using fast Toeplitz multiplication."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def bluestein(x):\n","  n = len(x)\n","  ω = np.exp((1j*π/n)*(np.arange(n)**2))\n","  return ω*fasttoeplitz(conj(ω),conj(ω),ω)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Fast Poisson solver.** The following code solves the Poisson equation using a naive fast Poisson solver and then compares the solution with the exact solution."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import dstn, idstn\n","n = 50; x = np.arange(1,n+1)/(n+1); Δx = 1/(n+1)\n","v = 2 - 2*np.cos(x*π) \n","λ = np.array([[[ (v[i]+v[j]+v[k])/Δx**2 \\\n","  for i in range(n)] for j in range(n)] for k in range(n)])\n","f = np.array([[[ (x-x**2)*(y-y**2) + \\\n","  (x-x**2)*(z-z**2)+(y-y**2)*(z-z**2) \\\n","  for x in x] for y in x] for z in x])\n","u = idstn(dstn(f,type=1)/λ,type=1)\n","U = np.array([[[ (x-x**2)*(y-y**2)*(z-z**2)/2 \\\n","  for x in x] for y in x] for z in x])             \n","la.norm(u - U)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**DCT image compression.**"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import dctn, idctn\n","def dctcompress(A,d):\n","  B = dctn(A)\n","  idx = int(d*np.prod(A.size))\n","  tol = np.sort(abs(B.flatten()))[-idx]\n","  B[abs(B)<tol] = 0\n","  return sps.csr_matrix(B), idctn(B)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = rgb2gray(getimage(bucket+\"red-fox.jpg\"))\n","_, A0 = dctcompress(A,0.001)\n","showimage(np.c_[A,A0])"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label6\"></a>\n# Part 2: Numerical Methods for Analysis\n<a name=\"label7\"></a>\n## Chapter 7: Preliminaries\nLet's start with a function that returns a double-precision floating-point representation as a string of bits."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def float_to_bin(x):\n","  if x == 0: return \"0\" * 64\n","  w, sign = (float.hex(x),0) if x > 0 else (float.hex(x)[1:],1)\n","  mantissa, exp = int(w[4:17], 16), int(w[18:])\n","  return \"{}{:011b}{:052b}\".format(sign, exp + 1023, mantissa)\n","float_to_bin(π)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Fast inverse square root.**  The following function implements the circa 1999 Q_rsqrt algorithm to approximate the reciprocal square root of a number."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def Q_rsqrt(x):\n","  i = np.float32(x).view(np.int32)\n","  i = (0x5f3759df - (i>>1)).astype(np.int32) \n","  y = i.view(np.float32)  \n","  return y * (1.5 - (0.5 * x * y * y))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["Q_rsqrt(0.01)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Rump's catastrophic cancellation.**  The answer should be `-0.827396...` What does Python come up with?"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["a = 77617; b = 33096\n","333.75*b**6+a**2*(11*a**2*b**2-b**6-121*b**4-2)+5.5*b**8+a/(2*b)"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label8\"></a>\n## Chapter 8: Solutions to Nonlinear Equations\nWe start with simple implementation of the bisection method."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def bisection(f,a,b,tolerance):\n","  while abs(b-a)>tolerance:\n","    c = (a+b)/2\n","    if np.sign(f(c))==np.sign(f(a)): a = c \n","    else: b = c\n","  return (a+b)/2"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["bisection(lambda x: np.sin(x),2,4,1e-14)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**The Mandelbrot set.** The following function takes the array `bb` for the lower-left and upper-right corners of the bounding box, `xn` for the number of horizontal pixels, and `n` for the maximum number of iterations. The function returns a two-dimensional array `M` that counts the number of iterations `k` to escape $\\{z\\in\\mathbb{C} \\mid |z^{(k)}|>2\\}$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def escape(n,z,c):   \n","  M = np.zeros_like(c,dtype=int)  \n","  for k in range(n):\n","    mask = np.abs(z)<2\n","    M[mask] += 1\n","    z[mask] = z[mask]**2 + c[mask]\n","  return M"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def mandelbrot(bb, xn=800, n=200, z=0):\n","  yn = int(np.round(xn*(bb[3]-bb[1])/(bb[2]-bb[0])))\n","  z = z*np.ones((yn,xn),dtype=complex)\n","  c = np.linspace(bb[0],bb[2],xn).reshape(1,-1) + \\\n","      1j*np.linspace(bb[3],bb[1],yn).reshape(-1,1) \n","  return escape(n,z,c)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import matplotlib.image as mpimg\n","M = mandelbrot([-0.1710,1.0228,-0.1494,1.0443])\n","mpimg.imsave('mandelbrot.png', -M, cmap='magma')\n","from PIL import Image\n","Image.open('mandelbrot.png')"]},{"cell_type": "markdown", "metadata": {}, "source": ["Imaging the Julia set uses almost identical code. The Mandelbrot set lives in the $c$-domain with an initial value $z=0$, and the Julia set lives in the $z$-domain with a given value $c$. So the code for the Julia set requires only swapping the variables `z` and `c`."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def julia(bb,xn=800,n=200,c=-0.123+0.745j):\n","  yn = int(np.round(xn*(bb[3]-bb[1])/(bb[2]-bb[0])))\n","  c = c*np.ones((yn,xn),dtype=complex)\n","  z = np.linspace(bb[0],bb[2],xn).reshape(1,-1) + \\\n","      1j*np.linspace(bb[3],bb[1],yn).reshape(-1,1) \n","  return escape(n,z,c)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import matplotlib.image as mpimg\n","J = julia([-2,-1,2,1],800,100,-1+0.3j)\n","mpimg.imsave('julia.png', -J, cmap='magma')\n","Image.open('julia.png')"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Homotopy continuation.** The following snippet of code finds a root of $$x^3-3xy^2-1 =0$$\n$$y^3-3x^2y = 0$$ with an initial guess $(x,y) = (1,1)$ using homotopy continuation: "]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","def f(x): return (np.array([x[0]**3-3*x[0]*x[1]**2-1, \n","  x[1]**3-3*x[0]**2*x[1]]))\n","def df(t,x,p): \n","  A = np.array([[3*x[0]**2-3*x[1]**2,-6*x[0]*x[1]],\n","      [-6*x[0]*x[1],3*x[1]**2-3*x[0]**2]])\n","  return la.solve(-A,p)\n","x0 = np.array([1,1])\n","sol = solve_ivp(df,[0,1],x0,args=(f(x0),))\n","sol.y[:,-1]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Gradient descent.** The following code uses the gradient descent method to find the minimum of the Rosenbrock function and plot the intermediate steps."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def plot_trace(s):\n","  x = np.linspace(-2,1,100)\n","  y = np.linspace(-0.25,3.25,100)\n","  def rosenbrock(x,y): return (1-x)**2 + 100*(y - x**2)**2\n","  plt.contour(x,y,np.sqrt(rosenbrock(x[None,:],y[:,None])),10,colors='red',alpha=0.5)\n","  plt.plot(s[:,0],s[:,1],'black')"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def df(x): return np.array([-2*(1-x[0])-400*x[0]*(x[1]-x[0]**2),\n","  200*(x[1]-x[0]**2)])\n","x = np.array([-1.8,3.0]); p = np.array([0.0,0.0])\n","α =  0.001; β = 0.9\n","s = x\n","for i in range(500):\n","  p = -df(x) + β*p\n","  x += α*p\n","  s = np.vstack((s,x))\n","plot_trace(s)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.optimize import minimize\n","def f(x): return (1-x[0])**2 + 100*(x[1] - x[0]**2)**2\n","x0 = np.array([-1.8,3.0])\n","x = minimize(f,x0)"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label9\"></a>\n## Chapter 9: Interpolation\n **Splines.** The function `spline_natural` computes the coefficients `m` of a cubic spline with natural boundary conditions through the nodes given by the arrays `x` and `y`. The function `evaluate_spline` returns a set of `n` points along the spline. The final code snippet tests these functions with several randomly selected points.<a name=\"spline_natural\"></a>"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def spline_natural(x,y):\n","  h = np.diff(x)\n","  gamma = 6*np.diff(np.diff(y)/h)\n","  C = [h[:-1],2*(h[:-1]+h[1:])]\n","  m = np.pad(la.solveh_banded(C,gamma),(1, 1))\n","  return m"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def evaluate_spline(x,y,m,n):\n","  h = np.diff(x)\n","  B = y[:-1] - m[:-1]*h**2/6\n","  A = np.diff(y)/h-h/6*np.diff(m)\n","  X = np.linspace(np.min(x),np.max(x),n+1)    \n","  i = np.array([np.argmin(i>=x)-1 for i in X])\n","  i[-1] = len(x)-2\n","  Y = (m[i]*(x[i+1]-X)**3 + m[i+1]*(X-x[i])**3)/(6*h[i]) \\\n","      + A[i]*(X-x[i]) + B[i]\n","  return (X,Y)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["x = np.linspace(0,1,8); y = np.random.rand(8)\n","m = spline_natural(x,y)\n","X,Y = evaluate_spline(x,y,m,100)\n","plt.plot(x,y,'.',X,Y); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Bézier curves.** The following function builds a Bernstein matrix. We'll then test the function on a set of points to create a cubic Bézier curve with a set of four randomly selected control points. "]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def bernstein(n,t): \n","  from scipy.special import comb\n","  k = np.arange(n+1)[None,:]\n","  return comb(n,k)*t**k*(1-t)**(n-k)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 3\n","t = np.linspace(0,1,20)[:,None]\n","p = np.random.rand(n+1,2)\n","z = bernstein(n,t)@p\n","plt.plot(p[:,0],p[:,1],'.-',alpha=0.3);\n","plt.plot(z[:,0],z[:,1]); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label10\"></a>\n## Chapter 10: Approximating Functions\n **Legendre polynomials.** We can evaluate a Legendre polynomial of order $n$ using Bonnet's recursion formula."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def legendre(x,n):\n","  if n==0: \n","    return np.ones_like(x)\n","  elif n==1:\n","    return x\n","  else:\n","    return x*legendre(x,n-1)-1/(4-1/(n-1)**2)*legendre(x,n-2)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["x = np.linspace(-1,1,100)\n","for n in range(5): plt.plot(x,legendre(x,n))\n","plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Chebyshev polynomials.** We'll construct a Chebyshev differentiation matrix and use the matrix to solve a few simple problems."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def chebdiff(n):\n","  x = -np.cos(np.linspace(0,π,n))[:,None]\n","  c = np.outer(np.r_[2,np.ones(n-2),2],(-1)**np.arange(n))\n","  D = c/c.T/(x - x.T + np.eye(n))\n","  return D - np.diag(np.sum(D,axis=1)), x"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 15\n","D,x = chebdiff(n)\n","u = np.exp(-4*x**2);\n","plt.plot(x,D@u,'.-')\n","t = np.linspace(-1,1,200);\n","plt.plot(t,-8*t*np.exp(-4*t**2)); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["D[0,:] = np.zeros((1,n)); D[0,0] = 1; u[0] = 2\n","plt.plot(x,la.solve(D,u),'.-'); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 15; k2 = 256\n","D,x = chebdiff(n)\n","L = D@D - k2*np.diag(x.flatten())\n","L[[0,-1],:] = 0; L[0,0] = 1; L[-1,-1] = 1 \n","y = la.solve(L,np.r_[2,[0]*(n-2),1].T)\n","plt.plot(x,y,'o'); \n","from scipy import special\n","k32 = np.cbrt(k2) \n","ai,_,bi,_ = special.airy([-k32,k32])\n","a = la.solve(np.c_[ai,bi],np.c_[2,1].T)\n","def sol(x): \n","  ai,_,bi,_ = special.airy(k32*x)\n","  return a[0]*ai + a[1]*bi\n","plt.plot(t,sol(t)); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["N = range(6,62,2); e = []\n","for n in N: \n","  D,x = chebdiff(n);\n","  L = D@D - k2*np.diag(x.flatten())\n","  L[[0,-1],:] = 0; L[0,0] = 1; L[-1,-1] = 1 \n","  y = la.solve(L,np.r_[2,[0]*(n-2),1][:,None])\n","  e.append(la.norm(y - sol(x),np.inf))\n","plt.semilogy(N,e,'.-');plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Wavelets.** The function `scaling` returns the scaling function (father wavelet). We can use it to generate the wavelet function (mother wavelet). As an example, we will plot the Daubechies $D_4$ with $c_k = (1+\\sqrt{3},3+\\sqrt{3},3-\\sqrt{3},1-\\sqrt{3}])/4$ and $\\phi(k) = (0,1+\\sqrt{3},1-\\sqrt{3},0)/2$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def scaling(c,z,n):\n","  m = len(c); L = 2**n\n","  ϕ = np.zeros(2*m*L) \n","  ϕ[0:m*L:L] = z\n","  for j in range(n):\n","    for i in range(m*2**j):\n","      x = (2*i+1)*2**(n-1-j)            \n","      ϕ[x] = sum([c[k]*ϕ[(2*x-k*L)%(2*m*L)] for k in range(m)])\n","  return np.arange((m-1)*L)/L,ϕ[:(m-1)*L]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["sqrt3 = np.sqrt(3)\n","c = np.array([1+sqrt3,3+sqrt3,3-sqrt3,1-sqrt3])/4\n","z = np.array([0,1+sqrt3,1-sqrt3,0])/2\n","x,ϕ = scaling(c,z,8)\n","plt.plot(x,ϕ); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["ψ = np.zeros_like(ϕ); n = len(c)-1; L = len(ϕ)//(2*n)\n","for k in range(n):\n","  ψ[k*L:(k+n)*L] += (-1)**k*c[n-k]*ϕ[::2]\n","plt.plot(x,ψ);plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**DWT image compression.** The following code explores using a discrete wavelet transform along with filtering as means of image compression."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pywt\n","def adjustlevels(x): return 1-np.clip(np.sqrt(np.abs(x)),0,1)\n","A = rgb2gray(getimage(bucket+\"laura_square.png\"))/255\n","A = pywt.wavedec2(A,'haar')\n","c, slices = pywt.coeffs_to_array(A)\n","showimage(adjustlevels(c)*255)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["level = 0.5\n","c = pywt.threshold(c,level)\n","c = pywt.array_to_coeffs(c,slices,output_format='wavedec2')\n","B = pywt.waverec2(c,'haar')\n","showimage(B*255)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Nonlinear least squares approximation.** The function `gauss_newton` solves a nonlinear least squares problem using the Levenberg–Marquardt method. The Jacobian is approximated numerically by the  function `jacobian`  using the complex-step method. The solver is then used to find the parameters for a two-Gaussian problem.<a name=\"jacobian\"></a>"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def jacobian(f,x,c):\n","  J = np.empty([len(x), len(c)])\n","  n = np.arange(len(c))\n","  for i in n:\n","    J[:,i] = np.imag(f(x,c+1e-8j*(i==n)))/1e-8\n","  return J"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def gauss_newton(f,x,y,c):\n","  r = y - f(x,c)\n","  for j in range(100):\n","    G = jacobian(f,x,c)\n","    M = G.T @ G\n","    c += la.solve(M + np.diag(np.diag(M)),G.T@r)\n","    r, r0 = y - f(x,c), r\n","    if la.norm(r-r0) < 1e-10: return c\n","  print('Gauss-Newton did not converge.')"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def f(x,c): return ( c[0]*np.exp(-c[1]*(x-c[2])**2) +\n","  c[3]*np.exp(-c[4]*(x-c[5])**2) )\n","x = 8*np.random.rand(100)\n","y = f(x,np.array([1,3,3,2,3,6])) + np.random.normal(0,0.1,100)\n","c0 = np.array([2,0.3,2,1,0.3,7])\n","c = gauss_newton(f,x,y,c0)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["X = np.linspace(0,8,100)\n","if c is not None: plt.plot(x,y,'.',X,f(X,c))"]},{"cell_type": "markdown", "metadata": {}, "source": ["In practice, we can use the scipy.optimize function `curve_fit`, which uses the Levenberg–Marquardt method for unconstrained  problems."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.optimize import curve_fit\n","def g(x,c0,c1,c2,c3,c4,c5): return f(x,[c0,c1,c2,c3,c4,c5])\n","c,_ = curve_fit(g, x, y, c0)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["plt.plot(x,y,'.',X,f(X,c)); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Logistic regression.** We'll first define the logistic function and generate synthetic data. Then, we apply Newton's method. Finally, we plot the fit logistic function."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def σ(x): return 1/(1+np.exp(-x))\n","x =  np.random.rand(30)[:,None]\n","y = (np.random.rand(30)[:,None] < σ(10*x-5))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["X, w = np.c_[np.ones_like(x),x], np.zeros((2,1))\n","for i in range(10):\n","  S = σ(X@w)*(1-σ(X@w))\n","  w += la.solve(X.T@(S*X), X.T@(y-σ(X@w)))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["plt.scatter(x,y)\n","t = np.linspace(min(x),max(x),50)\n","plt.plot(t,σ(np.c_[np.ones_like(t),t]@w))"]},{"cell_type": "markdown", "metadata": {}, "source": ["In practice, we can use the statsmodels module to do logistic regression.} %  Install the package using `!pip install statsmodels`, as needed."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import statsmodels.api as sm\n","results = sm.Logit(y, X).fit()\n","w = results.params"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["plt.scatter(x,y)\n","plt.plot(t,σ(np.c_[np.ones_like(t),t]@w))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Neural Networks.** Let's use a neural network to find a function that approximates semi-circular data."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["N = 100; θ = np.linspace(0,π,N)\n","x = np.cos(θ); x = np.c_[np.ones(N),x].T\n","y = np.sin(θ) + 0.05*np.random.randn(1,N)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 20; W1 = np.random.rand(n,2); W2 = np.random.randn(1,n)\n","def ϕ(x): return np.maximum(x,0)\n","def dϕ(x): return (x>0)\n","α = 1e-3"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["for epoch in range(10000):\n","  ŷ = W2 @ ϕ(W1@x)\n","  dLdy = 2*(ŷ-y)\n","  dLdW1 = dϕ(W1@x)* (W2.T@ dLdy) @ x.T   \n","  dLdW2 = dLdy @ ϕ(W1@x).T\n","  W1 -= 0.1 * α * dLdW1 \n","  W2 -= α * dLdW2"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["plt.scatter(x[1,:],y,color='#ff000050')\n","x̂ = np.linspace(-1.2,1.2,200); x̂ = np.c_[np.ones_like(x̂),x̂].T\n","ŷ = W2 @ ϕ(W1@x̂)\n","plt.plot(x̂[1,:],ŷ[0],color='#000000')\n","plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["N = 100; θ = np.linspace(0,π,N)\n","x = np.cos(θ); x = np.c_[np.ones(N),x].T\n","y = np.sin(θ) + 0.05*np.random.randn(1,N)\n","n = 20; W1 = np.random.rand(n,2); W2 = np.random.randn(1,n)\n","def ϕ(x): return 1/(1+np.exp(-x))\n","def dϕ(x): return ϕ(x)*(1-ϕ(x))\n","α = 1e-1\n","for epoch in range(10000):\n","  ŷ = W2 @ ϕ(W1@x)\n","  L = la.norm(ŷ-y)\n","  dLdy = 2*(ŷ-y)/L\n","  dLdW1 = dϕ(W1@x)* (W2.T@ dLdy) @ x.T   \n","  dLdW2 = dLdy @ ϕ(W1@x).T\n","  W1 -= 0.1*α * dLdW1 \n","  W2 -= α * dLdW2 \n","plt.scatter(x[1,:],y,color='#ff000050')\n","x̂ = np.linspace(-1.2,1.2,200); x̂ = np.c_[np.ones_like(x̂),x̂].T\n","ŷ = W2 @ ϕ(W1@x̂)\n","plt.plot(x̂[1,:],ŷ[0],color='#000000');plt.ylim(-0.25,1.25)\n","plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","n = 20; N = 100; \n","θ = tf.linspace(0.0,π,N)\n","x = tf.math.cos(θ); y = tf.math.sin(θ) + 0.05*tf.random.normal([N])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["model = keras.Sequential(\n","  [\n","    layers.Dense(n, input_dim=1, activation='relu'),\n","    layers.Dense(1)\n","  ]\n",")\n","model.compile(loss='mean_squared_error', optimizer='SGD')\n","model.fit(x,y,epochs=2000,verbose=0)\n","ŷ = model.predict(x)\n","plt.plot(x,ŷ,color='#000000'); plt.scatter(x,y,color='#ff000050')"]},{"cell_type": "markdown", "metadata": {}, "source": ["The solution above used the default gradient descent model. We can also choose a specialized optimizer. Let's change the learning rate and add momentum."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["optimizer = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n","model.compile(loss='mean_squared_error', optimizer=optimizer)\n","model.fit(x,y,epochs=2000,verbose=0)\n","ŷ = model.predict(x)\n","plt.plot(x,ŷ,color='#000000'); plt.scatter(x,y,color='#ff000050')"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label11\"></a>\n## Chapter 11: Differentiation and Integration\n Let's compute the coefficients to the third-order approximation to $f'(x)$ using nodes at $x-h$, $x$, $x+h$ and $x+2h$. We can use the function `rats` <a name=\"rats\"></a> to rewrite the floating-point approximation for the coefficients given by `C[1,:]` as fractions"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["d = np.array([-1,0,1,2])[:,None]\n","n = len(d)\n","V = d**np.arange(n) / [np.math.factorial(i) for i in range(n)]\n","C = la.inv(V)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from fractions import Fraction\n","def rats(x): return str(Fraction(x).limit_denominator())\n","[rats(x) for x in C[1,:]]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Richardson extrapolation.** $D(\\phi(x))$ of a finite difference operator $\\phi(x)$.<a name=\"richardson_extrapolation\"></a>"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def richardson(f,x,m,n):\n","  if n==0: return ϕ(f,x,2**m) \n","  return (4**n*richardson(f,x,m,n-1)-richardson(f,x,m-1,n-1))/(4**n-1)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def ϕ(f,x,n): return (f(x+1/n) - f(x-1/n))/(2/n)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["richardson(lambda x: np.sin(x),0,4,4)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Automatic differentiation.** <a name=\"dualclass\"></a> We can build a minimal working example of forward accumulation automatic differentiation by defining a class and overloading the base operators.  We'll verify the code using the function $x + \\sin x$. "]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["class Dual:\n","  def __init__(self, value, deriv=1):\n","    self.value = value\n","    self.deriv = deriv\n","  def __add__(u, v):\n","    return Dual(value(u) + value(v), deriv(u) + deriv(v))\n","  __radd__ = __add__\n","  def __sub__(u, v):\n","    return Dual(value(u) - value(v), deriv(u) - deriv(v))\n","  __rsub__ = __sub__\n","  def __mul__(u, v):\n","    return Dual(value(u)*value(v), \n","        value(v)*deriv(u) + value(u)*deriv(v))\n","  __rmul__ = __mul__\n","  def sin(u):\n","    return Dual(sin(value(u)),cos(value(u))*deriv(u))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def value(x): \n","  return (x.value if isinstance(x, Dual) else x)\n","def deriv(x): \n","  return (x.deriv if isinstance(x, Dual) else 0)\n","def sin(x): return np.sin(x) \n","def cos(x): return np.cos(x) \n","def auto_diff(f,x): \n","    return f(Dual(x)).deriv"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["auto_diff(lambda x: x + sin(x),0)"]},{"cell_type": "markdown", "metadata": {}, "source": ["Now, let's apply the code above to compute the Jacobian of the system $$y_1 = x_1x_2 + \\sin x_2$$$$y_2 = x_1x_2 - \\sin x_2$$ evaluated at $(x_1,x_2) = (2,\\pi)$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["x1 = Dual(2,np.array([1,0]))\n","x2 = Dual(π,np.array([0,1]))\n","y1 = x1*x2 + sin(x2)\n","y2 = x1*x2 - sin(x2)\n","[y1.value,y2.value,y1.deriv,y2.deriv]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Romberg method.** We can use the following trapezoidal quadrature  to make a Romberg method using Richardson extrapolation. We first define the function `trapezoidal` for composite trapezoidal quadrature. By redefining `phi` to be `trapezoidal`, we can simply apply the function `D` that we used to define Richardson extrapolation. We'll verify the code by integrating $\\sin x$ from $0$ to $\\pi/2$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def trapezoidal(f,x,n): \n","  F = f(np.linspace(x[0],x[1],n+1))\n","  return (F[0]/2 + sum(F[1:-1]) + F[-1]/2)*(x[1]-x[0])/n\n","def ϕ(f,x,n): return trapezoidal(f,x,n)\n","richardson(lambda x: np.sin(x),[0,π/2],4,4)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Composite trapezoidal method.** Let's examine the convergence rate for the composite trapezoidal rule applied to the function $f(x) = x + (x - x^2)^p$ over the interval $[0,2]$ with $p = 1,2,\\dots,7$. We can do this by finding the logl-og slope of the error as a function of subintervals $n$. We find that the error of the trapezoidal rule is $O(n^2)$ when $p=1$, $O(n^4)$ when $p$ is 2 or 3, $O(n^6)$ when $p$ is 4 or 5, and so on."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = np.logspace(1,2,num=10).astype(int)\n","error = np.zeros((10,7))\n","def f(x,p): return ( x + x**p*(2-x)**p )\n","for p in range(1,8):\n","  S = trapezoidal(lambda x: f(x,p),(0,2),10**6)\n","  for i in range(len(n)):\n","    Sn = trapezoidal(lambda x: f(x,p),(0,2),n[i])\n","    error[i,p-1] =  abs(Sn - S)/S\n","np.log(error)  \n","A = np.c_[np.log(n),np.ones_like(n)]\n","x = np.log(error)\n","s = np.linalg.lstsq(A,x,rcond=None)[0][0]\n","info = ['{0}: slope={1:0.1f}'.format(k+1,s[k]) for k in range(7)]\n","lines = plt.loglog(n,error)\n","plt.legend(lines, info); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Clenshaw–Curtis quadrature.** applies the trapezoidal rule to a discrete cosine transform (type-1) as a means of numerically evaluating the integral $\\int_{-1}^{1} f(x) \\,\\mathrm{d}x$.  We'll test the integral on the function $f(x) = 8 \\cos x^2$, with an integral of approximately 0.566566"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def clenshaw_curtis(f,n):\n","  x = np.cos(π*np.arange(n+1)/n)\n","  w = np.zeros(n+1); w[0:n+1:2] = 2/(1-np.arange(0,n+1,2)**2)\n","  return ( 1/n * np.dot(dctI(f(x)), w) )"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import dct\n","def dctI(f):\n","  g = dct(f,type=1)\n","  return ( np.r_[g[0]/2, g[1:-1], g[-1]/2] )"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["clenshaw_curtis(lambda x: np.cos(8*x**2),20)"]},{"cell_type": "markdown", "metadata": {}, "source": ["A mathematical comment: we could have also  defined a type-1 DCT explicitly in terms of its underlying FFTs if we wanted to crack the black box open just a wee bit more."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import fft\n","def dctI(f):\n","  n = len(f)\n","  g = np.real(fft(np.r_[f, f[n-2:0:-1]]))\n","  return ( np.r_[g[0]/2, g[1:n-1], g[n-1]/2] )"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Gauss–Legendre quadrature.** We first compute the Legendre weights and nodes and then apply Gauss–Legendre quadrature to compute $$\\int_{-1}^{1} \\cos x \\cdot \\mathrm{e}^{-x^2} \\,\\mathrm{d}x$$ using a nominal number of nodes $n=8$.  Alternatively, we can use the NumPy  function `leggauss` to compute the nodes and weights for Gauss–Legendre quadrature."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def gauss_legendre(n):\n","  a = np.zeros(n)  \n","  b = np.arange(1,n)**2 / (4*np.arange(1,n)**2 - 1)\n","  scaling = 2\n","  nodes, v = la.eigh_tridiagonal(a, np.sqrt(b))\n","  return ( nodes, scaling*v[0,:]**2 )"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 8\n","def f(x): return np.cos(x)*np.exp(-x**2)\n","nodes, weights = gauss_legendre(n)\n","np.dot(f(nodes), weights)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["nodes, weights = np.polynomial.legendre.leggauss(n)\n","np.dot(f(nodes), weights)"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label12\"></a>\n# Part 3: Numerical Differential Equations\n<a name=\"label13\"></a>\n## Chapter 12: Ordinary Differential Equations\n Let's plot the boundary of the region of absolute stability for BDF2: $$z = \\frac{\\frac{3}{2} r^2 - 2 r + \\frac{1}{2}}{r^2}$$"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["r = np.exp(2j*π*np.linspace(0,1,100))\n","z = (3/2*r**2 - 2*r + 0.5)/r**2\n","plt.plot(z.real,z.imag); plt.axis('equal'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Multistep coefficients.** The function `multistepcoefficients` determines the multistep coefficients for stencil given by `m` and `n`. The function `plotstability` uses these coefficients to plot boundary of the region of absolute stability. We'll test it on the Adams–Moulton method with input `m = [0 1]` and `n = [0 1 2]`.<a name=\"multistepcoefficients\"></a>"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def multistepcoefficients(m,n):\n","  s = len(m) + len(n) - 1\n","  A = (np.array(m)+1)**np.c_[range(s)]\n","  B = [[i*((j+1)**max(0,i-1)) for j in n] for i in range(s)]\n","  c = la.solve(-np.c_[A[:,1:],B],np.ones((s,1))).flatten()\n","  return ( np.r_[1,c[:len(m)-1]], c[len(m)-1:] )"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def plotstability(a,b):\n","  r = np.exp(1j*np.linspace(0,2*π,200))\n","  z = [np.dot(a,r**np.arange(len(a))) / \\\n","       np.dot(b, r**np.arange(len(b))) for r in r]\n","  plt.plot(np.real(z),np.imag(z)); plt.axis('equal')"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = [0,1]; n = [0,1,2]\n","a,b = multistepcoefficients(m,n)\n","plotstability(a,b)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Recipe for solving an ODE.** The general recipe for solving an ODE is to\n1. Load the module\n1. Set up the parameters\n1. Choose the method\n1. Solve the problem\n1. Present the solution\n\nLet's apply this recipe to solve the pendulum problem $u'' = \\sin u$ with initial conditions $u(0) = \\pi/9$ and $u'(0) = 0$ over $t\\in[0,8\\pi]$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import numpy as np; import matplotlib.pyplot as plt\n","from scipy.integrate import solve_ivp\n","def pndlm(t,u): return u[1],-np.sin(u[0])\n","u0 = [8*π/9,0]; tspan = [0,8*π]\n","mthd = 'RK23'\n","sltn = solve_ivp(pndlm,tspan,u0,method=mthd)\n","plt.plot(sltn.t,sltn.y[0,:],'.-')\n","plt.plot(sltn.t,sltn.y[1,:],'.-')\n","plt.legend(labels=['θ','ω']); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["The values of `sltn.t` are those determined and used for adaptive time stepping. Higher-order methods such as `DOP853` that use smoother interpolating polynomials produce rougher (though still accurate) plots than lower-order methods such as `RK23`:"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["mthd = 'DOP853'\n","sltn = solve_ivp(pndlm,tspan,u0,method=mthd)\n","plt.plot(sltn.t,sltn.y[0,:],'.-')\n","plt.plot(sltn.t,sltn.y[1,:],'.-')\n","plt.legend(labels=['θ','ω']); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["We can request a continuous solution by setting `dense_output=True`.  In this case, `solve_ivp` returns an additional field `sol` that we can think of as a function of the independent variable:"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["sltn = solve_ivp(pndlm,tspan,u0,method=mthd,dense_output=True)\n","t = np.linspace(tspan[0],tspan[1],200)\n","y = sltn.sol(t)\n","plt.plot(t,y[0],t,y[1])\n","plt.legend(labels=['θ','ω']); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Differential-algebraic equations.** The pendulum problem."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def pendulum(t,U,p):\n","  x,y,u,v = U; ℓ,g,m = p\n","  x = x/ℓ; y = y/ℓ; u = -v*y/x       # manifold projection\n","  τ = m*(u**2 + v**2 + g*y)/ℓ**2\n","  return (u, v, -τ*x/m, -τ*y/m + g)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","θ = π/3; ℓ = 1; tspan = (0,30.0)\n","U = (ℓ*np.sin(θ), -ℓ*np.cos(θ), 0, 0)\n","sol = solve_ivp(pendulum, tspan, U, args=((ℓ,1,1),),\n","    method='RK45',dense_output=True)\n","t = np.linspace(0,tspan[1],2000); \n","x,y = sol.sol(t)[:2,:]\n","plt.plot(x,y); plt.gca().invert_yaxis(); plt.gca().axis('equal');"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Gauss–Legendre–Lobatto orthogonal collocation** The following code solves the pendulum problem using orthogonal collocation."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def gauss_legendre(n,lobatto=False):\n","  a = np.zeros(n)  \n","  b = np.arange(1,n)**2 / (4*np.arange(1,n)**2 - 1)\n","  if lobatto: b[-1] = (n-1)/(2*(n-1) - 1)\n","  scaling = 2\n","  nodes, v = la.eigh_tridiagonal(a, np.sqrt(b))\n","  return ( nodes, scaling*v[0,:]**2 )\n","\n","def differentiation_matrix(n,Δt=1):\n","  nodes, _ = gauss_legendre(n+1,lobatto=True)\n","  t = (nodes[1:]+1)/2\n","  A = np.vander(t,increasing=True)*np.arange(1,n+1)\n","  B = np.diag(t)@np.vander(t,increasing=True)\n","  return (A@la.inv(B)/Δt, t)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.optimize import fsolve\n","n = 6; N = 100; Δt = 30/N\n","θ = π/3; ℓ = 1\n","u0 = [ℓ*np.sin(θ), -ℓ*np.cos(θ), 0, 0, 0]\n","u = np.concatenate([np.tile(i,n) for i in u0])\n","M,t = differentiation_matrix(n,Δt) \n","def D(u,u0): return M@(u - u0)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def pendulum(U,U0,n):\n","  x,y,u,v,τ = U[:n],U[n:2*n],U[2*n:3*n],U[3*n:4*n],U[4*n:5*n]\n","  x0,y0,u0,v0,τ0 = U0\n","  ℓ,g,m = (1,1,1)\n","  return np.r_[D(x,x0) - u,\n","    D(y,y0) - v,\n","    D(u,u0) + τ*x/m,\n","    D(v,v0) + τ*y/m - g,\n","    x**2 + y**2 - ℓ**2]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["U = u.reshape(5,-1)\n","for i in range(N):\n","  u0 = U[:,-1]\n","  u = fsolve(pendulum,u,args=(u0,n))\n","  U = np.c_[U,u.reshape(5,-1)]\n","plt.plot(U[0,:],U[1,:]); plt.gca().axis('equal')\n","plt.gca().invert_yaxis(); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["Alternatively, we can use the `GEKKO` library to automate orthogonal collocation"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["!pip install gekko\n","from gekko import GEKKO\n","m = 1; g = 1; ℓ = 1; θ = π/3\n","model = GEKKO()\n","x = model.Var(ℓ*np.sin(θ))\n","y = model.Var(-ℓ*np.cos(θ))\n","u = model.Var(0)\n","v = model.Var(0)\n","τ = model.Var(m*ℓ*g*np.cos(θ)/2)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["model.Equation(x.dt()==u)\n","model.Equation(y.dt()==v)\n","model.Equation(m*u.dt()==-τ*x)\n","model.Equation(m*v.dt()==-τ*y + m*g)\n","model.Equation(x**2+y**2==ℓ**2)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["model.time = np.linspace(0,30,200)\n","model.options.IMODE=4        # dynamic mode\n","model.options.NODES=3        # number of collocation nodes\n","model.solve(disp=False)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["plt.plot(x.value,y.value); plt.gca().axis('equal')\n","plt.gca().invert_yaxis(); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label14\"></a>\n## Chapter 13: Parabolic Equations\n**Heat equation using the backward Euler method.** Let's solve the heat equation using the backward Euler method with initial conditions given by a rectangular function and absorbing boundary conditions."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import timeit\n","start_time = timeit.default_timer()\n","Δx = .01; Δt = .01; L = 2; c = Δt/Δx**2; uL = 0; uR = 0;\n","x = np.arange(-L,L,Δx); n = len(x) \n","u = (abs(x)<1)\n","u[0] += 2*c*uL; u[n-1] += 2*c*uR; \n","D = np.tile(np.array([[-c,1+2*c,-c]]).T,(1,n))\n","D[0,1] = 0; D[2,n-2] = 0\n","for i in range(20):\n","  u = la.solve_banded((1, 1), D, u)\n","elapsed_time = timeit.default_timer() - start_time\n","plt.plot(x,u);plt.show()\n","print(\"elapsed time = \"+str(elapsed_time))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Heat equation using the Crank–Nicolson method.** Let's solve the heat equation again using the Crank–Nicolson method with initial conditions given by a rectangular function. This time we'll use reflecting boundary conditions. Notice how the high-frequency information does not decay as it did when using the backward Euler method."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.sparse.linalg import spsolve\n","Δx = .01; Δt = .01; L = 2; ν = Δt/Δx**2\n","x = np.arange(-L,L,Δx); n = len(x) \n","u = (abs(x)<1)\n","diagonals = [np.ones(n-1), -2*np.ones(n), np.ones(n-1)]\n","D = sps.diags(diagonals, [-1,0,1], format='csr')\n","D[0,1] *= 2; D[-1,-2] *= 2\n","A = 2*sps.identity(n) + ν*D \n","B = 2*sps.identity(n) - ν*D \n","for i in range(20):\n","  u = spsolve(B,A@u)\n","plt.plot(x,u); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Porous medium equation.** We'll now solve the porous medium equation $u_t = (u^2u_x)_x$ using an adaptive-step BDF routine."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","n = 400; L = 2; x,Δx = np.linspace(-L,L,n,retstep=True)\n","def m(u): return u**2\n","def Du(t,u): \n","  return np.r_[0,np.diff(m((u[:-1]+u[1:])/2)*np.diff(u))/Δx**2,0]\n","u0 = (abs(x)<1)\n","sol = solve_ivp(Du, [0,2], u0, method='LSODA',\\\n","  lband=1,uband=1,dense_output=True)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from ipywidgets import interactive\n","def anim(t=0):\n","  plt.fill_between(x,sol.sol(t),color='#ff9999');\n","  plt.ylim(0,1);plt.show()\n","interactive(anim, t = (0,2,0.01))"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label15\"></a>\n## Chapter 16: Fourier Spectral Methods\n**Heat equation.** The formal solution to the heat equation is $$u(t,x) = \\mathrm{F}^{-1}\\left[  \\mathrm{e}^{-\\xi^2 t}  \\mathrm{F} u(0,x) \\right].$$"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from numpy.fft import fft,ifft, fftfreq\n","n = 256; ℓ = 4\n","ξ2 = (fftfreq(n,1/n)*(2*π/L))**2\n","def u(t,u0): return np.real(ifft(np.exp(-ξ2*t)*fft(u0)))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["x = np.linspace(-L/2,L/2,n,endpoint=False)\n","u0 = (np.abs(x)<1)\n","plt.plot(x,u(0.1,u0)); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**Navier–Stokes equation.** We solve the Navier–Stokes equation in three parts: define the functions, initialize the variables, and iterate over time."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from numpy.fft import fft2,ifft2,fftfreq\n","def cdiff(Q,step=1): return Q-np.roll(Q,step,0)\n","def flux(Q,c): return c*cdiff(Q,1) - \\\n","  0.5*c*(1-c)*(cdiff(Q,1)+cdiff(Q,-1))\n","def H(u,v,iξx,iξy): return fft2(ifft2(u)*ifft2(iξx*u) + \\\n","  ifft2(v)*ifft2(iξy*u))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["ℓ, n, Δt, ϵ = 2, 128, 0.001, 0.001; Δx = ℓ/n \n","x = np.linspace(Δx,ℓ,n)[None,:]; y = x.T\n","q = 0.5*(1+np.tanh(10*(1-np.abs(ℓ/2 - y)/(ℓ/4))))\n","Q = np.tile(q, (1,n))\n","u = Q*(1+0.5*np.sin(ℓ*π*x))  \n","v = np.zeros_like(u) \n","u,v = fft2(u),fft2(v)\n","us,vs = u,v\n","iξx = (1j*fftfreq(n)*n*(2*π/ℓ))[None,:]\n","iξy = iξx.T\n","ξ2 = iξx**2+iξy**2\n","Hx, Hy = H(u,v,iξx,iξy), H(v,u,iξy,iξx)  \n","M1 = 1/Δt + (ϵ/2)*ξ2\n","M2 = 1/Δt - (ϵ/2)*ξ2"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["for i in range(1200):\n","  Q -= flux(Q,(Δt/Δx)*np.real(ifft2(v))) + \\\n","    flux(Q.T,(Δt/Δx)*np.real(ifft2(u)).T).T\n","  Hxo, Hyo = Hx, Hy\n","  Hx, Hy = H(u,v,iξx,iξy), H(v,u,iξy,iξx)           \n","  us = u - us + (-1.5*Hx + 0.5*Hxo + M1*u)/M2\n","  vs = v - vs + (-1.5*Hy + 0.5*Hyo + M1*v)/M2\n","  ϕ = (iξx*us + iξy*vs)/(ξ2+(ξ2==0)) \n","  u, v =  us - iξx*ϕ, vs - iξy*ϕ\n","plt.imshow(Q,'seismic'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label16\"></a>\n# Part 4: Solutions\n<a name=\"label17\"></a>\n## Numerical Linear Algebra\n**1.4. Invertibility of random (0,1) matrices.** The number of invertible $n\\times n$ (0,1) matrices is known for $n$ up to 8. (See the [On-Line Encyclopedia of Integer Sequences](http://oeis.org/A055165).) We'll approximate the ratio of invertible matrices by checking the determinants of randomly drawn ones. "]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["N = 10000; n = np.zeros(20)\n","def mat_01(d): return np.random.choice((0,1),size=(d,d))\n","for d in range(20):\n","  n[d] = sum([np.linalg.det(mat_01(d))!=0 for i in range(N)])\n","plt.plot(range(1,21),n/N,'.-'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**2.3. Naive algorithm for the determinant.** The determinant of  matrix $\\mathbf{A}$ is given by the product of the elements along the diagonal of $\\mathbf{U}$ multiplied by the parity of the permutation matrix $\\mathbf{P}$ from the LU decomposition $\\mathbf{PLU} = \\mathbf{A}$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def det(A):\n","  P,L,U = la.lu(A)\n","  s = 1\n","  for i in range(len(P)):\n","    try:\n","      m = np.argwhere(P[i+1:,i]).item(0)+1\n","      P[[i,i+m],:] = P[[i+m,i],:] \n","      s *= -1\n","    except:\n","      pass\n","  return s*np.prod(np.diagonal(U))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = np.random.rand(20,20)\n","det(A) - la.det(A)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**2.4. Good Will Hunting problem.** The following function computes the number of walks for $n$-step walks for the graph</br><img src=\"https://raw.githubusercontent.com/nmfsc/data/master/good_will_hunting.svg\" alt=\"good will hunting graph\" title=\"good will hunting graph\" />"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = np.array([[0,1,0,1],[1,0,2,1],[0,2,0,0],[1,1,0,0]])\n","def walks(A,i,j,N): \n","  return [np.linalg.matrix_power(A,n+1)[i-1,j-1] for n in range(N)]\n","walks(A,1,3,9)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**2.5. Reverse Cuthill–McKee algorithm.** The following function implements a naive reverse Cuthill–McKee algorithm  for symmetric matrices. We'll verify the algorithm by applying it to a sparse, random (0,1) matrix."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def rcuthillmckee(A):\n","  r = np.argsort(np.bincount(A.nonzero()[0]))\n","  while r.size:\n","    q = np.atleast_1d(r[0])\n","    r = np.delete(r,0)\n","    while q.size:\n","      try: p = np.append(p,q[0])\n","      except: p = np.atleast_1d(q[0])\n","      k = sps.find(A[q[0],[r]])[1]\n","      q = np.append(q[1:],r[k])\n","      r = np.delete(r,k)\n","  return np.flip(p)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = sps.random(1000,1000,0.001); A += A.T\n","p = rcuthillmckee(A)\n","fig, (ax1, ax2) = plt.subplots(1, 2)\n","ax1.spy(A,ms=1); ax2.spy(A[p[:,None],p],ms=1)\n","plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**2.6. Dolphins of Doubtful Sound.**  We'll reuse the code [above](#dolphins_graph) used to draw the original graph of the dolphins."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd, networkx as nx\n","df = pd.read_csv(bucket+'dolphins.csv', header=None)\n","G = nx.from_pandas_edgelist(df,0,1)\n","nx.draw(G,nx.circular_layout(G),alpha=0.5,node_color='#828e84')\n","plt.axis('equal'); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = nx.adjacency_matrix(G)\n","p = rcuthillmckee(A)\n","A = A[p[:,None],p]\n","G = nx.from_scipy_sparse_array(A)\n","nx.draw(G,nx.circular_layout(G),alpha=0.5,node_color='#828e84')\n","plt.axis('equal'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**2.8. Stigler diet problem.** Let's solve the Stigler diet problem. We'll use the  naïve [`simplex`](#simplex) function defined above."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def get_pivot(tableau):\n","  j = np.argmax(tableau[-1,:-1]>0)\n","  a, b = tableau[:-1,j], tableau[:-1,-1]\n","  k = np.argwhere(a > 0)\n","  i = k[np.argmin(b[k]/a[k])]\n","  return (i,j)\n","\n","def row_reduce(tableau):\n","  i,j = get_pivot(tableau)\n","  G = tableau[i,:]/tableau[i,j]\n","  tableau -= tableau[:,j].reshape(-1,1)*G\n","  tableau[i,:] = G\n","\n","from collections import namedtuple\n","def simplex(c,A,b):\n","  m,n = A.shape\n","  tableau = np.r_[np.c_[A,np.eye(m),b], \\\n","    np.c_[c.T,np.zeros((1,m)),0]]\n","  while (any(tableau[-1,:n]>0)): row_reduce(tableau)\n","  p = np.argwhere(tableau[-1,:n] != 0) \n","  x = np.zeros(n)\n","  for i in p.flatten(): \n","    x[i] = np.dot(tableau[:,i],tableau[:,-1])\n","  z = -tableau[-1,-1]\n","  y = -tableau[-1,range(n,n+m)]\n","  solution = namedtuple(\"solution\",[\"z\",\"x\",\"y\"])       \n","  return solution(z,x,y)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd\n","diet = pd.read_csv(bucket+'diet.csv')\n","A = diet.values[1:,3:].T\n","b = diet.values[0,3:][:,None]\n","c = np.ones(((A.shape)[1],1))\n","food = diet.values[1:,0]\n","solution = simplex(b,A.T,c)\n","print(\"value: \", solution.z)\n","i = np.argwhere(solution.y!=0).flatten()\n","print(\"foods: \", food[i])"]},{"cell_type": "markdown", "metadata": {}, "source": ["In practice, we can use `scipy.optimize.linprog`."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy import optimize \n","solution = optimize.linprog(c,-A,-b,method='highs')\n","solution.fun, food[np.where(solution.x>1e-12)]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**2.9. Six degrees of Kevin Bacon.** Let's determine the shortest path between two actors along with their connecting movies. We'll first define helper functions `get_names`<a name=\"get_names\"></a> and `get_adjacency_matrix`<a name=\"get_adjacency_matrix\"></a>. Then we'll build an biadjacency matrix $\\mathbf{B}$ and construct the adjacency matrix $$\\mathbf{A} = \\begin{bmatrix} \\mathbf{0} & \\mathbf{B}^\\mathsf{T} \\\\ \\mathbf{B} & \\mathbf{0}\\end{bmatrix}.$$"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def get_names(filename):\n","  return np.genfromtxt(bucket+filename+'.txt',delimiter='\\n',\\\n","    dtype=\"str\",encoding=\"utf8\").tolist()\n","def get_adjacency_matrix(filename):\n","  i = np.genfromtxt(bucket+filename+'.csv',delimiter=',',dtype=int)\n","  return sps.csr_matrix((np.ones_like(i[:,0]), (i[:,0]-1,i[:,1]-1)))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["actors = get_names(\"actors\")\n","movies = get_names(\"movies\")\n","B = get_adjacency_matrix(\"actor-movie\")\n","A = sps.bmat([[None,B.T],[B,None]],format='csr')\n","actormovie = np.r_[actors,movies]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def findpath(A,a,b):\n","  p = -np.ones(A.shape[1],dtype=np.int64)\n","  q = [a]; p[a] = -9999; i = 0\n","  while i<len(q):\n","    k = sps.find(A[q[i],:])[1]\n","    k = k[p[k]==-1]\n","    q.extend(k)\n","    p[k] = q[i]; i += 1\n","    if any(k==b): return backtrack(p,b)\n","  display(\"No path.\")"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def backtrack(p,b):\n","  s = [b]; i = p[b]\n","  while i != -9999: s.append(i); i = p[i]\n","  return s[::-1]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["a = actors.index(\"Bruce Lee\"); b = actors.index(\"Tommy Wiseau\")\n","actormovie[findpath(A,a,b)].tolist()"]},{"cell_type": "markdown", "metadata": {}, "source": ["In practice, we can use the `shortest_path` function from the scipy.sparse.csgraph library or networkx library"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["a = actors.index(\"Bruce Lee\"); b = actors.index(\"Tommy Wiseau\")\n","_,p = sps.csgraph.shortest_path(A,indices=a,return_predecessors=True)\n","actormovie[backtrack(p,b)].tolist()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import networkx as nx\n","G = nx.from_scipy_sparse_array(A)\n","a = actors.index(\"Emma Watson\"); b = actors.index(\"Kevin Bacon\")\n","i = nx.shortest_path(G,a,b)\n","actormovie[i].tolist()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**2.10. Sparse matrix storage efficiency.**"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["d = 2/3; A = sps.rand(60,80,format='csr',density=d)\n","nbytes = A.data.nbytes + A.indptr.nbytes + A.indices.nbytes\n","nbytes, 4*(3*d*np.prod(A.shape) + A.shape[0] + 1)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**3.4. Image deblurring.** Take `X` to grayscale image (with pixel intensity between 0 and 1), `A` and `B`  to be Gaussian blurring matrices with standard deviations of 20 pixels, and `N` to be a matrix of random values  from the uniform distribution over the interval (0,0.01). We'll compare three deblurring methods: inverse, Tikhonov regulation, and the pseuodinverse. We can find a good value for regulariation parameter α = 0.05 with some trial-and-error."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["X = rgb2gray(getimage(bucket+\"laura.png\"))\n","m,n = X.shape\n","def blur(x): return np.exp(-(x/20)**2/2)\n","A = [[blur(i-j) for i in range(m)] for j in range(m)]\n","A /= np.sum(A,axis=1)\n","B = [[blur(i-j) for i in range(n)] for j in range(n)]\n","B /= np.sum(B,axis=0)\n","N = 0.01*np.random.rand(m,n)\n","Y = A@X@B + N"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["α = 0.05\n","X1 = la.lstsq(A,Y)[0]\n","X2 =  la.solve(A.T@A+α**2*np.eye(m),A.T@Y).T\n","X2 =  la.solve(B@B.T+α**2*np.eye(n),B@X2).T\n","X3 =  la.pinv(A,α) @ Y @ la.pinv(B,α)\n","showimage(np.c_[X,Y,X1,X2,X3])"]},{"cell_type": "markdown", "metadata": {}, "source": ["**3.5. Filippelli problem.** The National Institute for Standards and Technology (NIST) contrived the Filippelli dataset to benchmark linear regression software. The Filippelli problem consists of fitting a 10th degree polynomial to the data set⁠—a rather ill-conditioned problem. We first need to download the data. Then we'll define three methods for solving the Vandermonde problem: the normal equation, QR decomposition, and the pseudoinverse."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd\n","df = pd.read_csv(bucket+'filip.csv',header=None)\n","y,x = np.array(df[0]),np.array(df[1])\n","coef = pd.read_csv(bucket+'filip-coeffs.csv',header=None)\n","β = np.array(coef[0])[None,:]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def solve_filip(x,y):\n","  V = vandermonde(x,11)\n","  Q,R = la.qr(V,mode='economic') \n","  c = np.zeros((3,11),float)\n","  c[0,:] = la.solve(V.T@V,V.T@y)\n","  c[1,:] = la.solve(R,Q.T@y)\n","  c[2,:] = la.pinv(V,1e-14)@y\n","  r = [la.norm(V@c[i,:].T-y) for i in range(3)]\n","  return (c,r)\n","def build_poly(c,x): \n","  return vandermonde(x,len(c))@c\n","def vandermonde(x,n): \n","  return np.vander(x,n,increasing=True)"]},{"cell_type": "markdown", "metadata": {}, "source": ["Now, let's solve the problem and plot the results. Let's also list the coefficients from each method alongside the official NIST coefficients. What do you notice about the coefficients? What methods performs the best?"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["b,r = solve_filip(x,y)\n","X = np.linspace(min(x),max(x),200)\n","b = np.r_[b,β]\n","plt.scatter(x,y,color='#0000ff40')\n","for i in range(4): \n","  plt.plot(X,build_poly(b[i],X))\n","plt.ylim(0.7,0.95);plt.show()\n","coef.assign(β1=b[0], β2=b[1], β3=b[2])"]},{"cell_type": "markdown", "metadata": {}, "source": ["What makes the Filippelli problem difficult is that the system's huge condition number. We can reduce the condition number by first standardizing the data before using it⁠—i.e., subtracting the mean and dividing by the standard deviation. Look at the difference in condition numbers of the Vandermonde matrix before and after standardizing the data."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def zscore(X,x): return (X - x.mean())/x.std()\n","k1 = np.linalg.cond(vandermonde(x,11))\n","k2 = np.linalg.cond(vandermonde(zscore(x,x),11))\n","print(\"Condition numbers of the Vandermonde matrix:\")\n","print(\"{:e}\".format(k1))\n","print(\"{:e}\".format(k2))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["c,r = solve_filip(zscore(x,x),zscore(y,y))\n","plt.scatter(x,y,color='#0000ff40')\n","for i in range(3):\n","  Y = build_poly(c[i],zscore(X,x))*y.std() + y.mean()\n","  plt.plot(X, Y)\n","plt.show()\n","la.norm(c[0]-c[1]),la.norm(c[0]-c[2])"]},{"cell_type": "markdown", "metadata": {}, "source": ["**3.7. Modeling daily temperatures.** We'll use $u(t) = c_1 \\sin(2\\pi t) + c_2 \\cos(2\\pi t) + c_3$ to model the daily temperatures using data recorded in Washington, DC. between 1967 and 1971."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd\n","df = pd.read_csv(bucket+'dailytemps.csv')\n","t = pd.to_datetime(df[\"date\"]).values\n","day = (t - t[0])/np.timedelta64(365, 'D')\n","u = df[\"temperature\"].values[:,None]\n","def tempsmodel(t): return np.c_[np.sin(2*π*t),\\\n","  np.cos(2*π*t), np.ones_like(t)]\n","c = la.lstsq(tempsmodel(day),u)[0]\n","plt.plot(day,u,'o',color='#0000ff15');\n","plt.plot(day,tempsmodel(day)@c,'k'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**3.8. Image recognition.** We'll practice  identifying handwritten digits using the MNIST database. We'll use the Keras library to load the MNIST data."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from keras.datasets import mnist\n","from scipy.sparse.linalg import svds\n","(image_train,label_train),(image_test,label_test) = mnist.load_data()\n","image_train = np.reshape(image_train, (60000,-1));\n","V = np.zeros((12,784,10))\n","for i in range(10):\n","  D = sps.csr_matrix(image_train[label_train==i], dtype=float)\n","  U,S,V[:,:,i] = svds(D,12)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["pix = [V[i,:,3].reshape(28,28) for i in range(11,-1,-1)]\n","plt.imshow(np.hstack(pix), cmap=\"gray\")\n","plt.axis('off'); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["image_test = np.reshape(image_test, (10000,-1));\n","r = np.zeros((10,10000))\n","for i in range(10):\n","  q = V[:,:,i].T@(V[:,:,i] @ image_test.T) -  image_test.T\n","  r[i,:]  = np.sum(q**2,axis=0)\n","prediction = np.argmin(r,axis=0)\n","confusion = np.zeros((10,10)).astype(int)\n","for i in range(10): \n","  confusion[i,:] = np.bincount(prediction[label_test==i],minlength=10)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd\n","pd.DataFrame(confusion)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**3.9. Actor similarity model.** We use SVD to find a lower-dimensional subspace relating actors and genres. Then we find the closest actors in that subspace using cosine similarity. We use the functions [`get_names`](#get_names) and  [`get_adjacency_matrix`](#get_adjacency_matrix) developed earlier."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["actors = get_names(\"actors\")\n","genres = get_names(\"genres\")\n","A = get_adjacency_matrix(\"movie-genre\"); A /= A.sum(axis=0)\n","B = get_adjacency_matrix(\"actor-movie\")"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.sparse.linalg import svds\n","U,S,Vᵀ = svds(A@B, 12)\n","Q = Vᵀ/np.sqrt((Vᵀ**2).sum(axis=0))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["q = Q[:,actors.index(\"Steve Martin\")]                         \n","z = Q.T @ q\n","r = np.argsort(-z)\n","[actors[i] for i in r[:10]]"]},{"cell_type": "markdown", "metadata": {}, "source": ["Let's also see Steve Martin's genre signature."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["p = (U*S) @ q\n","r = np.argsort(-p)\n","[(genres[i],p[i]/p.sum()) for i in r[:10]]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**3.10. Multilateration.** We use ordinary least squares and total least squares to solve a multilateration problem. The function [`tls`](#tls) is defined above."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["X = np.array([[3,3,12],[1,15,14],[10,2,13],[12,15,14],[0,11,12]])\n","reference = X[0,:];  X = X - reference\n","A = np.array([2,2,-2])*X\n","b = (X**2)@np.array([[1],[1],[-1]])\n","x_ols = la.lstsq(A,b)[0] + reference[:,None]\n","x_tls = tls(A,b) + reference[:,None]\n","x_ols, x_tls"]},{"cell_type": "markdown", "metadata": {}, "source": ["**3.11. ShotSpotter.** Let's modify the previous solution for this multilateration problem. We'll first download the data set."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd\n","df = pd.read_csv(bucket+'shotspotter.csv')\n","c = 328.6\n","X = df.iloc[:-1].to_numpy()\n","reference = X[0,:];  X = X - reference\n","A = np.array([2,2,2,-2*c**2])*X\n","b = (X**2)@np.array([[1],[1],[1],[-1*c**2]])\n","x_ols = la.lstsq(A,b)[0] + reference[:,None]\n","error = x_ols.flatten() - df.iloc[-1].to_numpy()\n","display(error)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**4.1. Girko's circular law.** Let's plot out the eigenvalues of a few thousand normal random matrices of size $n$ to get a probability distribution in the complex plane.  What do you notice?"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 8\n","E = [la.eigvals(np.random.randn(n,n)) for i in range(2500)]\n","E = np.concatenate(E)\n","plt.plot(E.real, E.imag,'.',c='#0000ff10',mec='none') \n","plt.axis('equal'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**4.4. Rayleigh quotient iteration.** Let's define a function that finds an eigenvalue $\\lambda$ and eigenvector $\\mathbf{x}$ of a matrix. The function will choose a random initial guess for $\\mathbf{x}$ unless one is provided. We'll then verify the algorithm on a symmetric matrix. Rayleigh quotient iteration works on general classes of matrices, but it often has difficulty converging when matrices get large or far from symmetric⁠—i.e., when eigenvectors get closer together."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def rayleigh(A,x=[]):\n","  n = len(A)\n","  if x==[]: x = np.random.randn(n,1)\n","  while True:\n","    x = x/la.norm(x)\n","    ρ = x.T @ A @ x\n","    M = A - ρ*np.eye(n)\n","    if abs(la.det(M))<1e-10:\n","      return (ρ,x)\n","    x = la.solve(M,x)\n","A = np.array([[2,3,6,4],[3,0,3,1],[6,3,8,8],[4,1,8,2]])\n","rayleigh(A)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**4.5. Implicit QR method.** We'll define a function that computes all the eigenvalues of a matrix using the implicit QR method. We'll then verify the algorithm on a matrix with known eigenvalues."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def implicitqr(A):\n","  tolerance = 1e-12\n","  n = len(A)\n","  H = la.hessenberg(A)\n","  while True:\n","    if abs(H[n-1,n-2]) < tolerance:\n","      n -= 1\n","      if n<2: return np.diag(H)\n","    Q,_ = la.qr([[H[0,0]-H[n-1,n-1]], [H[1,0]]])\n","    H[:2,:n] = Q @ H[:2,:n]\n","    H[:n,:2] = H[:n,:2] @ Q.T\n","    for i in range(1,n-1):\n","      Q,_ = la.qr([[H[i,i-1]], [H[i+1,i-1]]])\n","      H[i:i+2,:n] = Q @ H[i:i+2,:n]\n","      H[:n,i:i+2] = H[:n,i:i+2] @ Q.T"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 20; S = np.random.randn(n,n); \n","D = np.diag(np.arange(1,n+1)); A = S @ D @ la.inv(S)\n","implicitqr(A)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**4.6. Hollywood eigenvector centrality.** We'll use eigenvector centrality to determine who's at the center of Hollywood. We use the functions [`get_names`](#get_names) and  [`get_adjacency_matrix`](#get_adjacency_matrix) developed earlier."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["actors = get_names(\"actors\")\n","B = get_adjacency_matrix(\"actor-movie\")\n","r,c = (B.T@B).nonzero()\n","M = sps.csr_matrix((np.ones(len(r)),(r,c)))\n","v = np.ones(M.shape[0])\n","for k in range(10):\n","  v = M@v; v /= np.linalg.norm(v)\n","r = np.argsort(-v)\n","[actors[i] for i in r[:10]]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**4.7. Randomized SVD.** We define a method that implements randomized SVD. The idea is to start with a set of $k$ random vectors and perform a few steps of the naive QR method to generate a $k$-dimensional subspace closer to the space of dominant singular values. Then, we perform SVD on that subspace. We may not get the exact singular values, but we just need a good guess. Because the matrix is huge, this method can be significantly faster than SVD or sparse SVD."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def randomizedsvd(A,k):\n","  Z = np.random.rand(A.shape[1],k)\n","  Q,R = la.qr(A@Z, mode='economic')\n","  for i in range(4):\n","    Q,R = la.qr(A.T @ Q, mode='economic')\n","    Q,R = la.qr(A @ Q, mode='economic')\n","  W,S,Vᵀ = la.svd(Q.T @ A,full_matrices=False)\n","  U = Q @ W\n","  return (U,S,Vᵀ)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = rgb2gray(getimage(bucket+'red-fox.jpg'))\n","U, S, Vᵀ = randomizedsvd(A,10);\n","img = np.c_[A, np.minimum(np.maximum((U*S)@Vᵀ,0),255)]\n","showimage(img)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import timeit\n","k = 10\n","print('Random SVD singular values and elapsed time:')\n","start_time = timeit.default_timer()\n","display(randomizedsvd(A,k)[1])\n","display(timeit.default_timer() - start_time)\n","print('Regular SVD singular values and elapsed time:')\n","start_time = timeit.default_timer()\n","display(la.svd(A)[1][:k])\n","display(timeit.default_timer() - start_time)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**4.8. 100-dollar, 100-digit challenge.** \"The infinite matrix $\\mathbf{A}$ with entries a₁₁=1, a₁₂ = 1/2, a₂₁ = 1/3, a₁₃ = 1/4, a₂₂ = 1/5, a₃₁ = 1/6, and so on, is a bounded operator on $\\ell^2$. What is $\\|\\mathbf{A}\\|_2$?\""]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.sparse.linalg import svds\n","m = 5000\n","A = np.array([[1/((i+j+1)*(i+j+2)/2 - j) \n","  for i in range(m)] for j in range(m)])\n","svds(A, 1)[1][0]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**5.4. 3D Poisson equation.** Let's compare the Jacobi, Gauss–Seidel, SOR, and conjugate gradient methods on the Poisson equation over the unit cube."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 50; ξ = np.arange(1,n+1)/(n+1); Δx = 1/(n+1)\n","I = sps.identity(n)\n","D = sps.diags([1, -2, 1], [-1, 0, 1], shape=(n, n))\n","A = ( sps.kron(sps.kron(D,I),I) + sps.kron(I,sps.kron(D,I)) +\n","  sps.kron(I,sps.kron(I,D)) )/Δx**2\n","f = np.array([(x-x**2)*(y-y**2) + (x-x**2)*(z-z**2)+(y-y**2)*(z-z**2) \n","    for x in ξ for y in ξ for z in ξ])\n","ue = np.array([(x-x**2)*(y-y**2)*(z-z**2)/2 \n","    for x in ξ for y in ξ for z in ξ])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.sparse.linalg import spsolve\n","def stationary(A,b,ω=0,n=400):\n","  ϵ = []; u = np.zeros_like(b)\n","  P = sps.diags(A.diagonal(),0) + ω*sps.tril(A,-1)\n","  for i in range(n):\n","    u += spsolve(P,b-A@u,'NATURAL')\n","    ϵ = np.append(ϵ,la.norm(u - ue,1))\n","  return ϵ"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def conjugategradient(A,b,n=400):\n","  ϵ = []; u = np.zeros_like(b)\n","  r = b - A@u; p = np.copy(r)\n","  for i in range(n):\n","    Ap = A@p\n","    α = np.dot(r,p)/np.dot(Ap,p)\n","    u += α*p; r -= α*Ap\n","    β = np.dot(r,Ap)/np.dot(Ap,p)\n","    p = r - β*p\n","    ϵ = np.append(ϵ,la.norm(u - ue,1))\n","  return ϵ"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["ϵ = np.zeros((400,4))\n","ϵ[:,0] = stationary(A,-f,0)\n","ϵ[:,1] = stationary(A,-f,1)\n","ϵ[:,2] = stationary(A,-f,1.9)\n","ϵ[:,3] = conjugategradient(A,-f)\n","plt.semilogy(ϵ); \n","plt.legend([\"Jacobi\",\"Gauss-Seidel\",\"SOR\",\"Conj. Grad.\"]); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**5.5.  100-dollar, 100-digit challenge.** \"Let $\\mathbf{A}$ be the 20000$\\times$20000 matrix whose entries are zero everywhere except for the primes 2, 3, 5, 7,..., 224737 along the main diagonal and the number 1 in all the positions $a_{ij}$ with |*i*-*j*|=1,2,4,8,...,16384. What is the (1,1)-entry of $\\mathbf{A}^{-1}$?\""]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.sparse.linalg import cg\n","n = 20000\n","d = 2 ** np.arange(15); d = np.r_[-d,d]\n","P = sps.diags(np.loadtxt(bucket+\"primes.csv\"))\n","B = [np.ones(n - abs(d)) for d in d]\n","A = P + sps.diags(B, d)\n","b = np.zeros(n); b[0] = 1\n","cg(A, b, M=P)[0][0]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**6.1. Radix-3 FFT.** The radix-3 FFT is similar to the [radix-2 FFT](#radix2fft). We'll verify that the code is correct by comparing it with a built-in FFT"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def fftx3(c):\n","  n = len(c)\n","  ω = np.exp(-2j*π/n); \n","  if np.mod(n,3) == 0:\n","    k = np.arange(n/3)\n","    u = np.stack((fftx3(c[:-2:3]),\\\n","        ω**k * fftx3(c[1:-1:3]),\\\n","        ω**(2*k) * fftx3(c[2::3])))\n","    F = np.exp(-2j*π/3)**np.array([[0,0,0],[0,1,2],[0,2,4]])    \n","    return (F @ u).flatten()\n","  else:\n","    k = np.arange(n)[:,None]\n","    F = ω**(k*k.T);\n","    return  F @ c"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import fft\n","v = np.random.rand(24)\n","np.c_[fft(v),fftx3(v)]"]},{"cell_type": "markdown", "metadata": {}, "source": ["**6.2. Fast multiplication.** The following function uses FFTs to multiply two large integers (inputted as strings). We'll verify that the algorithm works by multiplying the [RSA-129 factors](https://en.wikipedia.org/wiki/RSA_numbers#RSA-129).  Python uses arbitrary-precision integers, so we can simply multiply the numbers directly."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def multiply(p_,q_):\n","  from scipy.signal import fftconvolve\n","  p = np.flip(np.array([int(i) for i in list(p_)]))\n","  q = np.flip(np.array([int(i) for i in list(q_)]))\n","  pq = np.rint(fftconvolve(p,q)).astype(int)\n","  pq = np.r_[pq,0]\n","  carry = pq//10\n","  while (np.any(carry)):\n","    pq -= carry*10\n","    pq[1:] += carry[:-1]\n","    carry = pq//10\n","  return ''.join([str(i) for i in np.flip(pq)]).lstrip('0')"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["display(32769132993266709549961988190834461413177642967992942539798288533 *\\\n","3490529510847650949147849619903898133417764638493387843990820577)\n","multiply('32769132993266709549961988190834461413177642967992942539798288533',\\\n","'3490529510847650949147849619903898133417764638493387843990820577')"]},{"cell_type": "markdown", "metadata": {}, "source": ["**6.3. Fast discrete cosine transform.**"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import fft,ifft\n","def dct(f):\n","  n = f.shape[0]\n","  ω = np.exp(-0.5j*π*np.arange(n)/n).reshape(-1,1)\n","  i = [*range(0,n,2),*range(n-1-n%2,0,-2)]\n","  return np.real(ω*fft(f[i,:],axis=0))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def idct(f):\n","  n = f.shape[0]\n","  ω = np.exp(-0.5j*π*np.arange(n)/n).reshape(-1,1)\n","  i = [n-(i+1)//2 if i%2 else i//2 for i in range(n)]\n","  f[0,:] = f[0,:]/2\n","  return np.real(ifft(f/ω,axis=0))[i,:]*2"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def dct2(f): return dct(dct(f.T).T)\n","def idct2(f): return idct(idct(f.T).T)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**6.4. DCT image compression.**"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import dctn, idctn\n","def dctcompress2(A,d):\n","  n = A.shape  \n","  n0 = tuple(int(np.sqrt(d)*i) for i in A.shape)\n","  B = dctn(A)[:n0[0],:n0[1]]\n","  return B, idctn(B,s=n)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = rgb2gray(getimage(bucket+\"red-fox.jpg\"))\n","_, A0 = dctcompress2(A,0.001)\n","showimage(np.c_[A,A0])"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label18\"></a>\n## Numerical Analysis\n**8.7. Aitken $\\Delta^2$ process.** Let's approximate the Leibniz series $$1 - \\frac{1}{3} + \\frac{1}{5} - \\frac{1}{7} + \\dots = \\pi$$ with partial sums and with Aitken's extrapolation of the partial sums. We'll plot error to examine convergence."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def aitken(x1,x2,x3): \n","  return x3-(x3-x2)**2/(x3-2*x2+x1), (x1*x3-x2**2)/(x3-2*x2+x1)\n","n = 50000\n","p = np.cumsum([(-1)**i*4/(2*i+1) for i in range(n)])\n","p1,p2 = aitken(p[:n-2],p[1:n-1],p[2:n])\n","plt.loglog(abs(π-p)); plt.loglog(abs(π-p2)); plt.loglog(abs(π-p1))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**8.12. Solving a nonlinear system.** We'll solve $$(x^2+y^2)^2 - 2 (x^2 - y^2) =0$$ $$(x^2+y^2 -1)^3-x^2y^3 = 0$$ using homotopy continuation and Newton's method."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def f(x,y): return ( np.array([(x**2+y**2)**2-2*(x**2-y**2),\n","  (x**2+y**2-1)**3-x**2*y**3]) )\n","def df(x,y): return(np.array([ \\\n","  [4*x*(x**2+y**2-1),  4*y*(x**2+y**2+1)],\n","  [6*x*(x**2+y**2-1)**2-2*x*y**3, \\\n","   6*y*(x**2+y**2-1)**2-3*x**2*y**2]]))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def homotopy(f,df,x):\n","  from scipy.integrate import solve_ivp\n","  def dxdt(t,x,p): return(la.solve(-df(x[0],x[1]),p))\n","  sol = solve_ivp(dxdt,[0,1],x,args=(f(x[0],x[1]),))\n","  return sol.y[:,-1]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def newton(f,df,x):\n","  for i in range(100):\n","    Δx = -la.solve(df(x[0],x[1]),f(x[0],x[1]))\n","    x += Δx\n","    if (la.norm(Δx) < 1e-8): return x"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["x0 = [-1,-1]\n","print(homotopy(f,df,x0))\n","print(newton(f,df,x0))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**8.13. Secp256k1 Elliptic curve Diffie–Hellman.** We'll first write a function that implements the point addition and point doubling. Then, we implement the double-and-add algorithm. Finally, we test the algorithm using Alice and Bob. The Python 3.8 `pow` function allows modular inverses. For Python 3.7 and earlier, see comments in this [stack overflow thread](https://stackoverflow.com/questions/4798654/modular-multiplicative-inverse-function-in-python)."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def addpoint(P,Q):\n","  a = 0\n","  r = (1<<256) - (1<<32) - 977\n","  if P[0] == Q[0]:\n","    d = pow(2*P[1], -1, r)\n","    λ = ((3*pow(P[0],2,r)+a)*d) % r\n","  else:  \n","    d = pow(Q[0] - P[0], -1, r)\n","    λ = ((Q[1] - P[1])*d) % r\n","  x = (pow(λ,2,r) - P[0] - Q[0]) % r\n","  y = (-λ*(x - P[0]) - P[1]) % r\n","  return [x,y]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def isodd(m): return ((m&1)==1)\n","def dbl_add(m,P):\n","  if m>1:\n","    Q = dbl_add(m>>1,P)\n","    return addpoint(addpoint(Q,Q),P) if isodd(m) else addpoint(Q,Q)\n","  else:\n","    return P"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["Px  = int(\"79BE667EF9DCBBAC55A06295CE87\"\\\n"," + \"0B07029BFCDB2DCE28D959F2815B16F81798\",16)\n","Py = int(\"483ADA7726A3C4655DA4FBFC0E11\"\\\n"," + \"08A8FD17B448A68554199C47D08FFB10D4B8\",16)\n","P = [Px,Py]\n","m, n = 1829442, 3727472\n","mP = dbl_add(m,P)\n","nmP = dbl_add(n,mP)\n","nP = dbl_add(n,P)\n","print(\"Alice's private key:\\n{}\\n\\n\".format(m))\n","print(\"Bob's private key:\\n{}\\n\\n\".format(n))\n","print(\"Alice's public key:\\n{}\\n\\n\".format(mP))\n","print(\"Bob's public key:\\n{}\\n\\n\".format(nP))\n","print(\"Alice and Bob's shared secret key:\\n{}\".format(nmP))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**9.2. Periodic parametric splines.** We modify the code [`spline_natural`](#spline_natural) (above) to  make a generate a spine with periodic boundary conditions. The function `evaluate_spline` is duplicated from the code above."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def spline_periodic(x,y):\n","  h = np.diff(x)\n","  d = 6*np.diff(np.diff(np.r_[y[-2],y])/np.r_[h[-1],h])\n","  α = h[:-1]\n","  β = h + np.r_[h[-1],h[:-1]]\n","  C = np.diag(β)+np.diag(α,1)\n","  C[0,-1]=h[-1]; C += C.T \n","  m = la.solve(C,d)\n","  return np.r_[m,m[0]]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def evaluate_spline(x,y,m,n):\n","  h = np.diff(x)\n","  B = y[:-1] - m[:-1]*h**2/6\n","  A = np.diff(y)/h-h/6*np.diff(m)\n","  X = np.linspace(np.min(x),np.max(x),n+1)    \n","  i = np.array([np.argmin(X>=x)-1 for X in X])\n","  i[-1] = len(x)-2\n","  Y = (m[i]*(x[i+1]-X)**3 + m[i+1]*(X-x[i])**3)/(6*h[i]) \\\n","      + A[i]*(X-x[i]) + B[i]\n","  return (X,Y)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n, nx = 10, 20\n","x, y = np.random.rand(n), np.random.rand(n)\n","x, y = np.r_[x,x[0]], np.r_[y,y[0]]\n","t = np.cumsum(np.sqrt(np.diff(x)**2+np.diff(y)**2))\n","t = np.r_[0,t]  \n","T,X = evaluate_spline(t,x,spline_periodic(t,x),nx*n)\n","T,Y = evaluate_spline(t,y,spline_periodic(t,y),nx*n)\n","plt.plot(X,Y,x,y,'o'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**9.3. Radial basis functions.** Let's examine how a polynomial $y(x) = \\sum_{i=0}^n c_i x^i$ compares with Gaussian and cubic radial basis functions $y(x) = \\sum_{i=0}^n c_i \\phi(x-x_i),$ taking $\\phi(x)= \\exp(-20x^2)$ and $\\phi(x) = |x|^3$ an interpolant of the Heaviside function."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["n = 20; N = 200\n","x = np.linspace(-1,1,n)[:,None]\n","X = np.linspace(-1,1,N)[:,None]\n","y = (x>0)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def ϕ1(x,a): return abs(x-a)**3\n","def ϕ2(x,a): return np.exp(-20*(x-a)**2)\n","def ϕ3(x,a): return x**a\n","def interp(ϕ,a): \n","  return ϕ(X,a.T)@la.solve(ϕ(x,a.T),y)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["Y1 = interp(ϕ1,x)\n","Y2 = interp(ϕ2,x)\n","Y3 = interp(ϕ3,np.arange(n))\n","plt.plot(x,y,X,Y1,X,Y2,X,Y3)\n","plt.ylim((-.5,1.5)); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**9.4. Collocation.** We'll use collocation to solve Bessel's equation.  We first define a function to solve general linear boundary value problems. And, then we define a function to interpolate between collocation points."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def solve(L,f,bc,x):\n","  h = x[1]-x[0]\n","  S = np.array([[1,-1/2,1/6],[-2,0,2/3],[1,1/2,1/6]])  \\\n","          /np.array([h**2,h,1])\n","  S = np.r_[np.zeros((1,3)),L(x)@S.T,np.zeros((1,3))]\n","  d = np.r_[bc[0], f(x), bc[1]]\n","  A = np.diag(S[1:,0],-1) + np.diag(S[:,1]) + np.diag(S[:-1,2],1)\n","  A[0,:3] , A[-1,-3:] = np.array([1,4,1])/6 , np.array([1,4,1])/6\n","  return la.solve(A,d)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def build(c,x,N):\n","  X = np.linspace(x[0],x[-1],N)\n","  h = x[1] - x[0]\n","  i = (X // h).astype(int)\n","  i[-1] = i[-2]\n","  C = np.c_[c[i],c[i+1],c[i+2],c[i+3]]\n","  B = lambda x: np.c_[(1-x)**3, 4-3*(2-x)*x**2, \\\n","           4-3*(1+x)*(1-x)**2, x**3]/6\n","  Y = np.sum(C*B((X-x[i])/h),axis=1)\n","  return (X,Y)"]},{"cell_type": "markdown", "metadata": {}, "source": ["Now, we can solve the Bessel equation $xu''+u'+xu =0$ with boundary conditions $u(0)=1$ and $u(b)=0$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.special import jn_zeros, j0\n","n = 15; N = 141\n","L = lambda x: np.c_[x,np.ones_like(x),x]\n","f = lambda x: np.zeros_like(x)\n","b = jn_zeros(0,4)[-1]\n","x = np.linspace(0,b,n)\n","c = solve(L,f,[1,0],x)\n","X,Y = build(c,x,N)\n","plt.plot(X,Y,X,j0(X)); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["Finally, we'll explore the error and convergence rate."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["N = 10*2**np.arange(6)\n","ϵ = []\n","for n in N:\n","  x = np.linspace(0,b,n)\n","  c = solve(L,f,[1,0],x)\n","  [X,Y] = build(c,x,n)\n","  ϵ = np.r_[ϵ,la.norm(Y-j0(X))/n]\n","plt.loglog(N,ϵ,'.-'); plt.show()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from numpy.polynomial.polynomial import polyfit \n","s = polyfit(np.log(N),np.log(ϵ),1)[1]\n","print(\"slope = \" + \"{:4.4f}\".format(s))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**10.3. Fractional derivatives.** We'll plot the fractional derivatives for a function."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from numpy.fft import fft,ifft,fftshift\n","def f(x): return np.exp(-16*x**2)\n","def f(x): return x*(1-np.abs(x))\n","n = 2000; ℓ = 2 \n","x = np.arange(n)/n*ℓ-ℓ/2\n","ξ = fftshift(np.arange(n)-n/2)*2*π/ℓ"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from ipywidgets import interactive\n","def anim(derivative=0):\n","  u = np.real(ifft((1j*ξ)**derivative*fft(f(x))))\n","  plt.plot(x,u,color='k'); plt.show()\n","interactive(anim, derivative = (0,2,0.01))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**10.4. Handwriting classification.** We'll use Keras to train a convolutional neural net using MNIST data and then test the model."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import tensorflow as tf\n","from tensorflow import keras\n","from keras.layers import Conv2D, AvgPool2D, Dense, Flatten\n","model = keras.models.Sequential([\n","  Conv2D(6,5,activation='tanh',padding='same',input_shape=(28,28,1)),\n","  AvgPool2D(),\n","  Conv2D(16, 5, activation='tanh'),\n","  AvgPool2D(),\n","  Conv2D(120, 5, activation='tanh'),\n","  Flatten(),\n","  Dense(84, activation='tanh'),\n","  Dense(10, activation='sigmoid')\n","])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["model.build(); model.summary()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from keras.datasets import mnist\n","(image_train,label_train),(image_test,label_test) = mnist.load_data()\n","image_train = tf.expand_dims(image_train/255.0, 3)\n","image_test = tf.expand_dims(image_test/255.0, 3)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n","model.compile(optimizer=\"adam\",  loss=loss, metrics=[\"accuracy\"])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["model.fit(image_train, label_train, epochs=5)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["model.evaluate(image_test,label_test)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**10.5. Multilateration.** Let's modify the previous solution for this multilateration problem. We'll first download the data set."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.optimize import curve_fit\n","def ϵ(X, x, y, t): \n","  return np.sqrt((X[0] - x)**2 + (X[1] - y)**2) - (X[2]-t)\n","X = np.array([[3,3,12],[1,15,14],[10,2,13],[12,15,14],[0,11,12]])\n","x_nls = curve_fit(ϵ, X.T, np.zeros(len(X)), p0 = (0,0,0))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["import pandas as pd\n","df = pd.read_csv(bucket+'shotspotter.csv')\n","X = df.iloc[:-1].to_numpy()"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def ϵ(X, x, y, z, t): \n","  return np.sqrt((X[0]-x)**2+(X[1]-y)**2+(X[2]-z)**2)-328.6*(X[3]-t)\n","x_nls = curve_fit(ϵ, X.T, np.zeros(len(X)), p0 = X[0,:])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["x_nls[0] - df.iloc[-1].to_numpy()"]},{"cell_type": "markdown", "metadata": {}, "source": ["Let's also plot the solution. We'll first define a function to plot circles."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def plot_circle (x,y,r):\n","  t = np.linspace(0,2*π,100)\n","  plt.plot(x+r*np.cos(t), y+r*np.sin(t), color=[0,0,0,0.5])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["r = 328.6*(X[:,-1] - x_nls[0][-1])\n","plt.scatter(X[:,0], X[:,1], color = 'black')\n","[plot_circle(X[i,0],X[i,1],r[i]) for i in range(len(r))]\n","plt.scatter(x_nls[0][0], x_nls[0][1], color = 'red')\n","plt.gca().set_aspect('equal')"]},{"cell_type": "markdown", "metadata": {}, "source": ["**11.1. Finite difference approximation.**  Let's find coefficients to the third-order approximation of $f'(x)$ for nodes at $x$, $x+h$, $x+2h$ and $x+3h$.  We'll reuse the function [`rats`](#rats) from above."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["d = np.array([0,1,2,3])[:,None]; n = len(d)\n","factorial = [np.math.factorial(i) for i in range(n+1)]\n","V = d**np.arange(n) / factorial[:-1]\n","C = la.inv(V)\n","C = np.c_[C,C@d**n/factorial[-1]]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from fractions import Fraction\n","def rats(x): return str(Fraction(x).limit_denominator())"]},{"cell_type": "markdown", "metadata": {}, "source": ["The coefficients of the finite difference approximation of the derivative and coefficient of the truncation error are given by"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["print(\"Coefficients: \"+\", \".join([rats(x) for x in C[1,:-1]]))\n","print(\"Truncation: \"+rats(C[1,-1]) )"]},{"cell_type": "markdown", "metadata": {}, "source": ["**11.2. Richardson extrapolation.** The following code is an iterative version of the recursive [`richardson`](#richardson_extrapolation) function above:"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def richardson(f,x,m):\n","  D = np.zeros(m)\n","  for i in range(m):\n","    D[i] = ϕ(f,x,2**(i+1))\n","    for j in range(i-1,-1,-1):\n","      D[j] = (4**(i-j)*D[j+1] - D[j])/(4**(i-j) - 1)\n","  return D[1]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def ϕ(f,x,n): return (f(x+1/n) - f(x-1/n))/(2/n)\n","richardson(lambda x: np.sin(x),0,4)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**11.3. Automatic differentiation.** Let's extend the [`Dual class`](#dualclass) above by adding methods for division, cosine, and square root to the class definition. We'll also add a few more help functions. "]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["class Dual:\n","  def __init__(self, value, deriv=1):\n","    self.value = value\n","    self.deriv = deriv\n","  def __add__(u, v):\n","    return Dual(value(u) + value(v), deriv(u) + deriv(v))\n","  __radd__ = __add__\n","  def __sub__(u, v):\n","    return Dual(value(u) - value(v), deriv(u) - deriv(v))\n","  __rsub__ = __sub__\n","  def __mul__(u, v):\n","    return Dual(value(u)*value(v), \n","        value(v)*deriv(u) + value(u)*deriv(v))\n","  __rmul__ = __mul__\n","  def sin(u):\n","    return Dual(sin(value(u)),cos(value(u))*deriv(u)) \n","  def __truediv__(u, v):\n","    return Dual(value(u) / value(v), \n","      (value(v)*deriv(u)-value(u)*deriv(v))/(value(v)*value(v)))\n","  __rtruediv__ = __truediv__\n","  def cos(u):\n","    return Dual(cos(value(u)),-1*sin(value(u))*deriv(u))\n","  def sqrt(u):\n","    return Dual(sqrt(value(u)),deriv(u)/(2*sqrt(value(u))))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def value(x): \n","  return (x.value if isinstance(x, Dual) else x)\n","def deriv(x): \n","  return (x.deriv if isinstance(x, Dual) else 0)\n","def sin(x): return np.sin(x) \n","def cos(x): return np.cos(x) \n","def auto_diff(f,x): \n","    return f(Dual(x)).deriv\n","def cos(u): return np.cos(u)\n","def sqrt(u): return np.sqrt(u)"]},{"cell_type": "markdown", "metadata": {}, "source": ["Now, we can define Newton's method using this new Dual class and use it to find the zero of $4\\sin x + \\sqrt{x}$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def get_zero(f,x):\n","  ϵ = 1e-14; δ = 1\n","  while abs(δ) > ϵ:\n","    fx = f(Dual(x))\n","    δ = value(fx)/deriv(fx)\n","    x -= δ\n","  return x"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def f(x): return 4*sin(x) + sqrt(x)\n","get_zero(f, 4)"]},{"cell_type": "markdown", "metadata": {}, "source": ["We can find a minimum or maximum of $4\\sin x + \\sqrt{x}$ by modifying Newton's method."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def get_extremum(f,x):\n","  ϵ = 1e-14; δ = 1\n","  while abs(δ)>ϵ:\n","    fx = f(Dual(Dual(x)))\n","    δ = deriv(value(fx))/deriv(deriv(fx))\n","    x -= δ\n","  return x"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["get_extremum(f, 4)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**11.4. Cauchy differentiation formula.** Let's compute the sixth derivative of $\\mathrm{e}^x(\\cos^3 x + \\sin^3 x)^{-1}$ evaluated at $x = 0$ using the Cauchy differentiation formula: $$f^{(p)}(a) = \\frac{p!}{2\\pi\\mathrm{i}} \\oint_\\gamma \\frac{f(z)}{(z-a)^{p+1}} \\,\\mathrm{d}{z}.$$"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def cauchyderivative(f, a, p, n = 20, ϵ = 0.1):\n","  ω = np.exp(2*π*1j*np.arange(n)/n)\n","  return np.math.factorial(p)/(n*ϵ**p)*sum(f(a+ϵ*ω)/ω**p)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["f = lambda x: np.exp(x)/(np.cos(x)**3 + np.sin(x)**3)\n","cauchyderivative(f, 0, 6)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**11.5. Gauss–Legendre quadrature.** The following  function computes the nodes and weights for  Gauss–Legendre quadrature by using Newton's method to find the roots of $\\mathrm{P_n}(x)$. We'll verify the function on a toy problem."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def gauss_legendre(n):\n","  x = -np.cos((4*np.arange(n)+3)*π/(4*n+2))\n","  Δ = np.ones_like(x)\n","  dP = 0\n","  while(max(abs(Δ))>1e-16):\n","    P0, P1 = x, np.ones_like(x)\n","    for k in range(2,n+1):\n","      P0, P1 = ((2*k - 1)*x*P0-(k-1)*P1)/k, P0 \n","    dP = n*(x*P0 - P1)/(x**2-1)\n","    Δ =  P0 / dP \n","    x -= Δ\n","  return ( x, 2/((1-x**2)*dP**2) )"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def f(x): return 2*np.sqrt(1-x**2)\n","x,w = gauss_legendre(10)\n","np.dot(w,f(x))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**11.7. Fundamental solution to the heat equation.** We'll use Gauss–Hermite quadrature to compute the solution to the heat equation $$u(t,x) = \\frac{1}{\\sqrt{4\\pi t}}\\int_{-\\infty}^\\infty  u_0(s) \\mathrm{e}^{-(x-s)^2/4t} \\;\\mathrm{d}s.$$"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["ξ,w = np.polynomial.hermite.hermgauss(40)\n","def u0(x): return np.sin(x)\n","def u(t,x): \n","  return [np.dot(w,u0(x-2*np.sqrt(t)*ξ)/np.sqrt(π)) for x in x]\n","x = np.linspace(-12,12,100)\n","plt.plot(x,u(1,x)); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**11.8. Monte Carlo integration.** The following  function the volume of an $d$-dimensional sphere using $n$ samples and $m$ trials. We'll use it to verify that error of Monte Carlo integration is $O(1/\\sqrt{n})$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def mc_π(n,d,m): \n","  return sum(sum(np.random.rand(d,n,m)**2)<1)/n*2**d"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = 20; error = []; N = 2**np.arange(20)\n","error = [sum(abs(π - mc_π(n,2,m)))/m for n in N]\n","plt.loglog(N,error,marker=\".\",linestyle=\"None\")\n","s = np.polyfit(np.log(N),np.log(error),1)\n","plt.loglog(N,np.exp(s[1])*N**s[0])\n","plt.show()\n","print(\"slope = {:4.3f}\".format(s[0]))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**11.10 Orthogonal collocation** We'll solve $u'(t) = \\alpha u^2$ using the spectral method and pseudospectral method."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def gauss_legendre(n,lobatto=False):\n","  a = np.zeros(n)  \n","  b = np.arange(1,n)**2 / (4*np.arange(1,n)**2 - 1)\n","  if lobatto: b[-1] = (n-1)/(2*(n-1) - 1)\n","  scaling = 2\n","  nodes, v = la.eigh_tridiagonal(a, np.sqrt(b))\n","  return ( nodes, scaling*v[0,:]**2 )"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def differentiation_matrix(n,Δt=1):\n","  nodes, _ = gauss_legendre(n+1,lobatto=True)\n","  t = (nodes[1:]+1)/2\n","  A = np.vander(t,increasing=True)*np.arange(1,n+1)\n","  B = np.diag(t)@np.vander(t,increasing=True)\n","  return (A@la.inv(B)/Δt, t)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.optimize import fsolve\n","n = 20; u0 = 1.0; α = 0.9\n","M,t = differentiation_matrix(n) \n","def D(u,u0): return M@(u - u0)\n","def F(u,u0,α): return D(u,u0) - α*u**2\n","u = fsolve(F,u0*np.ones(n),args=(u0,α))\n","plt.plot(t, u, marker=\"o\")"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["N = 20; Δt = 1.0/N; n = 8; α\n","M,t = differentiation_matrix(n,Δt) \n","def D(u,u0): return M@(u - u0)\n","u0 = 1.0; U = np.array(u0); T = np.array(0)\n","for i in range(N):\n","  u = fsolve(F,u0*np.ones(n),args=(u0,α))\n","  u0 = u[-1]\n","  T = np.append(T,(i + t)*Δt)\n","  U = np.append(U,u)\n","plt.plot(T, U, marker=\"o\")"]},{"cell_type": "markdown", "metadata": {}, "source": ["<a name=\"label19\"></a>\n## Numerical Differential Equations\n**12.4. Runge–Kutta  stability.** The following code plots the region of absolute stability for a Runge–Kutta method with tableau `A` and `b`."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["A = np.array([\n","  [0,   0,   0,   0,   0],\n","  [1/3, 0,   0,   0,   0],\n","  [1/6, 1/6, 0,   0,   0],\n","  [1/8, 0,   3/8, 0,   0],\n","  [1/2, 0,  -3/2, 2,   0]])\n","b = np.array([[1/6, 0, 0, 2/3, 1/6]])"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["N = 100; n = b.shape[1]\n","r = np.zeros((N,N))\n","E = np.ones((n,1))\n","x,y = np.linspace(-4,4,N),np.linspace(-4,4,N)\n","for i in range(N):\n","  for j in range(N):\n","    z = x[i] + 1j*y[j]\n","    r[j,i] = abs(1 + z*b@(la.solve(np.eye(n) - z*A,E)))\n","plt.contour(x,y,r,[1]); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**12.7. Third-order IMEX coefficients.** We can determine the coefficients of a third-order IMEX method by inverting a system of linear equations."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["i = np.arange(4)[:,None]\n","def factorial(k): return np.cumprod(np.r_[1,range(1,k)])\n","c1 = la.solve(((-i)**i.T/factorial(4)).T,np.array([0,1,0,0]))\n","c2 = la.solve(((-(i+1))**i.T/factorial(4)).T,np.array([1,0,0,0]))"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from fractions import Fraction\n","def rats(x): return str(Fraction(x).limit_denominator())"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["print(\"right-hand side: \" + \", \".join([rats(c) for c in c1]))\n","print(\"implicit: \" + \", \".join([rats(c) for c in c2]))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**12.8. Predictor-corrector stability.** We'll use the  [`multistepcoefficients`](#multistepcoefficients) introduced earlier. The following function provides the orbit of points in the complex plane for an $n$th order  Adams–Bashforth–Moulton PE(CE)$^m$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def multistepcoefficients(m,n):\n","  s = len(m) + len(n) - 1\n","  A = (np.array(m)+1)**np.c_[range(s)]\n","  B = [[i*((j+1)**max(0,i-1)) for j in n] for i in range(s)]\n","  c = la.solve(-np.c_[A[:,1:],B],np.ones((s,1))).flatten()\n","  return ( np.r_[1,c[:len(m)-1]], c[len(m)-1:] )"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def PECE(n,m):\n","  _,a = multistepcoefficients([0,1],range(1,n))\n","  _,b = multistepcoefficients([0,1],range(0,n))\n","  def c(r): return np.r_[r-1,\\\n","    np.full(m, r + np.dot(b[1:],r**np.arange(1,n))/b[0]),\\\n","    (a @ r**np.arange(1,n))/b[0]]\n","  return [np.roots(np.flip(c(r)))/b[0] \\\n","    for r in np.exp(1j*np.linspace(0,2*π,200))]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["for i in range(5): \n","  z = PECE(4,i)      \n","  plt.scatter(np.real(z),np.imag(z),s=0.5)\n","plt.axis('equal'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**12.9. Padé approximant.** We'll build a function to compute the coefficients of the Padé approximant to $log(r)$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def pade(a,m,n):\n","  A = np.eye(m+n+1);\n","  for i in range(n): A[i+1:,m+i+1] = -a[:m+n-i]\n","  pq = la.solve(A,a[:m+n+1])\n","  return pq[:m+1], np.r_[1,pq[m+1:]]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = 3; n = 2\n","a = np.r_[0, (-1)**np.arange(m+n)/(1+np.arange(m+n))]\n","p,q = pade(a,m,n)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def S(n): return la.invpascal(n+1, kind='upper')\n","S(m)@p, S(n)@q"]},{"cell_type": "markdown", "metadata": {}, "source": ["**12.13. SIR solution.** Let's solve the susceptible-infected-recovered (SIR) model for infectious diseases using a general ODE solver."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","def SIR(t,u,β,γ): return (-β*u[0]*u[1],β*u[0]*u[1]-γ*u[1],γ*u[1])\n","sol = solve_ivp(SIR, [0, 15], [0.99, 0.01, 0],\\\n","  args=(2,0.4), dense_output=True)\n","t = np.linspace(0,15,200); u = sol.sol(t)\n","plt.plot(t,u[0,:],t,u[1,:],t,u[2,:]); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**12.14. Duffing equation.** We'll use a high-order, explicit ODE solver for the Duffing equation."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","def duffing(t,x,g): return(x[1],-g*x[1]+x[0]-x[0]**3+0.3*np.cos(t))\n","sol = solve_ivp(duffing,[0,200], [1, 0], args=(0.37,), \n","    method='DOP853',dense_output=True)\n","t = np.linspace(0,200,2000); y = sol.sol(t)\n","plt.plot(y[0,:],y[1,:]); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**12.15. Shooting method.** We'll solve the Airy equation $y'' - xy = 0$ using the shooting method that incorporates an initial value solver into a nonlinear root finder."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","from scipy.optimize import fsolve\n","def airy(x,y): return (y[1],x*y[0])\n","domain = [-12,0]; bc = [1,1]; guess = 5\n","def shoot_airy(guess):\n","  sol = solve_ivp(airy,domain,[bc[0],guess[0]])\n","  return sol.y[0,-1] - bc[1] \n","v = fsolve(shoot_airy,guess)[0]"]},{"cell_type": "markdown", "metadata": {}, "source": ["Once we have our second initial value, we can plot the solution:"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["sol = solve_ivp(airy,domain,[bc[0],v],dense_output=True)\n","x = np.linspace(-12,0,200)\n","plt.plot(x,sol.sol(x)[0,:]); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**13.4. An unconditionally unstable method.** Let's generate the coefficients for multistep scheme given by the stencil:</br><img src=\"https://raw.githubusercontent.com/nmfsc/data/master/unstable_heat_stencil.svg\" alt=\"unstable finite difference stencil\" title=\"unstable finite difference  stencil\" /></br> We'll use the function  [`multistepcoefficients`](#multistepcoefficients) introduced earlier. Then we'll plot $r(\\lambda k)$ along the real axis. The method is unstable wherever $|r|>1$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = [0,1,2,3,4]; n = [1]\n","a,b = multistepcoefficients(m,n)\n","b = np.r_[0,b]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def λk(r): return np.dot(a,r**-np.arange(len(a))) /\\\n","  np.dot(b,r**-np.arange(len(b)))\n","r = np.linspace(0.2,6,100)\n","plt.plot([λk(r) for r in r],r)\n","plt.plot([λk(-r) for r in r],r); plt.xlim([-2,2]);"]},{"cell_type": "markdown", "metadata": {}, "source": ["**13.5. Dufort–Frankel method.** We'll use the Dufort–Frankel method to solve the heat equation. While this method is unconditionally stable, it generates the wrong solution. Notice that while the long-term behavior is dissipative, the solution is largely oscillatory, and the dynamics are more characteristic of a viscous fluid than heat propagation."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["dx = 0.01; dt = 0.01; n = 400\n","L = 1; x = np.arange(-L,L,dx); m = len(x) \n","U = np.empty((n,m))\n","U[0,:] = np.exp(-8*x**2); U[1,:] = U[0,:]  \n","c = dt/dx**2; a = 0.5 + c; b = 0.5 - c\n","B = c*sps.diags([1, 1], [-1, 1], shape=(m, m)).tocsr()\n","B[0,1] *=2; B[-1,-2] *=2\n","for i in range(1,n-1):\n","  U[i+1,:] = (B@U[i,:]+b*U[i-1,:])/a"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from ipywidgets import interactive\n","def anim(i=0):\n","  plt.fill_between(x,U[i,:],color='#ff9999');\n","  plt.ylim(0,1);plt.show()\n","interactive(anim, i=(0,n-1))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**13.7. Schrödinger equation.** Let's solve the Schrödinger equation for a harmonic potential using the Strang splitting Crank–Nicolson and confirm that the method is $O(h^2,k^2)$."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.sparse.linalg import spsolve\n","def ψ0(x,ϵ): return np.exp(-(x-1)**2/(2*ϵ))/(π*ϵ)**(1/4)\n","def schroedinger(n,m,ϵ):\n","  x,dx = np.linspace(-4,4,n,retstep=True); Δt = 2*π/m; V = x**2/2\n","  ψ = ψ0(x,ϵ)\n","  D = 0.5j*ϵ*sps.diags([1, -2, 1], [-1, 0, 1], shape=(n, n))/dx**2 \\\n","    - 1j/ϵ*sps.diags(V,0)\n","  D[0,1] *= 2; D[-1,-2] *= 2\n","  A = sps.eye(n) + (Δt/2)*D \n","  B = sps.eye(n) - (Δt/2)*D  \n","  for i in range(m):\n","    ψ = spsolve(B,A*ψ)\n","  return ψ"]},{"cell_type": "markdown", "metadata": {}, "source": ["We'll loop over several values for time steps and mesh sizes and plot the error. This may take a while. Go get a snack."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["ϵ = 0.3; m = 20000; N = np.logspace(2,3.7,6).astype(int)\n","x = np.linspace(-4,4,m)\n","ψ_m = -ψ0(x,ϵ)\n","error_t = []; error_x = []\n","for n in N: \n","  x = np.linspace(-4,4,n) \n","  ψ_n = -ψ0(x,ϵ)\n","  error_t.append(la.norm(ψ_m - schroedinger(m,n,ϵ))/m)\n","  error_x.append(la.norm(ψ_n - schroedinger(n,m,ϵ))/n)\n","plt.loglog(2*π/N,error_t,'.-r',8/N,error_x,'.-k'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**13.8. Polar heat equation.** We'll solve a radially symmetric heat equation. Although we divide by zero at $r=0$ when constructing the Laplacian operator, we subsequently overwrite the resulting  `inf` term when we apply the boundary condition."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.sparse.linalg import spsolve\n","T = 0.5; m = 100; n = 100\n","r = np.linspace(0,2,m); Δr = r[1]-r[0]; Δt = T/n\n","u = np.tanh(32*(1-r))[:,None]\n","D = sps.diags([1, -2, 1], [-1, 0, 1], shape=(m,m))/Δr**2 \\\n","  + sps.diags([-1/r[1:], 1/r[:-1]], [-1, 1])/(2*Δr)\n","D = D.tocsr()\n","D[0,0:2] = np.array([-4,4])/Δr**2;\n","D[-1,-2:] = np.array([2,-2])/Δr**2 \n","A = sps.eye(m) - 0.5*Δt*D \n","B = sps.eye(m) + 0.5*Δt*D  \n","for i in range(n):\n","  u = spsolve(A,B@u)\n","plt.fill_between(r,u,-1,color='#ff9999'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**13.9. Open boundaries.** We can approximate open boundaries by spacing the grid points using a sigmoid function such as $\\mathrm{arctanh}\\, x$. We start by defining a function `logitspace`, a logit analog to `np.linspace`. Then we define a Laplacian operator using arbitrary grid spacing. Finally, we solve the heat equation using the Crank–Nicolson using both equally-spaced and logit-spaced grid points."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def logitspace(x,n,p): \n","  return x*np.arctanh(np.linspace(-p,p,n))/np.arctanh(p)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.sparse.linalg import spsolve\n","def laplacian(x):\n","  h = np.diff(x); h1 = h[:-1]; h2 = h[1:]; n = len(x)\n","  d = np.c_[ \\\n","    np.r_[h1[0]**2, h2*(h1+h2),0], \\\n","    np.r_[-h1[0]**2, -h1*h2,-h2[-1]**2 ], \\\n","    np.r_[h1*(h1+h2), h2[-1]**2,0]].T\n","  d[0,-1], d[2,-1] = 999, 999\n","  return sps.diags(2/d,[-1,0,1],shape=(n, n)).T"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def heat_equation(x,t,u):\n","  n = 40; Δt = t/n\n","  u = ϕ(x,0,10)\n","  D = laplacian(x)\n","  A = sps.eye(len(x)) - 0.5*Δt*D\n","  B = sps.eye(len(x)) + 0.5*Δt*D\n","  for i in range(n):\n","    u = spsolve(A,B@u)\n","  return u"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def ϕ(x,t,s): \n","  return np.exp(-s*x**2/(1+4*s*t))/np.sqrt(1+4*s*t)\n","t = 15; m = 40\n","x = logitspace(20,m,.999)\n","laplacian(x).toarray()\n","u = heat_equation(x,t,ϕ(x,0,10))\n","plt.plot(x,u,'.-',x,ϕ(x,t,10),'k'); plt.show()\n","x = np.linspace(-20,20,m)\n","u = heat_equation(x,t,ϕ(x,0,10))\n","plt.plot(x,u,'.-',x,ϕ(x,t,10),'k'); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**13.10. Allen–Cahn equation.** We'll solve the Allen–Cahn equation using  Strang splitting. We'll save the solution every tenth iteration and animate it using the `ipywidgets` library.  Rerun the code by uncommenting the random initial conditions."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.sparse.linalg import spsolve\n","L = 16; m = 200; Δx = L/m\n","T = 8; n = 1600; Δt = T/n\n","x = np.linspace(-L/2,L/2,m)[None,:]\n","u = np.tanh(x**4 - 16*(2*x**2-x.T**2))\n","#u = np.random.standard_normal((m,m))\n","D = sps.diags([1, -2, 1], [-1, 0, 1], shape=(m,m)).tocsr()/Δx**2\n","D[0,1] *= 2; D[-1,-2] *= 2;\n","A = sps.eye(m) + 0.5*Δt*D\n","B = sps.eye(m) - 0.5*Δt*D \n","def f(u,Δt): \n","  return u/np.sqrt(u**2 - (u**2-1)*np.exp(-50*Δt))\n","u = f(u,Δt/2)\n","U = np.empty((m,m,n//10))\n","for i in range(n):\n","  if (i%8==0): U[:,:,i//10] = u\n","  u = spsolve(B,(A@spsolve(B,A@u).T)).T\n","  if (i<n): u = f(u,Δt)\n","u = f(u,Δt/2)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from ipywidgets import interactive\n","def anim(i=0):\n","  plt.imshow(U[:,:,i], cmap=\"gray\"); plt.axis('off'); plt.show()\n","interactive(anim, i = (0,U.shape[2]-1))"]},{"cell_type": "markdown", "metadata": {}, "source": ["**14.7. Burgers' equation.**"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = 100; x,Δx = np.linspace(-1,3,m,retstep=True)\n","n = 100; Lt = 4; Δt = Lt/n; c = Δt/Δx\n","def f(u): return u**2/2\n","def fp(u): return u\n","u = ((x>=0)&(x<=1)).astype(float)\n","for i in range(n):\n","  fu = f(np.r_[u[0],u]); fpu = fp(np.r_[u[0],u])\n","  α = np.maximum(abs(fu[1:-1]),abs(fu[:-2]))\n","  F = (fu[1:-1]+fu[:-2])/2 - α*(u[1:]-u[:-1])/2\n","  u -= c*(np.diff(np.r_[0,F,0]))\n","plt.fill(u,color=\"#9999ff\");"]},{"cell_type": "markdown", "metadata": {}, "source": ["**14.8. Dam break problem.**"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def limiter(t): return (abs(t)+t)/(1+abs(t))  \n","def fixzero(u): return u + (u==0).astype(float)\n","def diff(u): return np.diff(u,axis=0)\n","def slope(u):\n","  du = diff(u)\n","  return np.r_[np.c_[0,0], \\\n","    np.c_[du[1:,:]*limiter(du[:-1,:]/fixzero(du[1:,:]))],\\\n","    np.c_[0,0]]\n","def F(u):\n","  return np.c_[u[:,0]*u[:,1], u[:,0]*u[:,1]**2+0.5*u[:,0]**2]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = 1000; x,Δx = np.linspace(-.5,.5,m,retstep=True)\n","T = 0.25; n = (T/(Δx/2)).astype(int); Δt = (T/n)/2; c = Δt/Δx\n","u = np.c_[0.8*(x<0)+0.2,0*x] \n","for i in range(n):\n","  v = u-0.5*c*slope(F(u))\n","  u[1:,:]=(u[:-1,:]+u[1:,:])/2 - diff(slope(u))/8 - c*diff(F(v)) \n","  v = u-0.5*c*slope(F(u))\n","  u[:-1,:]=(u[:-1,:]+u[1:,:])/2 - diff(slope(u))/8 - c*diff(F(v))\n","plt.plot(x,u);"]},{"cell_type": "markdown", "metadata": {}, "source": ["**15.1. Finite element method.**"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = 10; x,h = np.linspace(0,1,m,retstep=True)\n","A = np.tile(np.r_[-1/h-h/6,2/h-2/3*h,-1/h-h/6],(m,1)).T\n","A[1,0]/=2; A[1,-1] /= 2\n","b=np.r_[-2/3*h**3,-4/3*h**3-8*h*x[1:-1]**2,-4*h+8/3*h**2-2/3*h**3+1]\n","u=la.solve_banded((1,1),A,b)\n","s=(-16)+8*x**2+15*np.cos(x)/np.sin(1)\n","plt.plot(x,s,'o-',x,u,'.-');"]},{"cell_type": "markdown", "metadata": {}, "source": ["**15.2. Finite element method.**"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["m = 8; x,h = np.linspace(0,1,m+2,retstep=True)\n","def tridiag(a,b,c): return np.diag(a,-1)+np.diag(b,0)+np.diag(c,1)\n","def D(a,b,c):   \n","  return tridiag(a*np.ones(m-1), b*np.ones(m), c*np.ones(m-1))/h**3\n","M = np.r_[np.c_[D(-12,24,-12),D(-6,0,6)],\n","  np.c_[D(6,0,-6),D(2,8,2)]]\n","b = np.r_[np.ones(m)*h*384,np.zeros(m)]\n","u = la.solve(M,b)\n","plt.plot(x,16*(x**4 - 2*x**3 + x**2),'o-',x,np.r_[0,u[:m],0],'.-');"]},{"cell_type": "markdown", "metadata": {}, "source": ["**16.2. Burgers' equation.** Fourier spectral methods perform poorly on problems that develop discontinuities such as Burgers' equation.  Gibbs oscillations develop around the discontinuity, and these oscillations will spread and grow because Burgers' equation is dispersive. Ultimately, the oscillations overwhelm the solution."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","from scipy.fft import fftshift, fft, ifft\n","m = 128; x = np.linspace(-π,π,m,endpoint=False)\n","ξ = 1j*fftshift(np.arange(-m/2,m/2))\n","def f(t,u): return -np.real(ifft(ξ*fft(0.5*u**2)))\n","sol = solve_ivp(f, [0,1.5], np.exp(-x**2), method = 'RK45')  \n","plt.plot(x,sol.y[:,-1]); plt.show()"]},{"cell_type": "markdown", "metadata": {}, "source": ["**16.3. KdV equation.** We'll solve the KdV equation using integrating factors. We first set the initial conditions and parameters. Then, we define the integrating factor `G` and the right-hand side `f` of the differential equation. Finally, we animate the solution. Notice the two soliton solution."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import fftshift, fft, ifft\n","def ϕ(x,x0,c): return 0.5*c/np.cosh(np.sqrt(c)/2*(x-x0))**2\n","L = 30; T = 2.0; m = 256\n","x = np.linspace(-L/2,L/2,m,endpoint=False)\n","iξ = 1j*fftshift(np.arange(-m/2,m/2))*(2*π/L)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["def G(t): return np.exp(-iξ**3*t)\n","def f(t,w): return -(3*iξ*fft(ifft(G(t)*w)**2))/G(t)"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.integrate import solve_ivp\n","u = ϕ(x,-4,4) + ϕ(x,-9,9)\n","w = fft(u)\n","sol = solve_ivp(f,[0,T],w,t_eval=np.linspace(0,T,200))   \n","u = [np.real(ifft(G(sol.t[i])*sol.y[:,i])) for i in range(200)]"]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["plt.rcParams[\"animation.html\"] = \"jshtml\"\n","from matplotlib.animation import FuncAnimation\n","fig, ax = plt.subplots()\n","l, = ax.plot([-15,15],[0,5])\n","def animate(i): l.set_data(x, u[i])\n","FuncAnimation(fig, animate, frames=len(u), interval=50)"]},{"cell_type": "markdown", "metadata": {}, "source": ["**16.4. Swift–Hohenberg equation.** We'll use Strang splitting to solve the  Swift–Hohenberg equation."]},
{"cell_type": "code", "execution_count": null,"metadata": {},"outputs": [],"source": ["from scipy.fft import fftshift, fft2, ifft2\n","ϵ = 1; m = 256; ℓ = 100; n = 2000; Δt=100/n\n","U = (np.random.rand(m,m)>0.5)-0.5\n","ξ = fftshift(np.arange(-m/2,m/2))*(2*π/ℓ)\n","D2 = -ξ[:,None]**2-ξ[None,:]**2\n","E = np.exp(-(D2+1)**2*Δt)\n","def f(U):\n","  return U/np.sqrt(U**2/ϵ + np.exp(-Δt*ϵ)*(1-U**2/ϵ))\n","for i in range(n):\n","  U = f(ifft2(E*fft2(f(U))))\n","plt.imshow(np.real(U), cmap=\"gray\"); plt.axis('off'); plt.show()"]}],
"metadata": { "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython","version": 3}, "file_extension": ".py",   "mimetype": "text/x-python",   "name": "python",   "nbconvert_exporter": "python",   "pygments_lexer": "ipython3",   "version": "3.6.3"  } }, "nbformat": 4, "nbformat_minor": 2 }